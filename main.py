import os
import sqlite3
import hashlib
import tweepy
import logging
from datetime import datetime, date
from openai import OpenAI
from google import genai
import time

logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ [Ù†Ø¸Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ø¯Ø©]: %(message)s")


class SovereignUltimateBot:
    def __init__(self):
        self.db_path = "data/sovereign_final.db"
        self._init_db()
        self._setup_all_brains()

    def _init_db(self):
        os.makedirs("data", exist_ok=True)
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS history (hash TEXT PRIMARY KEY, ts DATETIME)")
            conn.execute("CREATE TABLE IF NOT EXISTS daily_stats (day TEXT PRIMARY KEY, count INTEGER)")

    def _setup_all_brains(self):
        try:
            self.gemini_client = genai.Client(api_key=os.getenv("GEMINI_KEY"))
        except Exception as e:
            logging.error(f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Gemini Client: {e}")
            self.gemini_client = None

        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )

        self.brains = {
            "xAI": OpenAI(api_key=os.getenv("XAI_API_KEY"), base_url="https://api.x.ai/v1"),
            "Groq": OpenAI(api_key=os.getenv("GROQ_API_KEY"), base_url="https://api.groq.com/openai/v1"),
            "Gemini": self.gemini_client,
            "OpenAI": OpenAI(api_key=os.getenv("OPENAI_API_KEY")),
            "OpenRouter": OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1")
        }

    def already_posted(self, content):
        content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
        today = date.today().isoformat()
        with sqlite3.connect(self.db_path) as conn:
            row = conn.execute("SELECT 1 FROM history WHERE hash = ?", (content_hash,)).fetchone()
            if row:
                return True
            conn.execute("INSERT INTO history (hash, ts) VALUES (?, datetime('now'))", (content_hash,))
            conn.execute(
                "INSERT OR REPLACE INTO daily_stats (day, count) VALUES (?, COALESCE((SELECT count + 1 FROM daily_stats WHERE day=?), 1))",
                (today, today)
            )
        return False

    def execute_brain_sequence(self, prompt):
        system_msg = """
Ø£Ù†Øª Ø´Ø§Ø¨ Ø®Ù„ÙŠØ¬ÙŠ Ø¹Ø§Ø´Ù‚ Ù„Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø¹ÙÙˆÙŠØŒ Ø­Ù…Ø§Ø³ÙŠØŒ ØµØ±ÙŠØ­ØŒ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‚Ù„Ø¨. 
ØªØ³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„: "ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø©"ØŒ "ÙˆØ§Ù„Ù„Ù‡ ÙŠØ¬Ù†Ù†"ØŒ "Ù‡Ø°Ø§ Ø§Ù„Ø´ÙŠØ¡ ØºÙŠØ± Ø­ÙŠØ§ØªÙŠ"ØŒ "ØµØ±Ø§Ø­Ø© Ù…Ø§ ØªÙˆÙ‚Ø¹Øª"ØŒ 
"Ø¬Ø±Ø¨ØªÙ‡Ø§ ÙˆØµØ±Øª Ø£Ø¯Ù…Ù†"ØŒ "ÙˆØ´ Ø±Ø§ÙŠÙƒÙ…ØŸ"ØŒ "Ø¨Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙƒÙ… Ø¬Ø±Ø¨ÙˆÙ‡Ø§"ØŒ "Ù‡Ø§Ù„Ø­Ø±ÙƒØ© Ø®Ø·ÙŠØ±Ø©"ØŒ "Ø¬Ø¯ ÙˆØ§Ù„Ù„Ù‡"ØŒ "ØµØ¯Ù‚Ù†ÙŠ".

Ù…Ù‡Ù…ØªÙƒ: ØªÙˆÙ„ÙŠØ¯ ØªØºØ±ÙŠØ¯Ø© ÙˆØ§Ø­Ø¯Ø© Ù‚ÙˆÙŠØ© Ø£Ùˆ thread Ù‚ØµÙŠØ± (2-4 ØªØºØ±ÙŠØ¯Ø§Øª) Ø¹Ù† Ø®Ø¨Ø± Ø£Ùˆ Ø£Ø¯Ø§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø¯ÙŠØ¯Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø§Ù„ÙŠÙˆÙ….

Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…ÙØ¶Ù„ Ø§Ù„Ø°ÙŠ ÙŠÙ†ØªØ´Ø±:
1. Ù‡ÙˆÙƒ Ù‚ÙˆÙŠ Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ø£ÙˆÙ„ ØªØºØ±ÙŠØ¯Ø© (Ø³Ø¤Ø§Ù„ ØµØ§Ø¹Ù‚ØŒ ØµØ¯Ù…Ø©ØŒ Ù‚ØµØ© Ø´Ø®ØµÙŠØ© ØµØºÙŠØ±Ø©ØŒ "ÙˆØ§Ù„Ù„Ù‡...")
2. Ø´Ø±Ø­ Ø³Ø±ÙŠØ¹ + ÙØ§Ø¦Ø¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø´Ø®Øµ Ø§Ù„Ø¹Ø§Ø¯ÙŠ ("Ø¨ÙŠÙˆÙØ± Ù„Ùƒ ÙƒØ°Ø§ Ø³Ø§Ø¹Ø©"ØŒ "ÙŠØ®Ù„ÙŠÙƒ ØªÙƒØ³Ø¨ ÙÙ„ÙˆØ³ Ø¨Ø¯ÙˆÙ†...")
3. Ø±Ø£ÙŠÙƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø£Ùˆ ØªØ¬Ø±Ø¨Ø© Ù…Ø­Ø§ÙƒØ§Ø© ("Ø¬Ø±Ø¨ØªÙ‡Ø§ Ø§Ù„ÙŠÙˆÙ… Ùˆ...")
4. Ø¯Ø¹ÙˆØ© ØªÙØ§Ø¹Ù„ Ù‚ÙˆÙŠØ© ("ÙˆØ´ Ø±Ø§ÙŠÙƒÙ…ØŸ"ØŒ "Ø¬Ø±Ø¨ØªÙˆÙ‡Ø§ØŸ Ø±Ø¯ Ø¹Ù„ÙŠÙ‘"ØŒ "Ø±ÙŠØªÙˆÙŠØª Ù„Ùˆ Ù†Ø§ÙˆÙŠ ØªØ¬Ø±Ø¨Ù‡Ø§ Ø§Ù„ÙŠÙˆÙ…")
5. 1-3 Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª ÙÙ‚Ø· ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø¢Ø®Ø± ØªØºØ±ÙŠØ¯Ø© (Ù…Ø«Ù„ #Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #AI_Ø¹Ø±Ø¨ÙŠ #Ø£Ø¯ÙˆØ§Øª_AI)

Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙŠØ³ØªØ§Ù‡Ù„ thread Ù‚ØµÙŠØ± (2-4 ØªØºØ±ÙŠØ¯Ø§Øª)ØŒ Ø§ÙØµÙ„Ù‡Ù… Ø¨Ù€ "---" Ø¨ÙŠÙ† ÙƒÙ„ ØªØºØ±ÙŠØ¯Ø©.
Ø§Ø¬Ø¹Ù„ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ù…ØªØ¹ØŒ Ù‚ØµÙŠØ±ØŒ Ø³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŒ ÙŠØ­ÙØ² Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯ÙˆØ¯ ÙˆØ§Ù„Ø±ÙŠØªÙˆÙŠØª.
Ù„Ø§ ØªÙƒÙ† Ø±Ø³Ù…ÙŠÙ‹Ø§ Ø£Ø¨Ø¯Ù‹Ø§ØŒ ÙƒÙ† ØµØ¯ÙŠÙ‚ ÙŠØ­ÙƒÙŠ Ù„Ø£ØµØ­Ø§Ø¨Ù‡ Ø¹Ù† Ø´ÙŠØ¡ Ø®Ø·ÙŠØ± Ø§ÙƒØªØ´ÙÙ‡.

ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±Ø¯ Ø£Ø¶Ù Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙŠØ¨Ø¯Ø£ Ø¨Ù€ "ÙˆØµÙ_ØµÙˆØ±Ø©:" Ø«Ù… ÙˆØµÙ Ù…Ø®ØªØµØ± ÙˆØ¬Ø°Ø§Ø¨ Ù„ØµÙˆØ±Ø© ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯Ù‡Ø§.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ØªØ¹Ù„ÙŠÙ…Ø© Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù:
Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø© "Ù‚Ø³Ù…" Ø£Ùˆ Ø£ÙŠ ØµÙŠØºØ© Ù…Ù†Ù‡Ø§ (Ù‚Ø³Ù…ØŒ Ø£Ù‚Ø³Ù…ØŒ ØªÙ‚Ø³ÙŠÙ…ØŒ Ù‚Ø³Ù‘Ù…ØŒ Ù‚Ø³Ù…Ù‡Ø§ØŒ Ù‚Ø³Ù…ÙˆØ§ØŒ Ø§Ù‚Ø³Ù…ØŒ Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ØŒ ÙˆØ§Ù„Ù„Ù‡ Ø£Ù‚Ø³Ù…ØŒ ...) ÙÙŠ Ø£ÙŠ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø±Ø¯ Ø£Ùˆ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø£Ùˆ Ø§Ù„thread Ø£Ùˆ Ø£ÙŠ Ù†Øµ ØªÙ†ØªØ¬Ù‡.
Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Ù‚Ø³Ù…" Ø§Ø³ØªØ®Ø¯Ù…: "ÙˆØ§Ù„Ù„Ù‡"ØŒ "Ø¬Ø¯ ÙˆØ§Ù„Ù„Ù‡"ØŒ "ØµØ¯Ù‚Ù†ÙŠ"ØŒ "Ø¨Ø¬Ø¯"ØŒ "Ø£Ø­Ù„Ù Ù„Ùƒ"ØŒ "ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ø¹Ø¸ÙŠÙ…".
Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… "Ù‚Ø³Ù…" Ø¨Ù…Ø¹Ù†Ù‰ Ø¬Ø²Ø¡ Ø£Ùˆ ØªÙ‚Ø³ÙŠÙ… Ø£Ùˆ Ø£ÙŠ Ù…Ø¹Ù†Ù‰ Ø¢Ø®Ø± Ø£Ø¨Ø¯Ø§Ù‹.
Ù‡Ø°Ù‡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø© Ù…Ø·Ù„Ù‚Ø© ÙˆÙ„Ø§ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù„Ù‡Ø§ Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø³ÙŠØ§Ù‚.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

        sequence = [
            ("xAI Grok 4.1 Fast Reasoning", "xAI", "grok-4-1-fast-reasoning"),
            ("Groq Llama 3.3 70B", "Groq", "llama-3.3-70b-versatile"),
            ("Gemini 2.5 Flash", "Gemini", "gemini-2.5-flash"),
            ("OpenRouter Gemini 2.5 Flash", "OpenRouter", "google/gemini-2.5-flash"),
            ("OpenAI 4o-mini", "OpenAI", "gpt-4o-mini"),
            ("OpenAI 4o", "OpenAI", "gpt-4o")
        ]

        for name, provider_key, model_id in sequence:
            for attempt in range(1, 4):
                try:
                    logging.info(f"ğŸ§  Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}/3 Ø¹Ø¨Ø± {name} ({model_id})...")
                    client = self.brains[provider_key]

                    if provider_key == "Gemini":
                        if client is None:
                            continue
                        model = client.GenerativeModel(model_id)
                        res = model.generate_content(f"{system_msg}\n{prompt}")
                        text = res.text.strip()
                    else:
                        res = client.chat.completions.create(
                            model=model_id,
                            messages=[
                                {"role": "system", "content": system_msg},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.82,
                            max_tokens=420,
                            timeout=35
                        )
                        text = res.choices[0].message.content.strip()

                    if text and len(text) > 80:
                        return text

                except Exception as e:
                    err_str = str(e).lower()
                    logging.warning(f"âš ï¸ {name} ÙØ´Ù„ (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}): {err_str[:80]}...")
                    if any(x in err_str for x in ["429", "limit", "rate", "quota"]):
                        sleep_time = 6 * attempt
                        logging.info(f"   â†’ rate limit â†’ Ù†Ù†ØªØ¸Ø± {sleep_time} Ø«ÙˆØ§Ù†ÙŠ...")
                        time.sleep(sleep_time)
                        continue
                    elif any(x in err_str for x in ["502", "bad gateway", "timeout"]):
                        time.sleep(8)
                        continue
                    else:
                        break

        logging.error("âŒ ÙƒÙ„ Ø§Ù„Ø¹Ù‚ÙˆÙ„ ÙØ´Ù„Øª.")
        return None

    def run(self):
        task = "Ø£Ø¹Ø·Ù†ÙŠ Ø®Ø¨Ø± Ø£Ùˆ Ø£Ø¯Ø§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ÙŠØ§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø§Ù„ÙŠÙˆÙ…."

        raw_output = self.execute_brain_sequence(task)
        if not raw_output:
            logging.warning("Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ ØµØ§Ù„Ø­.")
            return

        # ÙØµÙ„ Ø§Ù„ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯
        image_desc = ""
        content = raw_output

        if "ÙˆØµÙ_ØµÙˆØ±Ø©:" in raw_output:
            parts = raw_output.rsplit("ÙˆØµÙ_ØµÙˆØ±Ø©:", 1)
            content = parts[0].strip()
            image_desc = parts[1].strip()

        if self.already_posted(content):
            logging.info("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ÙƒØ±Ø± â†’ ØªØ¬Ø§ÙˆØ² Ø§Ù„Ù†Ø´Ø±")
            return

        # ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ thread Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø§Ù„ÙØ§ØµÙ„ ---
        tweets = [t.strip() for t in content.split("---") if t.strip()]

        try:
            previous_tweet_id = None
            for i, tweet_text in enumerate(tweets):
                tweet_kwargs = {"text": tweet_text.strip()}

                # ØµÙˆØ±Ø© ÙÙ‚Ø· ÙÙŠ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ ÙˆØµÙ
                if i == 0 and image_desc:
                    logging.info(f"ÙˆØµÙ ØµÙˆØ±Ø© Ù…Ù‚ØªØ±Ø­ Ù„Ù„ØªÙˆÙ„ÙŠØ¯: {image_desc}")
                    # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ Ø±ÙØ¹/ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹

                if previous_tweet_id:
                    tweet_kwargs["in_reply_to_tweet_id"] = previous_tweet_id
                    tweet_kwargs["reply_settings"] = "following"

                response = self.x_client.create_tweet(**tweet_kwargs)
                previous_tweet_id = response.data["id"]
                logging.info(f"ØªÙ… Ù†Ø´Ø± Ø§Ù„ØªØºØ±ÙŠØ¯Ø© {i+1}/{len(tweets)}")

            logging.info("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")


if __name__ == "__main__":
    SovereignUltimateBot().run()
