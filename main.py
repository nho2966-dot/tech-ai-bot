import os, sqlite3, logging, hashlib, time, re, random, json
from datetime import datetime
import tweepy, feedparser
from dotenv import load_dotenv
from openai import OpenAI

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ© ---
load_dotenv()
logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

class TechEliteEnterpriseSystem:
    def __init__(self):
        self._init_db()
        self._init_clients()
        # Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø°Ø±ÙˆØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© (Ø¨ØªÙˆÙ‚ÙŠØªÙƒ Ø§Ù„Ù…Ø­Ù„ÙŠ)
        self.peak_hours = [8, 9, 12, 13, 18, 19, 21, 22] 

    def _init_db(self):
        with sqlite3.connect("news_enterprise_full_2026.db") as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS editorial_memory (content_hash TEXT PRIMARY KEY, summary TEXT, created_at TEXT)")
            conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, keywords TEXT)")

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _is_peak_time(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ù„Ù†Ø´Ø± Ù„Ø±ÙØ¹ Ø§Ù„Ù€ ROI"""
        current_hour = datetime.now().hour
        is_peak = current_hour in self.peak_hours
        if not is_peak:
            logging.info(f"â³ Current hour ({current_hour}) is not peak time. Skipping major posts...")
        return is_peak

    def _generate_ai(self, system_p, user_p, h):
        models = ["qwen/qwen-2.5-72b-instruct", "google/gemini-flash-1.5", "openai/gpt-4o-mini"]
        for model_name in models:
            try:
                r = self.ai_client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "system", "content": system_p}, {"role": "user", "content": user_p}],
                    temperature=0.3, timeout=45
                )
                content = r.choices[0].message.content
                with sqlite3.connect("news_enterprise_full_2026.db") as conn:
                    conn.execute("INSERT OR IGNORE INTO editorial_memory VALUES (?, ?, ?)", (h, content[:50], datetime.now().isoformat()))
                return content
            except Exception as e:
                if "429" in str(e): continue
                logging.error(f"ğŸš¨ Model {model_name} failed: {e}")
        return None

    def run_cycle(self):
        logging.info("ğŸš€ Sovereign Cycle Started")
        
        # 1. Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ© ØªØ¹Ù…Ù„ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ø¹Ø¶ÙˆÙŠ
        self.process_smart_replies()
        
        # 2. Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§ÙÙŠ (Ø§Ù„Ø«Ø±ÙŠØ¯Ø§Øª) Ù„Ø§ ÙŠØªÙ… Ø¥Ù„Ø§ ÙÙŠ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø°Ø±ÙˆØ©
        if self._is_peak_time():
            self.execute_targeted_publishing()
        
        logging.info("ğŸ Cycle Finished")

    # (Ø¨Ù‚ÙŠØ© Ø§Ù„Ø¯ÙˆØ§Ù„: process_smart_replies, execute_targeted_publishing, Ø¥Ù„Ø®... ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚)
