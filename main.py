import os, json, logging, tweepy, time
from openai import OpenAI

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(message)s")

# ====== Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ======
OPENAI_MODEL = "gpt-4o-mini"
STATE_FILE = "state.json"

PERSONA_PROMPT = """
Ø£Ù†Øª ØµØ­ÙÙŠ ØªÙ‚Ù†ÙŠ Ø¹Ø±Ø¨ÙŠ Ù…Ø­ØªØ±Ù.
ØªØ´Ø±Ø­ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ù„ØºØ© Ø¥Ù†Ø³Ø§Ù†ÙŠØ©ØŒ ÙˆØ¯ÙˆØ¯Ø©ØŒ Ø°ÙƒÙŠØ©.
Ù„Ø§ ØªØ¨Ø§Ù„ØºØŒ Ù„Ø§ ØªØ¬Ø²Ù… Ø¨Ø¯ÙˆÙ† Ù…ØµØ¯Ø±.
Ø§Ø¨Ø¯Ø£ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ù€ Hook Ù‚ÙˆÙŠ.
Ø£Ù†Ù‡Ù Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø¨Ø³Ø¤Ø§Ù„ ØªÙØ§Ø¹Ù„ÙŠ.
"""

TREND_TOPICS = [
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "ChatGPT",
    "Meta",
    "Google",
    "OpenAI",
    "ØªØ­Ø¯ÙŠØ«",
    "Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©"
]

# ====== ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª ======
def run_bot():
    logging.info("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ")

    client = tweepy.Client(
        bearer_token=os.environ["X_BEARER_TOKEN"],
        consumer_key=os.environ["X_API_KEY"],
        consumer_secret=os.environ["X_API_SECRET"],
        access_token=os.environ["X_ACCESS_TOKEN"],
        access_token_secret=os.environ["X_ACCESS_SECRET"],
        wait_on_rate_limit=True
    )

    ai = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

    query = "(AI OR ØªÙ‚Ù†ÙŠØ© OR Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ) lang:ar -is:retweet"
    tweets = client.search_recent_tweets(query=query, max_results=5)

    state = load_state()

    for tweet in tweets.data or []:
        if tweet.id in state["replied"]:
            continue

        content = generate_content(ai, tweet.text)
        score = evaluate_content(ai, content)

        if score < 80:
            logging.info(f"â›” ØªÙ… Ø±ÙØ¶ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Score={score})")
            continue

        client.create_tweet(
            text=content,
            in_reply_to_tweet_id=tweet.id
        )

        state["replied"].append(tweet.id)
        save_state(state)
        logging.info(f"âœ… Ù†ÙØ´Ø± Ø¨Ù†Ø¬Ø§Ø­ (Score={score})")
        break

# ====== ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ======
def generate_content(ai, source_text):
    prompt = f"""
{PERSONA_PROMPT}

Ø§Ù„Ù…ØµØ¯Ø±:
{source_text}

Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© Ø£Ùˆ Ø«Ø±ÙŠØ¯ Ù‚ØµÙŠØ± Ø§Ø­ØªØ±Ø§ÙÙŠ.
"""
    res = ai.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content.strip()

# ====== ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ======
def evaluate_content(ai, content):
    prompt = f"""
Ù‚ÙŠÙ‘Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† 100 Ø­Ø³Ø¨:
- Ù‚ÙˆØ© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
- Ø§Ù„Ø¯Ù‚Ø©
- Ø§Ù„Ø£Ù†Ø³Ù†Ø©
- Ø§Ù„ØªÙØ§Ø¹Ù„

Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
{content}

Ø£Ø¹Ø·Ù†ÙŠ Ø±Ù‚Ù…Ù‹Ø§ ÙÙ‚Ø·.
"""
    res = ai.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "user", "content": prompt}]
    )
    try:
        return int(res.choices[0].message.content.strip())
    except:
        return 0

# ====== Ø§Ù„Ø­Ø§Ù„Ø© ======
def load_state():
    if not os.path.exists(STATE_FILE):
        return {"replied": []}
    with open(STATE_FILE, "r") as f:
        return json.load(f)

def save_state(state):
    with open(STATE_FILE, "w") as f:
        json.dump(state, f)

if __name__ == "__main__":
    run_bot()
