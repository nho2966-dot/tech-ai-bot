import os, sqlite3, logging, hashlib, re, time
from datetime import datetime
from urllib.parse import urlparse
import tweepy
from dotenv import load_dotenv
from openai import OpenAI

# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø­ÙˆÙƒÙ…Ø©
load_dotenv()
DB_FILE = "tech_om_sovereign_2026.db"
logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

EDITORIAL_POLICY = {
    "BREAKING": {"min_score": 4, "max_len": 240, "prefix": "ğŸš¨ Ø¹Ø§Ø¬Ù„ ØªÙ‚Ù†ÙŠ"},
    "ANALYSIS": {"min_score": 5, "max_len": 25000, "prefix": "ğŸ§  ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù…Ù‚"},
    "HARVEST":  {"min_score": 5, "max_len": 25000, "prefix": "ğŸ—ï¸ Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"}
}

TRUSTED_SOURCES = ["techcrunch.com", "openai.com", "wired.com", "theverge.com", "bloomberg.com"]

# 2. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø«Ø±ÙŠØ¯Ø§Øª Ø§Ù„Ù†Ø®Ø¨ÙˆÙŠ (Thread & Completion Guard)
class EliteThreadEngine:
    def __init__(self, client_x, ai_client):
        self.x = client_x
        self.ai = ai_client

    def _sanitize_and_guard(self, tweets):
        clean = []
        for t in tweets:
            t = t.strip()
            if len(t) < 45: continue
            if len(t) > 245: t = t[:242] + "..." # Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„Ø§Ù‚ØªØ·Ø§Ø¹
            clean.append(t)
        return clean

    def post_thread(self, raw_content, source_url):
        prompt = "Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø«Ø±ÙŠØ¯ Ø®Ù„ÙŠØ¬ÙŠ (Hook -> Analysis -> Takeaway) Ù…Ø¹ ÙÙˆØ§ØµÙ„ '---'."
        try:
            r = self.ai.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role": "user", "content": raw_content}], temperature=0.5
            )
            tweets = self._sanitize_and_guard(r.choices[0].message.content.split("---"))
            if len(tweets) < 3: return

            # Semantic Hook Guard
            if not re.search(r"(Ù„ÙŠØ´|ÙƒÙŠÙ|ÙˆØ´|Ù‡Ù„|Ø§Ù„Ø³Ø¨Ø¨)", tweets[0]):
                tweets[0] = "ğŸ”¥ Ù„ÙŠØ´ Ù‡Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙŠÙ‡Ù…Ùƒ Ø§Ù„Ø­ÙŠÙ†ØŸ Ø®Ù„Ù‘Ùƒ Ù…Ø¹ÙŠ.. ğŸ‘‡\n\n" + tweets[0]

            prev_id = None
            for i, txt in enumerate(tweets):
                header = "ğŸ§µ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„\n" if i == 0 else f"â†³ {i+1}/{len(tweets)}\n"
                footer = f"\n\nğŸ”— {source_url}" if i == len(tweets)-1 else ""
                
                # Takeaway Guard
                if i == len(tweets)-1 and "ØŸ" not in txt:
                    txt += "\n\nÙˆØ´ Ø±Ø£ÙŠÙƒØŸ ØªØªÙÙ‚ Ø£Ùˆ Ù„Ø§ØŸ ğŸ‘‡"

                time.sleep(1.5 if i == 0 else 0.8)
                res = self.x.create_tweet(text=f"{header}{txt}{footer}", in_reply_to_tweet_id=prev_id)
                prev_id = res.data['id']
            return prev_id
        except Exception as e: logging.error(f"âŒ Ø®Ø·Ø£ Ø«Ø±ÙŠØ¯: {e}")

# 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠ (Reply Engine)
class SmartReplyEngine:
    def __init__(self, client_x, ai_client):
        self.x = client_x
        self.ai = ai_client

    def handle_mentions(self):
        try:
            me = self.x.get_me().data.id
            mentions = self.x.get_users_mentions(id=me, expansions=['author_id'])
            if not mentions.data: return

            with sqlite3.connect(DB_FILE) as conn:
                for tweet in mentions.data:
                    rh = hashlib.sha256(f"{tweet.id}".encode()).hexdigest()
                    if conn.execute("SELECT 1 FROM replies WHERE rh=?", (rh,)).fetchone(): continue

                    prompt = f"Ø±Ø¯ ÙƒØ®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø®Ù„ÙŠØ¬ÙŠ Ø¨Ø§Ø®ØªØµØ§Ø± ÙˆØ°ÙƒØ§Ø¡ Ø¹Ù„Ù‰: '{tweet.text}'. Ø§Ø³ØªØ¹Ù…Ù„ Ù„Ù‡Ø¬Ø© Ø¨ÙŠØ¶Ø§Ø¡ ÙˆØ¥ÙŠÙ…ÙˆØ¬ÙŠ."
                    res = self.ai.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "user", "content": prompt}])
                    
                    self.x.create_tweet(text=res.choices[0].message.content.strip(), in_reply_to_tweet_id=tweet.id)
                    conn.execute("INSERT INTO replies VALUES (?, ?, ?, ?)", (rh, tweet.id, tweet.author_id, datetime.now().isoformat()))
                    logging.info(f"âœ… ØªÙ… Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰: {tweet.id}")
        except Exception as e: logging.error(f"âŒ Ø®Ø·Ø£ Ø±Ø¯ÙˆØ¯: {e}")

# 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Sovereign Engine)
class SovereignEngine:
    def __init__(self):
        self._init_clients()
        self._init_db()
        self.threader = EliteThreadEngine(self.x, self.ai)
        self.replier = SmartReplyEngine(self.x, self.ai)

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS vault (h TEXT PRIMARY KEY, type TEXT, dt TEXT)")
            conn.execute("CREATE TABLE IF NOT EXISTS replies (rh TEXT PRIMARY KEY, tid TEXT, uid TEXT, dt TEXT)")

    def _init_clients(self):
        self.x = tweepy.Client(bearer_token=os.getenv("X_BEARER_TOKEN"), consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"), access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET"))
        self.ai = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def publish_logic(self, raw_data, url, mode="ANALYSIS"):
        # (Ù‡Ù†Ø§ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ AI Ù„Ù„ØªØ­Ø³ÙŠÙ† ÙˆØ§Ù„Ø³ÙƒÙˆØ± ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
        # Ø¥Ø°Ø§ Ø§Ù„Ø³ÙƒÙˆØ± 5 ÙˆØ§Ù„Ù†Ù…Ø· ØªØ­Ù„ÙŠÙ„ØŒ ÙŠØªÙ… ØªØ´ØºÙŠÙ„ self.threader.post_thread
        pass

if __name__ == "__main__":
    bot = SovereignEngine()
    # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø£ÙˆÙ„Ø§Ù‹
    bot.replier.handle_mentions()
    # 2. ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ (Ø«Ø±ÙŠØ¯ ÙƒØ§Ù…Ù„)
    test_news = "Sora 2.0 ÙŠØºÙŠØ± Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØŒ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ ÙŠØµØ¨Ø­ ÙˆØ§Ù‚Ø¹Ø§Ù‹ ÙÙŠ Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬."
    bot.publish_logic(test_news, "techcrunch.com", mode="HARVEST")
