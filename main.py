import os
import asyncio
import random
from datetime import datetime, timezone, timedelta
from loguru import logger
import tweepy
import httpx
from bs4 import BeautifulSoup
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­
# ==========================================
KEYS = {"GROQ": os.getenv("GROQ_API_KEY")}
X_CRED = {
    "consumer_key": os.getenv("X_API_KEY"),
    "consumer_secret": os.getenv("X_API_SECRET"),
    "access_token": os.getenv("X_ACCESS_TOKEN"),
    "access_token_secret": os.getenv("X_ACCESS_SECRET")
}

# Ø¥Ø¹Ø¯Ø§Ø¯ v1.1 Ù„Ø±ÙØ¹ Ø§Ù„Ù…ÙŠØ¯ÙŠØ§ (Ø§Ù„ØµÙˆØ±)
auth_v1 = tweepy.OAuth1UserHandler(
    X_CRED["consumer_key"], X_CRED["consumer_secret"],
    X_CRED["access_token"], X_CRED["access_token_secret"]
)
api_v1 = tweepy.API(auth_v1)

GIANTS_TO_SNIPE = ["44196397", "76837396"] 
TIME_WINDOW_MINUTES = 120

MASTER_RSS_FEEDS = [
    "https://aitnews.com/feed/",                 
    "https://www.tech-wd.com/wd/feed/",          
    "https://www.unlimit-tech.com/feed/",        
    "https://techcrunch.com/category/artificial-intelligence/feed/", 
    "https://www.theverge.com/rss/index.xml",    
    "https://www.wired.com/feed/category/gear/latest/rss", 
    "https://9to5mac.com/feed/"                
]

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36"}
IMG_TEMP_FILE = "temp_news_img.jpg"

# ==========================================
# ğŸ“¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø§Ø¯Ø§Ø± (Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + Ø§Ù„ØµÙˆØ±)
# ==========================================
async def fetch_article_text(url, http_client):
    try:
        response = await http_client.get(url, headers=HEADERS, follow_redirects=True, timeout=15.0)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "html.parser")
            paragraphs = soup.find_all('p')
            return " ".join([p.get_text().strip() for p in paragraphs if len(p.get_text())>20])[:1500]
    except: return ""

async def fetch_latest_tech_news_with_image():
    news_data = {"text": "", "img_url": None}
    selected_feeds = random.sample(MASTER_RSS_FEEDS, min(3, len(MASTER_RSS_FEEDS)))
    
    async with httpx.AsyncClient(timeout=25.0) as client:
        for feed in selected_feeds:
            try:
                response = await client.get(feed, headers=HEADERS)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, "xml")
                    for item in soup.find_all('item', limit=2):
                        title = item.title.text if item.title else ""
                        link = item.link.text if item.link else ""
                        img_url = None
                        
                        media = item.find('media:content')
                        if media: img_url = media.get('url')
                        elif item.description:
                            d_soup = BeautifulSoup(item.description.text, "html.parser")
                            img = d_soup.find('img')
                            if img: img_url = img.get('src')
                        
                        article_text = await fetch_article_text(link, client)
                        if article_text:
                            news_data["text"] += f"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}\nØ§Ù„Ø±Ø§Ø¨Ø·: {link}\nØ§Ù„ØªÙØ§ØµÙŠÙ„: {article_text}\n---\n"
                            if img_url and not news_data["img_url"]: news_data["img_url"] = img_url
            except: continue
    return news_data

# ==========================================
# ğŸ§  Ø¹Ù‚Ù„ "Ø£ÙŠØ¨ÙƒØ³" (Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ø³Ù… Ù„Ù„ØµÙŠØ§ØºØ©)
# ==========================================
async def create_news_tweet(news_context, recent_texts, has_image=False):
    img_hint = " (Ù…Ù„Ø§Ø­Ø¸Ø©: Ø³Ù†Ø±ÙÙ‚ ØµÙˆØ±Ø©ØŒ Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ù…ØªÙ†Ø§ØºÙ…Ø§Ù‹ Ù…Ø¹Ù‡Ø§)" if has_image else ""
    sys_msg = f"""Ø£Ù†Øª "Ø£ÙŠØ¨ÙƒØ³"ØŒ Ù…Ø­Ù„Ù„ ØªÙ‚Ù†ÙŠ Ù…Ø­ØªØ±Ù. 
    Ù…Ù‡Ù…ØªÙƒ: Ø§Ø®ØªØ± Ø®Ø¨Ø±Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙ‚Ø· ÙˆØµÙØºÙ‡ ÙÙŠ Ù‚Ø§Ù„Ø¨ ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø¯ÙˆÙ† Ø°ÙƒØ± Ø§Ø³Ù… Ø§Ù„Ù‚Ø§Ù„Ø¨):

    1. [ØªØºØ±ÙŠØ¯Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ©]: (Ø®Ø·Ø§Ù ØµØ§Ø¯Ù… + Ø²Ø¨Ø¯Ø© Ø§Ù„Ø®Ø¨Ø± + Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±).
    2. [Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø±Ø£ÙŠ - POLL]: Ø§ÙƒØªØ¨ Ù†ØµØ§Ù‹ ÙŠØ«ÙŠØ± Ø§Ù„ÙØ¶ÙˆÙ„ Ø«Ù… Ø£Ù„Ø­Ù‚Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ù€ [POLL: Ø®ÙŠØ§Ø±1, Ø®ÙŠØ§Ø±2].
       âš ï¸ (Ù‚ÙŠØ¯ ØµØ§Ø±Ù…: ÙƒÙ„ Ø®ÙŠØ§Ø± ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ÙƒÙ„Ù…Ø© Ø£Ùˆ ÙƒÙ„Ù…ØªÙŠÙ† ÙÙ‚Ø·ØŒ Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 20 Ø­Ø±ÙØ§Ù‹).
    3. [Ø«Ø±ÙŠØ¯ - Thread]: ÙÙƒÙƒ Ø§Ù„Ø®Ø¨Ø± Ù„Ù€ 3 ØªØºØ±ÙŠØ¯Ø§Øª Ù…Ø±Ù‚Ù…Ø© (1/3ØŒ 2/3ØŒ 3/3).

    âŒ Ù…Ù…Ù†ÙˆØ¹ ØªÙ…Ø§Ù…Ø§Ù‹:
    - Ù„Ø§ ØªØ³Ø±Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ù„Ù„Ù…ØªØ§Ø¨Ø¹.
    - Ù„Ø§ ØªÙ‚Ù„ "Ù„Ø¯ÙŠÙƒ Ø®ÙŠØ§Ø±Ø§Øª" Ø£Ùˆ "Ø£Ø®Ø¨Ø§Ø± Ø¬Ø¯ÙŠØ¯Ø©".
    - Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù†Øµ Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØ¨Ù‚ÙˆØ©.
    - Ø§Ù„Ø±Ø§Ø¨Ø· Ø¯Ø§Ø¦Ù…Ø§Ù‹ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰.
    {img_hint}
    """
    
    prompt = f"Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©:\n{news_context}\nØ§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©: [{recent_texts}]\nØµØº Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¢Ù†:"
    return await generate_ai_content(prompt, sys_msg)

async def generate_ai_content(prompt, system_msg):
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"])
    try:
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="llama-3.3-70b-versatile",
            messages=[{"role":"system","content":system_msg},{"role":"user","content":prompt}],
            temperature=0.6
        )
        return response.choices[0].message.content.strip()
    except: return None

# ==========================================
# ğŸ“¤ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø± Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (Interactive Polls)
# ==========================================
async def publish_smart_content(client_v2, ai_output, media_id=None):
    try:
        # Ø§Ù„Ø«Ø±ÙŠØ¯Ø§Øª
        if "1/3" in ai_output:
            tweets = [t.strip() for t in ai_output.split("\n\n") if len(t.strip()) > 5][:3]
            last_id = None
            for i, text in enumerate(tweets):
                res = client_v2.create_tweet(text=text[:280], media_ids=[media_id] if media_id and i==0 else None, in_reply_to_tweet_id=last_id)
                last_id = res.data['id']
            logger.success("ğŸ§µ ØªÙ… Ù†Ø´Ø± Ø«Ø±ÙŠØ¯.")

        # Ø§Ù„Ø§Ø³ØªØ·Ù„Ø§Ø¹Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© (Ø£Ø²Ø±Ø§Ø± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ù‚Ø±)
        elif "[POLL:" in ai_output:
            parts = ai_output.split("[POLL:")
            main_text = parts[0].strip()
            raw_opts = parts[1].replace("]", "").split(",")
            # Ù‚Øµ Ø¢Ù„ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„Ø£Ø²Ø±Ø§Ø± (ØªÙˆÙŠØªØ± ÙŠØ±ÙØ¶ Ø£ÙƒØ«Ø± Ù…Ù† 25 Ø­Ø±Ù Ù„Ù„Ø®ÙŠØ§Ø±)
            safe_opts = [o.strip()[:25] for o in raw_opts if o.strip()][:4]
            
            if len(safe_opts) >= 2:
                client_v2.create_tweet(
                    text=main_text[:280], 
                    poll_options=safe_opts, 
                    poll_duration_minutes=1440
                )
                logger.success(f"ğŸ“Š ØªÙ… Ù†Ø´Ø± Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø¨Ø£Ø²Ø±Ø§Ø± ØªÙØ§Ø¹Ù„ÙŠØ©: {safe_opts}")
            else:
                client_v2.create_tweet(text=main_text[:280], media_ids=[media_id] if media_id else None)

        # Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
        else:
            client_v2.create_tweet(text=ai_output[:280], media_ids=[media_id] if media_id else None)
            logger.success("ğŸ“ ØªÙ… Ù†Ø´Ø± ØªØºØ±ÙŠØ¯Ø©.")
            
    except Exception as e: logger.error(f"âŒ Ø®Ø·Ø£ Ù†Ø´Ø±: {e}")

# ==========================================
# ğŸ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ==========================================
async def bot_cycle():
    client_v2 = tweepy.Client(**X_CRED)
    try: bot_id = client_v2.get_me().data.id
    except: return

    recent_txt = ""
    try:
        recent = client_v2.get_users_tweets(id=bot_id, max_results=10)
        if recent.data: recent_txt = " | ".join([t.text for t in recent.data])
    except: pass

    news_data = await fetch_latest_tech_news_with_image()
    if news_data["text"]:
        ai_msg = await create_news_tweet(news_data["text"], recent_txt, bool(news_data["img_url"]))
        
        if ai_msg and "SKIP" not in ai_msg.upper():
            mid = None
            if news_data["img_url"]:
                try:
                    async with httpx.AsyncClient() as c:
                        r = await c.get(news_data["img_url"])
                        with open(IMG_TEMP_FILE, 'wb') as f: f.write(r.content)
                        mid = api_v1.media_upload(filename=IMG_TEMP_FILE).media_id
                        os.remove(IMG_TEMP_FILE)
                except: pass
            await publish_smart_content(client_v2, ai_msg, mid)

if __name__ == "__main__":
    asyncio.run(bot_cycle())
