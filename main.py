import os
import json
import time
import logging
import tweepy
import yaml
from openai import OpenAI
from datetime import datetime

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(message)s")

class TechExpertProFinal:
    def __init__(self):
        logging.info("--- Tech Expert Pro [Hybrid Mode Activated] ---")
        
        # 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (ØªØ¹Ù…Ù„ Ø¥Ø°Ø§ ÙÙÙ‚Ø¯ Ù…Ù„Ù YAML)
        self.config = {
            'content': {
                'system_instruction': (
                    "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø¹Ø±Ø¨ÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯: "
                    "1. Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© ÙÙ‚Ø·. "
                    "2. Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ ØªÙØ§Ø¹Ù„ÙŠ ÙˆÙ…Ø«ÙŠØ± ÙˆØºÙŠØ± Ø¬Ø§Ù. "
                    "3. Ø§Ù„Ù…Ø¯ Ø¨Ø§Ù„ÙˆØ§Ùˆ ÙŠØªØ·Ù„Ø¨ Ø¶Ù… Ø§Ù„Ø´ÙØªÙŠÙ† Ø¬ÙŠØ¯Ø§Ù‹ (Ù…Ø«Ø§Ù„: Ø­Ø§Ø³ÙˆØ¨ØŒ ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§)."
                )
            },
            'api': {
                'openrouter_model': "qwen/qwen-2.5-72b-instruct",
                'reply_model': "openai/gpt-4o-mini"
            },
            'paths': {'state_file': "state.json"}
        }

        # 2. Ù…Ø­Ø§ÙˆÙ„Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
        base_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(base_dir, "config.yaml")
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    ext_cfg = yaml.safe_load(f)
                    if ext_cfg:
                        self.config.update(ext_cfg)
                        logging.info(f"âœ… ØªÙ… Ø¯Ù…Ø¬ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù†: {config_path}")
            except Exception as e:
                logging.warning(f"âš ï¸ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØŒ Ø³Ø£Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: {e}")
        else:
            logging.info("â„¹ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ config.yamlØŒ Ø³Ø£Ø¹Ù…Ù„ Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©.")

        # 3. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª (X Ùˆ AI)
        try:
            self.ai_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=os.environ.get("OPENROUTER_API_KEY")
            )
            
            # Ù…ÙØ§ØªÙŠØ­ X
            api_key = os.environ.get("X_API_KEY")
            api_secret = os.environ.get("X_API_SECRET")
            access_token = os.environ.get("X_ACCESS_TOKEN")
            access_secret = os.environ.get("X_ACCESS_SECRET")

            self.client_v2 = tweepy.Client(
                consumer_key=api_key, consumer_secret=api_secret,
                access_token=access_token, access_token_secret=access_secret
            )
            auth = tweepy.OAuth1UserHandler(api_key, api_secret, access_token, access_secret)
            self.api_v1 = tweepy.API(auth)
            
            self.state_path = os.path.join(base_dir, self.config['paths']['state_file'])
            self.state = self._load_state()
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­: {e}")
            raise

    def _load_state(self):
        if os.path.exists(self.state_path):
            try:
                with open(self.state_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except: pass
        return {"replied_to": [], "rotation_idx": 0}

    def run(self):
        try:
            logging.info(f"ğŸ•’ ØªÙˆÙ‚ÙŠØª Ø§Ù„ØªØ´ØºÙŠÙ„ (UTC): {datetime.utcnow()}")
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØºØ±ÙŠØ¯Ø§Øª Ù„Ø±Ø¯ Ø°ÙƒÙŠ
            query = "ØªÙ‚Ù†ÙŠØ© OR Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ lang:ar -is:retweet"
            tweets = self.client_v2.search_recent_tweets(query=query, max_results=5)
            
            if tweets.data:
                for tweet in tweets.data:
                    if tweet.id in self.state.get("replied_to", []): continue
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ø¨Ø°ÙƒØ§Ø¡
                    res = self.ai_client.chat.completions.create(
                        model=self.config['api']['reply_model'],
                        messages=[
                            {"role": "system", "content": self.config['content']['system_instruction']},
                            {"role": "user", "content": f"Ø±Ø¯ Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø®Ø¨ÙŠØ±: {tweet.text}"}
                        ]
                    )
                    reply = res.choices[0].message.content.strip()
                    
                    # Ø§Ù„Ø±Ø¯ Ø§Ù„ÙØ¹Ù„ÙŠ
                    self.api_v1.update_status(
                        status=reply[:280], 
                        in_reply_to_status_id=tweet.id, 
                        auto_populate_reply_metadata=True
                    )
                    self.state.setdefault("replied_to", []).append(tweet.id)
                    logging.info(f"âœ… ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©: {tweet.id}")
                    break # Ø±Ø¯ ÙˆØ§Ø­Ø¯ ÙÙŠ ÙƒÙ„ Ø¯ÙˆØ±Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ø¸Ø±
            
            # Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©
            with open(self.state_path, 'w', encoding='utf-8') as f:
                json.dump(self.state, f, ensure_ascii=False)
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„: {e}")

if __name__ == "__main__":
    TechExpertProFinal().run()
