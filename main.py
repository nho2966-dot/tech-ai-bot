import os, sqlite3, logging, hashlib, time, re, random
import tweepy, feedparser
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
DB_FILE = "news.db"

# ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù…Ø­Ø±Ø± Ø§Ù„ØªÙ‚Ù†ÙŠ (ÙˆØ¶Ø¹ Ø§Ù„ØªÙ‡Ø¯Ø¦Ø© ÙˆØ§Ù„ÙˆØ¯)
STRICT_FRIENDLY_PROMPT = """
Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± (TechElite)ØŒ Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ ÙˆØ¯ÙˆØ¯. ØµÙØº Ø«Ø±ÙŠØ¯Ø§Ù‹ Ù…Ù…ØªØ¹Ø§Ù‹ ÙˆØ±ØµÙŠÙ†Ø§Ù‹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ.
Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
1. ÙŠÙ…Ù†Ø¹ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£ÙŠ Ø±Ù…ÙˆØ² ØµÙŠÙ†ÙŠØ© Ø£Ùˆ Ù„ØºØ§Øª ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø©.
2. Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© ÙˆØ¯ÙˆØ¯Ø© ÙˆØ³Ù„Ø³Ø© Ù…Ø¹ ÙˆØ¶Ø¹ Ø§Ù„Ù…ØµØ·Ù„Ø­ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† (Term).
3. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:
[TWEET_1]: Ø§ÙØªØªØ§Ø­ÙŠØ© Ø¬Ø°Ø§Ø¨Ø© ØªØ´Ø±Ø­ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ.
[TWEET_2]: ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© (Technical Specs) Ù…Ø¨Ø³Ø·Ø©.
[POLL_QUESTION]: Ø³Ø¤Ø§Ù„ Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø±Ø£ÙŠ (Poll) Ø°ÙƒÙŠ (Ø£Ù‚Ù„ Ù…Ù† 80 Ø­Ø±ÙØ§Ù‹).
[POLL_OPTIONS]: Ø®ÙŠØ§Ø±Ø§Ù† Ø£Ùˆ 3 Ø®ÙŠØ§Ø±Ø§ØªØŒ Ù…ÙØµÙˆÙ„Ø© Ø¨Ø´Ø±Ø·Ø© (Ù…Ø«Ù„Ø§Ù‹: Ø±Ø§Ø¦Ø¹ Ø¬Ø¯Ø§Ù‹ - Ù„Ø§ Ø£Ø­ØªØ§Ø¬Ù‡).
"""

class TechEliteFinal:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")
        conn.commit(); conn.close()

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _is_clean_text(self, text):
        if re.search(r'[\u4e00-\u9fff]', text): return False
        return True

    def _generate_ai(self, context):
        try:
            r = self.ai_client.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role":"system","content":STRICT_FRIENDLY_PROMPT},{"role":"user","content":context}],
                temperature=0.1
            )
            content = r.choices[0].message.content.strip()
            return content if self._is_clean_text(content) else None
        except: return None

    def post_thread(self, ai_text, url):
        t1 = re.search(r'\[TWEET_1\](.*?)(?=\[|$)', ai_text, re.S)
        t2 = re.search(r'\[TWEET_2\](.*?)(?=\[|$)', ai_text, re.S)
        p_q = re.search(r'\[POLL_QUESTION\](.*?)(?=\[|$)', ai_text, re.S)
        p_o = re.search(r'\[POLL_OPTIONS\](.*?)(?=\[|$)', ai_text, re.S)

        if not (t1 and t2 and p_q and p_o): return False

        tweets_data = [
            {"text": f"1/ {t1.group(1).strip()}"[:278]},
            {"text": f"2/ {t2.group(1).strip()}\n\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: {url}"[:278]},
            {"text": f"3/ Ø±Ø£ÙŠÙƒÙ… ÙŠÙ‡Ù…Ù†Ø§: {p_q.group(1).strip()}"[:278], "is_poll": True}
        ]

        last_id = None
        for i, item in enumerate(tweets_data):
            retries = 0
            while retries < 3:
                try:
                    if item.get("is_poll"):
                        options = [o.strip() for o in p_o.group(1).split('-') if o.strip()][:4]
                        res = self.x_client.create_tweet(text=item["text"], poll_options=options, poll_duration_minutes=1440, in_reply_to_tweet_id=last_id)
                    else:
                        res = self.x_client.create_tweet(text=item["text"], in_reply_to_tweet_id=last_id)
                    
                    last_id = res.data["id"]
                    time.sleep(60) # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ø¯Ù‚ÙŠÙ‚Ø© ÙƒØ§Ù…Ù„Ø© Ø¨ÙŠÙ† ØªØºØ±ÙŠØ¯Ø§Øª Ø§Ù„Ø«Ø±ÙŠØ¯ Ø§Ù„ÙˆØ§Ø­Ø¯
                    break
                except tweepy.TooManyRequests:
                    retries += 1
                    wait = 300 * retries # ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ø®Ø·Ø£ØŒ ÙŠÙ†ØªØ¸Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø«Ù… 10 Ø¯Ù‚Ø§Ø¦Ù‚
                    logging.warning(f"âš ï¸ Ø¶ØºØ· Ø¹Ø§Ù„ÙŠØŒ Ø³Ø£Ù†ØªØ¸Ø± {wait} Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ù‡Ø¯ÙˆØ¡...")
                    time.sleep(wait)
                except Exception as e:
                    logging.error(f"âŒ Ø®Ø·Ø£: {e}"); return False
        return True

    def run_cycle(self):
        SOURCES = [
            "https://venturebeat.com/category/ai/feed/", "https://openai.com/news/rss.xml",
            "https://9to5mac.com/feed/", "https://techcrunch.com/feed/",
            "https://www.theverge.com/rss/index.xml"
        ]
        random.shuffle(SOURCES)
        published = 0
        max_per_cycle = 1 # Ø®Ø¨Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· ÙÙŠ ÙƒÙ„ Ø¯ÙˆØ±Ø© (ÙƒÙ„ 8 Ø³Ø§Ø¹Ø§Øª) Ù„ÙÙƒ Ø§Ù„Ø­Ø¸Ø±

        for url in SOURCES:
            if published >= max_per_cycle: break
            feed = feedparser.parse(url)
            for e in feed.entries[:3]:
                if published >= max_per_cycle: break
                h = hashlib.sha256(e.title.encode()).hexdigest()
                conn = sqlite3.connect(DB_FILE)
                if not conn.execute("SELECT 1 FROM news WHERE hash=?", (h,)).fetchone():
                    ai_text = self._generate_ai(f"Title: {e.title}\nSummary: {getattr(e, 'summary', '')}")
                    if ai_text and self.post_thread(ai_text, e.link):
                        conn.execute("INSERT INTO news VALUES (?, ?, ?)", (h, e.title, datetime.now().isoformat()))
                        conn.commit(); published += 1
                conn.close()

if __name__ == "__main__":
    TechEliteFinal().run_cycle()
