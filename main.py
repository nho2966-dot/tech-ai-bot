import os
import re
import asyncio
import random
import sqlite3
import tweepy
import httpx
import telegram
from datetime import datetime
from loguru import logger
from google import genai
from openai import OpenAI
from bs4 import BeautifulSoup

# ==========================================
# โ๏ธ ุงูุฑุจุท ุงููุจุงุดุฑ ูุน ุงูู Secrets (ุญุณุจ ุงูุตูุฑุฉ)
# ==========================================
KEYS = {
    "GEMINI": os.getenv("GEMINI_KEY"),
    "OPENAI": os.getenv("OPENAI_API_KEY"),
    "GROQ": os.getenv("GROQ_API_KEY"),
    "XAI": os.getenv("XAI_API_KEY")
}

X_CRED = {
    "ck": os.getenv("X_API_KEY"),
    "cs": os.getenv("X_API_SECRET"),
    "at": os.getenv("X_ACCESS_TOKEN"),
    "ts": os.getenv("X_ACCESS_SECRET")
}

TG_CONFIG = {
    "token": os.getenv("TG_TOKEN"),
    "chat_id": os.getenv("TELEGRAM_CHAT_ID")
}

# ==========================================
# ๐ง ูุญุฑู ุงูุนููู ุงูุฐูู (ุงูุชุจุฏูู ุงูุชููุงุฆู)
# ==========================================
async def smart_fetch_content(prompt):
    # ูุงุฆูุฉ ุงูุนููู ุงููุชุงุญุฉ ูู ุงูู Secrets ุนูุฏู
    brains = [
        ("Gemini", lambda p: genai.Client(api_key=KEYS["GEMINI"]).models.generate_content(model="gemini-2.0-flash", contents=p).text),
        ("OpenAI", lambda p: OpenAI(api_key=KEYS["OPENAI"]).chat.completions.create(model="gpt-4o", messages=[{"role":"user","content":p}]).choices[0].message.content),
        ("Groq", lambda p: OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"]).chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role":"user","content":p}]).choices[0].message.content)
    ]
    
    for name, func in brains:
        try:
            logger.info(f"๐ ูุญุงููุฉ ุงูุชูููุฏ ุนุจุฑ ุนูู: {name}")
            content = await asyncio.to_thread(func, prompt)
            if content and len(content) > 10:
                return content, name
        except Exception as e:
            logger.warning(f"โ๏ธ {name} ูุดู: {e}")
            continue

    # ๐ก๏ธ ุจุฑูุชูููู ุงูุทูุงุฑุฆ (ูู ุงููุทุนุช ูู ุงูุณุจู)
    return "ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุฃุฏูุงุชู ุงูุญุฏูุซุฉ ูู ุงูููุฉ ุงููุงุฏูุฉ ููุฃูุฑุงุฏุ ุงูุชุจูู ุงููุจูุฑ ูุนูู ูุฑุตุงู ูุง ุญุฏูุฏ ููุง ูู ุงูุฅูุชุงุฌูุฉ ูุงูุฅุจุฏุงุน. (ุชุญุฏูุซ ุชููู ุตุงุฏุฑ ุนู ุฃูุจูุณ).", "Emergency_System"

# ==========================================
# ๐ ุงููููุฉ ุงูุฑุฆูุณูุฉ
# ==========================================
async def apex_mission():
    try:
        api_v2 = tweepy.Client(consumer_key=X_CRED["ck"], consumer_secret=X_CRED["cs"],
                               access_token=X_CRED["at"], access_token_secret=X_CRED["ts"])
        
        headline = "ุฃุญุฏุซ ุชูููุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ููุฃูุฑุงุฏ 2026"
        prompt = f"ุฃูุช ุฃูุจูุณุ ุฎุจูุฑ ุชููู ุฎููุฌู. ุตุบ ุณุจูุงู ุตุญููุงู ูุฎูุงู ุนู: {headline}. ุฑูุฒ ุนูู ุงููุงุฆุฏุฉ ุงูุดุฎุตูุฉ."
        
        content, brain_used = await smart_fetch_content(prompt)
        final_post = f"๐ข [ุฃูุจูุณ ุงูุชููู]\n\n{content}\n\n#ุฐูุงุก_ุงุตุทูุงุนู #ุฃุฏูุงุช_ุงูุฐูุงุก_ุงูุงุตุทูุงุนู"
        
        # ุงููุดุฑ ุนูู X
        api_v2.create_tweet(text=final_post)
        logger.success(f"๐ฅ ุชู ุงููุดุฑ ุจูุฌุงุญ ุจูุงุณุทุฉ {brain_used}")

        # ุฅุฑุณุงู ุชููุฌุฑุงู
        if TG_CONFIG["token"]:
            try:
                bot = telegram.Bot(token=TG_CONFIG["token"])
                await bot.send_message(chat_id=TG_CONFIG["chat_id"], text=final_post)
            except: logger.warning("โ๏ธ ุชููุฌุฑุงู ูู ูุฑุณู (ุชุญูู ูู ุถุบุท Start)")

    except Exception as e:
        logger.error(f"๐จ ุฎุทุฃ: {e}")

if __name__ == "__main__":
    asyncio.run(apex_mission())
