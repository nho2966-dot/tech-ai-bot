import os, sqlite3, logging, hashlib, time, re, random
import tweepy, feedparser
from datetime import datetime, timedelta
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
DB_FILE = "news.db"

# Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù…Ù†Ø¹ Ø§Ù„Ù‡Ù„ÙˆØ³Ø© ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
STRICT_AUTHORITY_PROMPT = """
Ø£Ù†Øª Ù…Ø­Ø±Ø± ØªÙ‚Ù†ÙŠ ÙÙŠ (TechElite). ØµÙØº Ø«Ø±ÙŠØ¯Ø§Ù‹ ØªÙ‚Ù†ÙŠØ§Ù‹ Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±ÙÙ‚ ÙÙ‚Ø·.
Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØµØ§Ø±Ù…Ø©:
1. ÙŠÙ…Ù†Ø¹ Ø¥Ø¶Ø§ÙØ© Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© (Ø£Ø±Ù‚Ø§Ù…ØŒ ØªÙˆØ§Ø±ÙŠØ®ØŒ Ø£Ø³Ù…Ø§Ø¡) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ.
2. Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ØªÙƒØªØ¨ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† (Term) Ø¨Ø¬Ø§Ù†Ø¨ Ù…Ø¹Ù†Ø§Ù‡Ø§ Ø§Ù„Ø¹Ø±Ø¨ÙŠ.
3. ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ù‚ØªØ·Ø§Ø¹Ø› ÙˆØ²Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ:

[TWEET_1]: Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ù„Ù„Ø®Ø¨Ø± Ø¨Ø£Ø³Ù„ÙˆØ¨ "Ø®Ø·Ø§Ù" Ø±ØµÙŠÙ† ÙˆØ¬Ø°Ø§Ø¨.
[TWEET_2]: ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© Ø­Ø±ÙÙŠØ© Ù…ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø§Ù„Ù†Øµ (Ø£Ø±Ù‚Ø§Ù…ØŒ Ù…ÙŠØ²Ø§Øª).
[TWEET_3]: Ø³Ø¤Ø§Ù„ ØªÙ‚Ù†ÙŠ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…ØªØ§Ø¨Ø¹ÙŠÙ† Ù…Ø´ØªÙ‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø®Ø¨Ø± ÙÙ‚Ø·.
"""

class TechEliteAuthority:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()
        self.my_id = None

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("""
        CREATE TABLE IF NOT EXISTS news (
            hash TEXT PRIMARY KEY,
            title TEXT,
            published_at TEXT
        )
        """)
        conn.commit()
        conn.close()

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY")
        )

    def _generate_ai(self, prompt, context):
        try:
            r = self.ai_client.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role":"system","content":prompt},{"role":"user","content":context}],
                temperature=0.1, # ØµØ±Ø§Ù…Ø© ØªØ§Ù…Ø© Ø¶Ø¯ Ø§Ù„Ù‡Ù„ÙˆØ³Ø©
                max_tokens=700
            )
            return r.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"AI Error: {e}")
            return None

    def is_recycled_news(self, title):
        conn = sqlite3.connect(DB_FILE)
        # ÙØ­Øµ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙÙŠ Ø¢Ø®Ø± ÙŠÙˆÙ…ÙŠÙ† Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
        cutoff = (datetime.now() - timedelta(days=2)).isoformat()
        rows = conn.execute("SELECT title FROM news WHERE published_at > ?", (cutoff,)).fetchall()
        conn.close()
        
        t_clean = re.sub(r'\W+', '', title.lower())
        for (old_title,) in rows:
            if re.sub(r'\W+', '', old_title.lower()) == t_clean:
                return True
        return False

    def post_thread(self, ai_text, url):
        blocks = {}
        current = None
        for line in ai_text.splitlines():
            if line.startswith("[TWEET_"):
                current = line.split("]")[0].strip("[]")
                blocks[current] = []
            elif current and line.strip():
                blocks[current].append(line.strip())
        
        tweets = [" ".join(blocks[k]) for k in ["TWEET_1", "TWEET_2", "TWEET_3"] if k in blocks]
        if not tweets: return False

        footer = f"ğŸ”— Ø§Ù„Ù…ØµØ¯Ø±:\n{url}\n\nğŸ›¡ï¸ Ø±ØµØ¯ TechElite"
        tweets.append(footer)

        last_id = None
        for i, t in enumerate(tweets):
            try:
                prefix = f"{i+1}/ " if i < len(tweets)-1 else ""
                res = self.x_client.create_tweet(text=f"{prefix}{t}"[:278], in_reply_to_tweet_id=last_id)
                last_id = res.data["id"]
                time.sleep(15) # ÙØ§ØµÙ„ Ø¨ÙŠÙ† Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª
            except Exception as e:
                logging.error(f"Tweet Error: {e}")
                break
        return True

    def handle_mentions(self):
        try:
            if not self.my_id:
                self.my_id = str(self.x_client.get_me().data.id)
            mentions = self.x_client.get_users_mentions(id=self.my_id, max_results=5)
            if not mentions.data: return

            conn = sqlite3.connect(DB_FILE)
            for tweet in mentions.data:
                h = f"reply_{tweet.id}"
                if conn.execute("SELECT 1 FROM news WHERE hash=?", (h,)).fetchone(): continue
                
                reply_text = self._generate_ai("Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø±ØµÙŠÙ†. Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø§Ù„Ù…Ø±ÙÙ‚ Ø¨ÙˆÙ‚Ø§Ø± ÙˆØ¯ÙˆÙ† Ù‡Ù„ÙˆØ³Ø© ÙˆØ¨Ø§Ø®ØªØµØ§Ø±.", tweet.text)
                if reply_text:
                    self.x_client.create_tweet(text=reply_text[:278], in_reply_to_tweet_id=tweet.id)
                    conn.execute("INSERT INTO news VALUES (?, ?, ?)", (h, "reply", datetime.now().isoformat()))
                    conn.commit()
            conn.close()
        except Exception as e: logging.error(f"Mentions Error: {e}")

    def run_cycle(self):
        self.handle_mentions()
        
        count = 0
        sources = ["https://www.theverge.com/rss/index.xml", "https://9to5mac.com/feed/", "https://techcrunch.com/feed/"]
        random.shuffle(sources)

        for url in sources:
            if count >= 2: break
            feed = feedparser.parse(url)
            for e in feed.entries[:5]:
                if count >= 2: break
                
                if self.is_recycled_news(e.title): continue
                
                h = hashlib.sha256(e.title.encode()).hexdigest()
                conn = sqlite3.connect(DB_FILE)
                if not conn.execute("SELECT 1 FROM news WHERE hash=?", (h,)).fetchone():
                    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©
                    context = f"Title: {e.title}\nDetails: {getattr(e, 'summary', '')}"
                    ai_content = self._generate_ai(STRICT_AUTHORITY_PROMPT, context)
                    
                    if ai_content and self.post_thread(ai_content, e.link):
                        conn.execute("INSERT INTO news VALUES (?, ?, ?)", (h, e.title, datetime.now().isoformat()))
                        conn.commit()
                        count += 1
                        time.sleep(60) # ÙØ§ØµÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø®Ø¨Ø±ÙŠÙ†
                conn.close()

if __name__ == "__main__":
    TechEliteAuthority().run_cycle()
