import os
import asyncio
import random
from datetime import datetime, timezone, timedelta
from loguru import logger
import tweepy
import httpx
from bs4 import BeautifulSoup
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­
# ==========================================
KEYS = {"GROQ": os.getenv("GROQ_API_KEY")}
X_CRED = {
    "consumer_key": os.getenv("X_API_KEY"),
    "consumer_secret": os.getenv("X_API_SECRET"),
    "access_token": os.getenv("X_ACCESS_TOKEN"),
    "access_token_secret": os.getenv("X_ACCESS_SECRET")
}

# Ø¥Ø¹Ø¯Ø§Ø¯ v1.1 Ù„Ø±ÙØ¹ Ø§Ù„Ù…ÙŠØ¯ÙŠØ§ (Ø§Ù„ØµÙˆØ±)
auth_v1 = tweepy.OAuth1UserHandler(
    X_CRED["consumer_key"], X_CRED["consumer_secret"],
    X_CRED["access_token"], X_CRED["access_token_secret"]
)
api_v1 = tweepy.API(auth_v1)

GIANTS_TO_SNIPE = ["44196397", "76837396"] 
TIME_WINDOW_MINUTES = 120

MASTER_RSS_FEEDS = [
    "https://aitnews.com/feed/",                 
    "https://www.tech-wd.com/wd/feed/",          
    "https://www.unlimit-tech.com/feed/",        
    "https://techcrunch.com/category/artificial-intelligence/feed/", 
    "https://www.theverge.com/rss/index.xml",    
    "https://www.wired.com/feed/category/gear/latest/rss", 
    "https://9to5mac.com/feed/"                
]

HEADERS = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36"}
IMG_TEMP_FILE = "temp_news_img.jpg"

# ==========================================
# ğŸ“¡ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø§Ø¯Ø§Ø± (Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + Ø§Ù„ØµÙˆØ±)
# ==========================================
async def fetch_article_text(url, http_client):
    try:
        response = await http_client.get(url, headers=HEADERS, follow_redirects=True, timeout=15.0)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "html.parser")
            paragraphs = soup.find_all('p')
            return " ".join([p.get_text().strip() for p in paragraphs if len(p.get_text())>20])[:1500]
    except: return ""

async def fetch_latest_tech_news_with_image():
    news_data = {"text": "", "img_url": None}
    selected_feeds = random.sample(MASTER_RSS_FEEDS, min(3, len(MASTER_RSS_FEEDS)))
    
    async with httpx.AsyncClient(timeout=25.0) as client:
        for feed in selected_feeds:
            try:
                response = await client.get(feed, headers=HEADERS)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.content, "xml")
                    for item in soup.find_all('item', limit=2):
                        title = item.title.text if item.title else ""
                        link = item.link.text if item.link else ""
                        img_url = None
                        
                        media = item.find('media:content')
                        if media: img_url = media.get('url')
                        elif item.description:
                            d_soup = BeautifulSoup(item.description.text, "html.parser")
                            img = d_soup.find('img')
                            if img: img_url = img.get('src')
                        
                        article_text = await fetch_article_text(link, client)
                        if article_text:
                            news_data["text"] += f"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}\nØ§Ù„Ø±Ø§Ø¨Ø·: {link}\nØ§Ù„ØªÙØ§ØµÙŠÙ„: {article_text}\n---\n"
                            if img_url and not news_data["img_url"]: news_data["img_url"] = img_url
            except: continue
    return news_data

# ==========================================
# ğŸ§  Ø¹Ù‚Ù„ "Ø£ÙŠØ¨ÙƒØ³" (Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ)
# ==========================================
async def generate_ai_content(prompt, system_msg):
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"])
    try:
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="llama-3.3-70b-versatile",
            messages=[{"role":"system","content":system_msg},{"role":"user","content":prompt}],
            temperature=0.6
        )
        return response.choices[0].message.content.strip()
    except: return None

async def create_news_tweet(news_context, recent_texts, has_image=False):
    img_hint = " (Ù…Ù„Ø§Ø­Ø¸Ø©: Ø³Ù†Ø±ÙÙ‚ ØµÙˆØ±Ø©ØŒ Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ù…ØªÙ†Ø§ØºÙ…Ø§Ù‹ Ù…Ø¹Ù‡Ø§ Ø¨Ø°ÙƒØ§Ø¡)" if has_image else ""
    sys_msg = f"""Ø£Ù†Øª "Ø£ÙŠØ¨ÙƒØ³"ØŒ Ù…Ø­Ù„Ù„ ØªÙ‚Ù†ÙŠ Ø®Ù„ÙŠØ¬ÙŠ Ù…Ø­ØªØ±Ù ÙˆØµØ§Ù†Ø¹ Ù…Ø­ØªÙˆÙ‰ Ø¬Ø°Ø§Ø¨ Ø¹Ù„Ù‰ X.
    ğŸš« Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©: [{recent_texts}]

    ğŸ§© Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù„Ø£Ø«Ø± Ø§Ù„ØªÙ‚Ù†ÙŠ:
    1. [Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ø¹Ù…ÙŠÙ‚]: Ø®Ø·Ø§Ù ØµØ§Ø¯Ù… + Ø§Ù„ØªØ­Ù„ÙŠÙ„ + Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±.
    2. [Ø§Ù„Ø¬Ø¯Ù„ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ - POLL]: Ø§Ø·Ø±Ø­ Ù‚Ø¶ÙŠØ© ØªÙ‚Ù†ÙŠØ© + Ø«Ù… Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„ Ø¨Ø§Ù„ØµÙŠØºØ©: [POLL: Ø®ÙŠØ§Ø±1, Ø®ÙŠØ§Ø±2].
       âš ï¸ (Ù‚ÙŠØ¯ ØµØ§Ø±Ù…: ÙƒÙ„ Ø®ÙŠØ§Ø± ÙŠØ¬Ø¨ Ø£Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 20 Ø­Ø±ÙØ§Ù‹ ÙÙ‚Ø·).
    3. [Ø§Ù„Ø«Ø±ÙŠØ¯ Ø§Ù„Ù…Ù…ØªØ¹ - Thread]: ÙÙƒÙƒ Ø§Ù„Ø®Ø¨Ø± Ù„Ù€ 3 ØªØºØ±ÙŠØ¯Ø§Øª (1/3ØŒ 2/3ØŒ 3/3) ØªØ´Ø±Ø­ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„.

    ğŸ’ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
    - Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø± ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¸Ù‡Ø± ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù†Øµ/Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰.
    - Ø§Ø¨ØªØ¹Ø¯ Ø¹Ù† Ø§Ù„Ø³Ø±Ø¯ Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ› Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù‚Ø§Ø±Ø¦ ÙŠØ´Ø¹Ø± Ø£Ù†Ùƒ ØªÙƒØªØ¨ Ù„Ù‡ Ø´Ø®ØµÙŠØ§Ù‹.
    - Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø®Ø¨Ø±Ø§Ù‹ ÙŠØ³ØªØ­Ù‚ØŒ Ø§ÙƒØªØ¨: SKIP
    {img_hint}
    """
    return await generate_ai_content(f"Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠØ©:\n{news_context}", sys_msg)

# ==========================================
# ğŸ“¤ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø°ÙƒÙŠ (Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©)
# ==========================================
async def publish_smart_content(client_v2, ai_output, media_id=None):
    try:
        if "1/3" in ai_output:
            tweets = [t.strip() for t in ai_output.split("\n\n") if len(t.strip()) > 5][:3]
            last_id = None
            for i, text in enumerate(tweets):
                res = client_v2.create_tweet(text=text[:280], media_ids=[media_id] if media_id and i==0 else None, in_reply_to_tweet_id=last_id)
                last_id = res.data['id']
            logger.success("ğŸ§µ ØªÙ… Ù†Ø´Ø± Ø«Ø±ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­.")

        elif "[POLL:" in ai_output:
            parts = ai_output.split("[POLL:")
            main_text = parts[0].strip()
            # Ø¥ØµÙ„Ø§Ø­ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ·Ù„Ø§Ø¹ (Ù‚Øµ Ø¢Ù„ÙŠ Ù„Ù€ 25 Ø­Ø±Ù)
            raw_opts = parts[1].replace("]", "").split(",")
            safe_opts = [o.strip()[:25] for o in raw_opts if o.strip()][:4]
            
            if len(safe_opts) >= 2:
                client_v2.create_tweet(text=main_text[:280], poll_options=safe_opts, poll_duration_minutes=1440)
                logger.success(f"ğŸ“Š ØªÙ… Ù†Ø´Ø± Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø¢Ù…Ù†: {safe_opts}")
            else:
                client_v2.create_tweet(text=main_text[:280], media_ids=[media_id] if media_id else None)
                logger.warning("âš ï¸ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ·Ù„Ø§Ø¹ ØºÙŠØ± ØµØ§Ù„Ø­Ø©ØŒ ØªÙ… Ø§Ù„Ù†Ø´Ø± ÙƒÙ†Øµ.")

        else:
            client_v2.create_tweet(text=ai_output[:280], media_ids=[media_id] if media_id else None)
            logger.success("ğŸ“ ØªÙ… Ù†Ø´Ø± ØªØºØ±ÙŠØ¯Ø© Ø¹Ø§Ø¯ÙŠØ©.")
            
    except Exception as e: logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {e}")

# ==========================================
# ğŸ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨ÙˆØª
# ==========================================
async def bot_cycle():
    logger.info("ğŸš€ ØªØ´ØºÙŠÙ„ Ø£ÙŠØ¨ÙƒØ³...")
    client_v2 = tweepy.Client(**X_CRED)
    try: 
        bot_id = client_v2.get_me().data.id
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ØªÙˆÙŠØªØ±: {e}")
        return

    # Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
    recent_txt = ""
    try:
        recent = client_v2.get_users_tweets(id=bot_id, max_results=10)
        if recent.data: recent_txt = " | ".join([t.text for t in recent.data])
    except: pass

    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø§Ø¯Ø§Ø±
    news_data = await fetch_latest_tech_news_with_image()
    if news_data["text"]:
        ai_msg = await create_news_tweet(news_data["text"], recent_txt, bool(news_data["img_url"]))
        
        if ai_msg and "SKIP" not in ai_msg.upper():
            mid = None
            if news_data["img_url"]:
                try:
                    async with httpx.AsyncClient() as c:
                        r = await c.get(news_data["img_url"], timeout=15.0)
                        if r.status_code == 200:
                            with open(IMG_TEMP_FILE, 'wb') as f: f.write(r.content)
                            mid = api_v1.media_upload(filename=IMG_TEMP_FILE).media_id
                            os.remove(IMG_TEMP_FILE)
                            logger.info("ğŸ“¸ ØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©.")
                except Exception as e: logger.warning(f"âš ï¸ ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {e}")

            await publish_smart_content(client_v2, ai_msg, mid)
        else:
            logger.info("ğŸ˜´ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ ÙŠØ³ØªØ­Ù‚ Ø§Ù„Ù†Ø´Ø± Ø­Ø§Ù„ÙŠØ§Ù‹.")

if __name__ == "__main__":
    asyncio.run(bot_cycle())
