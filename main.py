import os, sqlite3, logging, hashlib, time, re, random
import tweepy, feedparser
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
DB_FILE = "news.db"

# Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ØµØ§Ø±Ù…: ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù‡ÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù‚Ø¨Ù„ Ø§Ù„ØµÙŠØ§ØºØ©
STRICT_AUTHORITY_PROMPT = """
Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ù…Ø­ØªÙˆÙ‰ ØªÙ‚Ù†ÙŠ ÙÙŠ (TechElite). Ù…Ù‡Ù…ØªÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù‡ÙŠ ØªØµÙÙŠØ© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆÙ†Ø´Ø± Ø§Ù„Ù…ÙÙŠØ¯ Ù…Ù†Ù‡Ø§ ÙÙ‚Ø·.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØµØ§Ø±Ù…Ø©:
1. Ø§Ù„Ø¬ÙˆØ¯Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ù…Ø¨Ù‡Ù…Ù‹Ø§ØŒ ØªØ§ÙÙ‡Ù‹Ø§ØŒ Ø£Ùˆ Ù…Ø¬Ø±Ø¯ Ø¥Ø´Ø§Ø¹Ø© Ø¶Ø¹ÙŠÙØ©ØŒ Ù„Ø§ ØªØµØºÙ Ø´ÙŠØ¦Ù‹Ø§ ÙˆØ§ÙƒØªØ¨ ÙÙ‚Ø·: [REJECTED].
2. Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©: Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù†Øµ Ø­ØµØ±Ø§Ù‹.
3. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ù‚Ø¨ÙˆÙ„):
[TWEET_1]: Ø­Ù‚ÙŠÙ‚Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø±ÙƒØ²ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø¯ÙˆÙ† ØºÙ…ÙˆØ¶).
[TWEET_2]: ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ© (Technical Details) Ù…Ø¹ Ø°ÙƒØ± Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† (Term).
[TWEET_3]: Ø§Ù„Ø£Ø«Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ Ø§Ù„Ø³ÙˆÙ‚.

Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø¨Ø§Ø±Ø§Øª ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª Ù…Ø¨Ù‡Ù…Ø© Ù…Ø«Ù„ "Ù‚Ø±ÙŠØ¨Ù‹Ø§" Ø£Ùˆ "Ø±Ø¨Ù…Ø§" Ù…Ø§Ù„Ù… ØªÙƒÙ† Ø¬Ø²Ø¡Ù‹Ø§ Ù…Ù† Ø­Ù‚ÙŠÙ‚Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø¤ÙƒØ¯Ø©.
"""

class TechEliteAuthority:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")
        conn.commit(); conn.close()

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY")
        )

    def _is_valuable_content(self, title):
        """ÙÙ„ØªØ± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù…Ù†Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø© Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        useless_keywords = ['deal', 'discount', 'sale', 'giveaway', 'rumor', 'maybe', 'opinion']
        return not any(word in title.lower() for word in useless_keywords)

    def _generate_ai(self, prompt, context):
        try:
            r = self.ai_client.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role":"system","content":prompt},{"role":"user","content":context}],
                temperature=0.0 # Ø£Ø¯Ù†Ù‰ Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø·Ù„Ù‚ ÙˆØ§Ù„ØµÙØ± Ù‡Ù„ÙˆØ³Ø©
            )
            return r.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"AI Error: {e}"); return None

    def _smart_parse(self, text):
        if "[REJECTED]" in text or len(text) < 50:
            return []
        
        tweets = []
        segments = re.split(r'\[TWEET_\d+\]', text)
        for seg in segments:
            clean_seg = seg.strip()
            if clean_seg and len(clean_seg) > 15:
                tweets.append(clean_seg)
        return tweets[:3]

    def post_thread(self, ai_text, url):
        tweets = self._smart_parse(ai_text)
        if not tweets:
            logging.info("ğŸš« ØªÙ… Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¹Ø¯Ù… ÙƒÙØ§ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø© Ø£Ùˆ Ø§Ù„ÙˆØ¶ÙˆØ­.")
            return False

        footer = f"ğŸ”— Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚:\n{url}\n\nğŸ›¡ï¸ TechElite | Ø±ØµØ¯ Ø¯Ù‚ÙŠÙ‚"
        tweets.append(footer)

        last_id = None
        for i, t in enumerate(tweets):
            try:
                prefix = f"{i+1}/ " if i < len(tweets)-1 else ""
                res = self.x_client.create_tweet(text=f"{prefix}{t}"[:278], in_reply_to_tweet_id=last_id)
                last_id = res.data["id"]
                time.sleep(15)
            except Exception as e:
                logging.error(f"Tweet Error: {e}"); break
        return True

    def run_cycle(self):
        published = 0
        sources = ["https://www.theverge.com/rss/index.xml", "https://9to5mac.com/feed/", "https://techcrunch.com/feed/"]
        random.shuffle(sources)

        for url in sources:
            if published >= 2: break
            feed = feedparser.parse(url)
            for e in feed.entries[:5]:
                if published >= 2: break
                
                # Ø·Ø¨Ù‚Ø© Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
                if not self._is_valuable_content(e.title): continue

                h = hashlib.sha256(e.title.encode()).hexdigest()
                conn = sqlite3.connect(DB_FILE)
                if not conn.execute("SELECT 1 FROM news WHERE hash=?", (h,)).fetchone():
                    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØµØ§Ø±Ù…
                    context = f"Title: {e.title}\nFull Text: {getattr(e, 'summary', '')}"
                    ai_text = self._generate_ai(STRICT_AUTHORITY_PROMPT, context)
                    
                    if ai_text and self.post_thread(ai_text, e.link):
                        conn.execute("INSERT INTO news VALUES (?, ?, ?)", (h, e.title, datetime.now().isoformat()))
                        conn.commit(); published += 1
                        time.sleep(120) # ÙØ§ØµÙ„ Ø²Ù…Ù†ÙŠ Ø·ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø±ØµØ§Ù†Ø©
                conn.close()

if __name__ == "__main__":
    TechEliteAuthority().run_cycle()
