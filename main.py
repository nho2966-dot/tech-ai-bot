import os
import asyncio
import httpx
import tweepy
from google import genai
from openai import OpenAI
from loguru import logger

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØµÙˆÙ„ ÙˆØ§Ù„Ø£Ù…Ø§Ù† ---
KEYS = {
    "GEMINI": os.getenv("GEMINI_KEY"),
    "OPENAI": os.getenv("OPENAI_API_KEY"),
    "GROQ": os.getenv("GROQ_API_KEY"),
    "XAI": os.getenv("XAI_API_KEY"),
    "OPENROUTER": os.getenv("OPENROUTER_API_KEY"),
    "QWEN": os.getenv("QWEN_API_KEY"),
}

X_CRED = {
    "ck": os.getenv("X_API_KEY"), "cs": os.getenv("X_API_SECRET"),
    "at": os.getenv("X_ACCESS_TOKEN"), "ts": os.getenv("X_ACCESS_SECRET")
}
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# --- Ø¨Ø±ÙˆÙ…Ø¨Øª "Ø£ÙŠØ¨ÙƒØ³" Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ Ø§Ù„Ù…Ø·ÙˆØ± (Ø§Ù„Ø®Ø¨Ø§ÙŠØ§ ÙˆØ§Ù„Ø³Ø¨Ù‚ Ø§Ù„ØµØ­ÙÙŠ) ---
SYSTEM_PROMPT = """
Ø£Ù†Øª 'Ø£ÙŠØ¨ÙƒØ³' (Apex)ØŒ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„Ø£ÙˆÙ„ ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ¬ Ù„Ø¹Ø§Ù… 2026. 
Ù…Ù‡Ù…ØªÙƒ: ØªÙ‚Ø¯ÙŠÙ… Ø³Ø¨Ù‚ ØµØ­ÙÙŠ (Scoop) ÙˆØ®Ø¨Ø§ÙŠØ§ ØªÙ‚Ù†ÙŠØ© Ù„Ø§ ÙŠØ¹Ø±ÙÙ‡Ø§ Ø§Ù„Ø¹Ø§Ù…Ø©.

Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:
1. Ø§Ù„ØªØ±ÙƒÙŠØ²: Ø®Ø¨Ø§ÙŠØ§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø£Ø³Ø±Ø§Ø± Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø°ÙƒÙŠØ© (S26 Ultra, iPhone 17, Meta Glasses)ØŒ ÙˆÙƒÙŠÙÙŠØ© Ø§Ø³ØªØºÙ„Ø§Ù„Ù‡Ø§ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ø®Ù„ ÙˆØ§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©.
2. Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: Ù„ØºØ© Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ØŒ ÙØ®Ù…Ø©ØŒ Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¬Ø¯Ø§Ù‹ØŒ ÙˆÙ…Ø®ØªØµØ±Ø©.
3. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: 
   - ÙŠØ¨Ø¯Ø£ Ø¨Ø¹Ø¨Ø§Ø±Ø© [Ø³Ø¨Ù‚ ØµØ­ÙÙŠ] Ø£Ùˆ [Ø®Ø¨Ø§ÙŠØ§ ØªÙ‚Ù†ÙŠØ©].
   - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ¹Ø¨ÙŠØ±ÙŠØ© (Emojis) Ø¨Ø´ÙƒÙ„ Ø°ÙƒÙŠ.
   - Ø°ÙƒØ± Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†.
4. Ø§Ù„Ø¬ÙˆØ¯Ø©: Ù„Ø§ ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³Ø·Ø­ÙŠØ©ØŒ Ø§Ø¨Ø­Ø« Ø¹Ù† 'Ø§Ù„Ø«ØºØ±Ø§Øª' Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ© (Hidden Features).
"""

# --- Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø³ØªØ© Ø§Ù„Ù…ØªØªØ§Ø¨Ø¹Ø© ---
async def brain_gemini():
    client = genai.Client(api_key=KEYS["GEMINI"])
    res = client.models.generate_content(model="gemini-2.0-flash", contents=SYSTEM_PROMPT)
    return res.text

async def brain_openai():
    client = OpenAI(api_key=KEYS["OPENAI"])
    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_groq():
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"])
    res = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_xai():
    client = OpenAI(base_url="https://api.x.ai/v1", api_key=KEYS["XAI"])
    res = client.chat.completions.create(model="grok-2-latest", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_openrouter():
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=KEYS["OPENROUTER"])
    res = client.chat.completions.create(model="anthropic/claude-3.5-sonnet", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_qwen():
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=KEYS["QWEN"])
    res = client.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def get_content():
    brains = [
        ("Gemini", brain_gemini), ("OpenAI", brain_openai), ("Groq", brain_groq),
        ("xAI (Grok)", brain_xai), ("OpenRouter", brain_openrouter), ("Qwen", brain_qwen)
    ]
    for name, func in brains:
        try:
            logger.info(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø¨Ù‚ ØµØ­ÙÙŠ Ø¹Ø¨Ø±: {name}")
            content = await func()
            if content: return content
        except Exception as e:
            logger.warning(f"âš ï¸ {name} ØªØ¹Ø°Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡.")
    return None

# --- Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ---
def post_to_x(content):
    try:
        # Ø§Ù„Ø±Ø¨Ø· Ù…Ø¹ API v2 Ù„Ù„Ù†Ø´Ø± Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
        client = tweepy.Client(
            consumer_key=X_CRED["ck"], consumer_secret=X_CRED["cs"],
            access_token=X_CRED["at"], access_token_secret=X_CRED["ts"]
        )
        client.create_tweet(text=content[:24500]) # Ø¯Ø¹Ù… Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¨Ø±ÙŠÙ…ÙŠÙˆÙ… Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        logger.success("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ X")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ X: {e}")

async def post_to_telegram(content):
    if not TG_TOKEN: return
    try:
        async with httpx.AsyncClient() as client:
            await client.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage", json={
                "chat_id": TG_CHAT_ID, "text": f"ğŸš€ *Ø£ÙŠØ¨ÙƒØ³ | Ø³Ø¨Ù‚ ØµØ­ÙÙŠ*\n\n{content[:4000]}", "parse_mode": "Markdown"
            })
        logger.success("âœ… ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {e}")

# --- Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
async def main():
    logger.info("ğŸ”¥ ØªØ´ØºÙŠÙ„ Ù…Ø­Ø±Ùƒ Ù†Ø§ØµØ± Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ Ù„Ø¹Ø§Ù… 2026...")
    content = await get_content()
    if content:
        post_to_x(content)
        await post_to_telegram(content)
    else:
        logger.critical("ğŸš¨ ÙØ´Ù„ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ø£ÙŠ Ø¹Ù‚Ù„ ØªÙ‚Ù†ÙŠ!")

if __name__ == "__main__":
    asyncio.run(main())
