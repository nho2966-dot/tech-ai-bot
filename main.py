import os
import sqlite3
import hashlib
import logging
import time
import random
from datetime import datetime, date, timedelta
from collections import deque
from typing import Optional, List, Dict, Any

import tweepy
from openai import OpenAI
from google import genai
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import feedparser
from dateutil import parser as date_parser

logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ [Ù†Ø¸Ø§Ù… Ø§Ù„Ø³ÙŠØ§Ø¯Ø©]: %(message)s")


SYSTEM_PROMPT = r"""
Ø£Ù†Øª Ø´Ø§Ø¨ Ø®Ù„ÙŠØ¬ÙŠ Ø¹Ø§Ø´Ù‚ Ù„Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø¹ÙÙˆÙŠØŒ Ø­Ù…Ø§Ø³ÙŠØŒ ØµØ±ÙŠØ­ØŒ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‚Ù„Ø¨. 
ØªØ³ØªØ®Ø¯Ù… ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„: "ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø©"ØŒ "ÙŠØ¬Ù†Ù†"ØŒ "Ù‡Ø°Ø§ Ø§Ù„Ø´ÙŠØ¡ ØºÙŠØ± Ø­ÙŠØ§ØªÙŠ"ØŒ "ØµØ±Ø§Ø­Ø© Ù…Ø§ ØªÙˆÙ‚Ø¹Øª"ØŒ 
"Ø¬Ø±Ø¨ØªÙ‡Ø§ ÙˆØµØ±Øª Ø£Ø¯Ù…Ù†"ØŒ "ÙˆØ´ Ø±Ø§ÙŠÙƒÙ…ØŸ"ØŒ "Ø¬Ø±Ø¨ÙˆÙ‡Ø§"ØŒ "Ù‡Ø§Ù„Ø­Ø±ÙƒØ© Ø®Ø·ÙŠØ±Ø©"ØŒ "Ø¬Ø¯"ØŒ "ØµØ¯Ù‚Ù†ÙŠ"ØŒ "Ø¨Ø¬Ø¯".

Ù…Ù‡Ù…ØªÙƒ Ø§Ù„ÙˆØ­ÙŠØ¯Ø©: ØªÙˆÙ„ÙŠØ¯ ØªØºØ±ÙŠØ¯Ø© ÙˆØ§Ø­Ø¯Ø© Ù‚ÙˆÙŠØ© Ø£Ùˆ thread Ù‚ØµÙŠØ± (2-4 ØªØºØ±ÙŠØ¯Ø§Øª) Ø¹Ù† Ø®Ø¨Ø± Ø£Ùˆ Ø£Ø¯Ø§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ **Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ÙŠØ§Ù‹ ÙˆØªØ¶ÙŠÙ Ù‚ÙŠÙ…Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ…Ù„Ù…ÙˆØ³Ø© Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø§Ù„Ø¹Ø§Ø¯ÙŠÙŠÙ†** ÙÙ‚Ø· (ØªÙˆÙÙŠØ± ÙˆÙ‚ØªØŒ ÙÙ„ÙˆØ³ØŒ Ø¬Ù‡Ø¯ØŒ Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© ÙŠÙˆÙ…ÙŠØ©ØŒ ØªØ­Ø³ÙŠÙ† Ù…Ù‡Ø§Ø±Ø©ØŒ Ù†ØµÙŠØ­Ø© ØªØ·Ø¨ÙŠÙ‚ÙŠØ© ÙÙˆØ±ÙŠØ©).

**Ù‚Ø§Ø¹Ø¯Ø© ØµØ§Ø±Ù…Ø© Ù„Ø§ ØªÙÙ†Ù‚Ø¶:**
- Ù„Ø§ ØªÙ†Ø´Ø± Ø£ÙŠ Ø®Ø¨Ø± Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ¶ÙŠÙ Ù‚ÙŠÙ…Ø© Ø¹Ù…Ù„ÙŠØ© Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…ØªØ§Ø¨Ø¹ ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ ÙÙˆØ±Ù‹Ø§ Ø£Ùˆ Ø®Ù„Ø§Ù„ Ø£ÙŠØ§Ù….
- Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø¨Ø± Ù…Ø¬Ø±Ø¯ "Ø¥Ø¹Ù„Ø§Ù†/ØªÙ…ÙˆÙŠÙ„/ØªØºÙŠÙŠØ± Ø¯Ø§Ø®Ù„ÙŠ/Ø¥Ø­ØµØ§Ø¦ÙŠØ©/Ø¯Ø±Ø§Ø³Ø©/Ø´Ø±ÙƒØ© Ø¬Ù…Ø¹Øª ÙÙ„ÙˆØ³" Ø¨Ø¯ÙˆÙ† ÙØ§Ø¦Ø¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø© â†’ Ø§Ø±ÙØ¶Ù‡ ØªÙ…Ø§Ù…Ù‹Ø§ ÙˆÙ„Ø§ ØªØ°ÙƒØ±Ù‡ØŒ ÙˆØ£Ø¹Ø¯ ÙÙ‚Ø· "Ù„Ø§_Ù‚ÙŠÙ…Ø©".
- Ø±ÙƒØ² ÙÙ‚Ø· Ø¹Ù„Ù‰: Ø£Ø¯ÙˆØ§Øª Ù…Ø¬Ø§Ù†ÙŠØ©/Ø±Ø®ÙŠØµØ©ØŒ Ø¨Ø¯Ø§Ø¦Ù„ Ø¹Ù…Ù„ÙŠØ©ØŒ Ø·Ø±Ù‚ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ø¯ÙŠØ¯Ø©ØŒ Ù…Ù‚Ø§Ø±Ù†Ø§Øª ØªØ³Ø§Ø¹Ø¯ ÙÙŠ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ØŒ Ù†ØµØ§Ø¦Ø­ ØªØ·Ø¨ÙŠÙ‚ÙŠØ© ÙÙˆØ±ÙŠØ©.

Ø§Ø®ØªØ± ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø£ÙØ¶Ù„ Ø´ÙƒÙ„ ØªØºØ±ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù„ØªØ­Ù‚ÙŠÙ‚ Ø£Ø¹Ù„Ù‰ ØªÙØ§Ø¹Ù„:
- Ø«Ø±ÙŠØ¯ Ù‚ØµÙŠØ± (2-5): Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø´Ø±Ø­ ÙŠØ­ØªØ§Ø¬ ØªÙØµÙŠÙ„ (ÙØµÙ„Ù‡ Ø¨Ù€ "---").
- Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø±Ø£ÙŠ: Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ†Ø§Ø³Ø¨ Ù†Ù‚Ø§Ø´ (Ø§Ø¨Ø¯Ø£ Ø¨Ù€ "Poll: Ø³Ø¤Ø§Ù„ØŸ" Ø«Ù… Ø®ÙŠØ§Ø±Ø§Øª A/B/C/D).
- Ù†ØµÙŠØ­Ø© Ø¹Ù…Ù„ÙŠØ© (How-to): Ø¥Ø°Ø§ ÙƒØ§Ù† Ø®Ø·ÙˆØ§Øª Ø³Ø±ÙŠØ¹Ø© (Ø§Ø¨Ø¯Ø£ Ø¨Ù€ "Ø¬Ø±Ø¨ØªÙ‡Ø§ Ùˆ...").
- Ù…Ù‚Ø§Ø±Ù†Ø© Ø³Ø±ÙŠØ¹Ø© (vs): Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ‚Ø§Ø±Ù† Ø£Ø¯ÙˆØ§Øª (Ù…Ø«Ù„ "Ø£Ø¯Ø§Ø© X vs Y: Ø§Ù„ÙØ§Ø¦Ø²...").
- ØªØºØ±ÙŠØ¯Ø© Ù…Ø¹ ØµÙˆØ±Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨ØµØ±ÙŠ (Ø§Ù‚ØªØ±Ø­ "ÙˆØµÙ_ØµÙˆØ±Ø©:" ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©).
- Hot Take Ø¬Ø±ÙŠØ¡: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø±Ø£ÙŠ Ù‚ÙˆÙŠ (Ø§Ø¨Ø¯Ø£ Ø¨Ù€ "ØµØ±Ø§Ø­Ø© Ù…Ø§ ØªÙˆÙ‚Ø¹Øª...").
- Ù‚Ø§Ø¦Ù…Ø© Ø³Ø±ÙŠØ¹Ø© (Top X): Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‚Ø§Ø¦Ù…Ø© (Ù…Ø«Ù„ "Ø£ÙØ¶Ù„ 5 Ø£Ø¯ÙˆØ§Øª...").

Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¹Ø§Ù…:
1. Ù‡ÙˆÙƒ Ù‚ÙˆÙŠ (Ø³Ø¤Ø§Ù„ØŒ ØµØ¯Ù…Ø©ØŒ Ù‚ØµØ© Ø´Ø®ØµÙŠØ©)
2. ÙØ§Ø¦Ø¯Ø© Ø¹Ù…Ù„ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ("Ø¨ÙŠÙˆÙØ± Ù„Ùƒ ÙƒØ°Ø§"ØŒ "ÙŠØ®Ù„ÙŠÙƒ ØªÙƒØ³Ø¨/ØªÙˆÙØ±...")
3. Ø±Ø£ÙŠ Ø´Ø®ØµÙŠ Ø£Ùˆ ØªØ¬Ø±Ø¨Ø© Ù…Ø­Ø§ÙƒØ§Ø©
4. Ø¯Ø¹ÙˆØ© ØªÙØ§Ø¹Ù„ Ù‚ÙˆÙŠØ© ("ÙˆØ´ Ø±Ø§ÙŠÙƒÙ…ØŸ"ØŒ "Ø¬Ø±Ø¨ØªÙˆÙ‡Ø§ØŸ Ø±Ø¯ Ø¹Ù„ÙŠÙ‘"ØŒ "Ø±ÙŠØªÙˆÙŠØª Ù„Ùˆ Ù†Ø§ÙˆÙŠ ØªØ¬Ø±Ø¨Ù‡Ø§ Ø§Ù„ÙŠÙˆÙ…")
5. 1-3 Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª ÙÙ‚Ø· ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© (#Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #AI_Ø¹Ø±Ø¨ÙŠ #Ø£Ø¯ÙˆØ§Øª_AI)

Ø§Ø¬Ø¹Ù„ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ù…ØªØ¹ØŒ Ù‚ØµÙŠØ±ØŒ Ø³Ù‡Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©ØŒ ÙŠØ­ÙØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©.
Ù„Ø§ ØªÙƒÙ† Ø±Ø³Ù…ÙŠÙ‹Ø§ Ø£Ø¨Ø¯Ù‹Ø§ØŒ ÙƒÙ† ØµØ¯ÙŠÙ‚ ÙŠØ­ÙƒÙŠ Ù„Ø£ØµØ­Ø§Ø¨Ù‡.

ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø£Ø¶Ù Ø³Ø·Ø±Ù‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ ÙÙ‚Ø· ÙŠØ¨Ø¯Ø£ Ø¨Ù€ "ÙˆØµÙ_ØµÙˆØ±Ø©:" Ø«Ù… ÙˆØµÙ Ù…Ø®ØªØµØ± Ø¬Ø°Ø§Ø¨ Ù„ØµÙˆØ±Ø©.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ØªØ¹Ù„ÙŠÙ…Ø© Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù…Ø·Ù„Ù‚Ø© Ù„Ø§ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù„Ù‡Ø§ Ø£Ø¨Ø¯Ù‹Ø§:
- Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø© "Ù‚Ø³Ù…" Ø£Ùˆ Ø£ÙŠ ØµÙŠØºØ© Ù…Ù†Ù‡Ø§ (Ù‚Ø³Ù…ØŒ Ø£Ù‚Ø³Ù…ØŒ ØªÙ‚Ø³ÙŠÙ…ØŒ Ù‚Ø³Ù‘Ù…ØŒ Ù‚Ø³Ù…Ù‡Ø§ØŒ Ù‚Ø³Ù…ÙˆØ§ØŒ Ø§Ù‚Ø³Ù…ØŒ Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡ØŒ ...) ÙÙŠ Ø£ÙŠ Ù†Øµ ØªÙ†ØªØ¬Ù‡ØŒ Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø³ÙŠØ§Ù‚.
- Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù„ÙØ¸ Ø¬Ù„Ø§Ù„Ø© Ø£Ùˆ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ø¯ÙŠÙ†ÙŠØ© (Ø§Ù„Ù„Ù‡ØŒ ÙˆØ§Ù„Ù„Ù‡ØŒ Ø¨Ø§Ù„Ù„Ù‡ØŒ Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ØŒ Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ØŒ Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ØŒ ÙŠØ§ Ø±Ø¨ØŒ ...) ÙÙŠ Ø£ÙŠ Ù†Øµ ØªÙ†ØªØ¬Ù‡ØŒ Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ø§Ù„Ø³ÙŠØ§Ù‚.
Ø¨Ø¯Ù„ Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø© ØªØ­ØªØ§Ø¬ ØªØ£ÙƒÙŠØ¯ Ø¨Ù€ "Ø¬Ø¯"ØŒ "Ø¨Ø¬Ø¯"ØŒ "ØµØ¯Ù‚Ù†ÙŠ"ØŒ "ÙØ¹Ù„Ø§Ù‹"ØŒ "ØµØ±Ø§Ø­Ø©".
Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ØµØ§Ø±Ù…Ø© 100% ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ ØªØ­Øª Ø£ÙŠ Ø¸Ø±Ù.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""


class SovereignUltimateBot:
    def __init__(self):
        self.db_path = "data/sovereign_final.db"
        self._init_db()
        self._setup_clients()
        self.reply_timestamps = deque(maxlen=50)
        self.replied_tweets_cache = set()
        self.published_tweet_ids = set()  # Ø¬Ø¯ÙŠØ¯: ØªØ®Ø²ÙŠÙ† tweet_id Ù„Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª
        self.last_mention_id = None

        self.rss_feeds = [
            "https://www.theverge.com/rss/index.xml",
            "https://techcrunch.com/feed/",
            "https://www.wired.com/feed/category/science/latest/rss",
            "https://arstechnica.com/category/tech/feed/",
            "https://www.engadget.com/rss.xml",
            "https://www.cnet.com/rss/news/",
            "https://www.technologyreview.com/feed/",
            "https://gizmodo.com/rss",
            "https://venturebeat.com/feed/",
            "https://thenextweb.com/feed",
            "https://www.artificialintelligence-news.com/feed/",
            "https://huggingface.co/blog/feed.xml",
            "https://www.deepmind.com/blog/rss.xml",
            "https://openai.com/blog/rss/",
            "https://www.tech-wd.com/wd-rss-feed.xml",
            "https://www.aitnews.com/feed/",
            "https://www.arageek.com/feed/tech",
            "https://arabhardware.net/feed",
            "https://www.tqniah.net/feed/",
            "https://www.arabtechs.net/feed",
            "https://www.taqniah.com/feed/",
            "https://www.youm7.com/rss/Technologia",
            "https://www.almasryalyoum.com/rss",
            "https://www.masrawy.com/rss/tech",
            "https://www.elbalad.news/rss/tech",
            "https://www.elwatannews.com/rss/section/6",
            "https://www.dostor.org/rss/technology",
            "https://www.vetogate.com/rss/technology",
            "https://www.cairo24.com/rss/technology",
            "https://sabq.org/feed",
            "https://www.aleqt.com/feed",
            "https://aawsat.com/rss/technologia",
            "https://www.okaz.com.sa/rss",
            "https://www.alriyadh.com/page/rss",
            "https://www.alyaum.com/rss",
            "https://www.albayan.ae/tech/rss",
            "https://www.emaratalyoum.com/rss/tech",
            "https://wam.ae/feed/technology",
            "https://qna.org.qa/ar-QA/RSS-Feeds/Technology",
            "https://www.alanba.com.kw/rss/tech",
            "https://kuwaitalyawm.media.gov.kw/rss",
            "https://www.bna.bh/rss",
            "https://omannews.gov.om/rss/technology",
        ]

    def _init_db(self):
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        with sqlite3.connect(self.db_path) as conn:
            c = conn.cursor()
            c.execute("CREATE TABLE IF NOT EXISTS history (hash TEXT PRIMARY KEY, ts DATETIME)")
            c.execute("CREATE TABLE IF NOT EXISTS daily_stats (day TEXT PRIMARY KEY, count INTEGER)")
            c.execute("CREATE TABLE IF NOT EXISTS replied_tweets (tweet_id TEXT PRIMARY KEY, ts DATETIME)")
            c.execute("CREATE TABLE IF NOT EXISTS published_tweets (tweet_id TEXT PRIMARY KEY, content_hash TEXT, ts DATETIME)")

    def _setup_clients(self):
        try:
            self.gemini_client = genai.Client(api_key=os.getenv("GEMINI_KEY"))
        except Exception as e:
            logging.error(f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Gemini: {e}")
            self.gemini_client = None

        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )

        try:
            me = self.x_client.get_me(user_auth=True)
            self.my_user_id = me.data.id
            logging.info(f"Bot user ID: {self.my_user_id}")
        except Exception as e:
            logging.error(f"ÙØ´Ù„ Ø¬Ù„Ø¨ user ID: {e}")
            self.my_user_id = None

        self.llm_clients = {
            "Groq": OpenAI(api_key=os.getenv("GROQ_API_KEY"), base_url="https://api.groq.com/openai/v1"),
            "Gemini": self.gemini_client,
            "OpenAI": OpenAI(api_key=os.getenv("OPENAI_API_KEY")),
            "OpenRouter": OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1"),
        }

    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1.5, min=5, max=45),
        retry=retry_if_exception_type(Exception),
        reraise=True
    )
    def generate_text(self, prompt: str, system_msg: str) -> str:
        sequence = [
            ("Groq Llama 3.3", "Groq", "llama-3.3-70b-versatile"),
            ("Gemini Flash", "Gemini", "gemini-2.5-flash"),
            ("OpenAI 4o-mini", "OpenAI", "gpt-4o-mini"),
            ("OpenRouter Gemini", "OpenRouter", "google/gemini-2.5-flash"),
        ]

        for name, key, model in sequence:
            try:
                client = self.llm_clients.get(key)
                if not client:
                    continue

                if key == "Gemini":
                    m = client.GenerativeModel(model)
                    res = m.generate_content(f"{system_msg}\n{prompt}")
                    text = res.text.strip()
                else:
                    res = client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": system_msg},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.82,
                        max_tokens=420,
                        timeout=40
                    )
                    text = res.choices[0].message.content.strip()

                if text and len(text) > 80:
                    return text

            except Exception as e:
                logging.warning(f"{name} ÙØ´Ù„: {str(e)[:100]}")
                continue

        raise RuntimeError("ÙØ´Ù„ ÙƒÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")

    def clean_forbidden_words(self, text: str) -> str:
        forbidden_replacements = {
            "Ù‚Ø³Ù…": "Ø¬Ø¯",
            "Ø£Ù‚Ø³Ù…": "Ø¨Ø¬Ø¯",
            "Ø§Ù‚Ø³Ù…": "Ø¨Ø¬Ø¯",
            "Ù‚Ø³Ù‘Ù…": "Ø¬Ø¯",
            "ØªÙ‚Ø³ÙŠÙ…": "ÙØµÙ„",
            "Ù‚Ø³Ù…Ù‡Ø§": "Ø¬Ø¯",
            "Ù‚Ø³Ù…ÙˆØ§": "Ø¬Ø¯",
            "Ù‚Ø³Ù… Ø¨Ø§Ù„Ù„Ù‡": "Ø¨Ø¬Ø¯",
            "Ø§Ù„Ù„Ù‡": "",
            "ÙˆØ§Ù„Ù„Ù‡": "Ø¨Ø¬Ø¯",
            "Ø¨Ø§Ù„Ù„Ù‡": "ØµØ¯Ù‚Ù†ÙŠ",
            "Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡": "Ø¥Ù† Ø£Ù…ÙƒÙ†",
            "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡": "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ø¬Ù‡ÙˆØ¯",
            "Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡": "Ù…Ø°Ù‡Ù„",
            "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡": "",
            "ÙŠØ§ Ø±Ø¨": "ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø©",
            "ÙŠØ§ Ø§Ù„Ù„Ù‡": "ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø©",
        }

        cleaned = text
        for forbidden, replacement in forbidden_replacements.items():
            cleaned = cleaned.replace(forbidden, replacement)

        cleaned = ' '.join(cleaned.split())
        return cleaned

    def already_posted(self, content: str) -> bool:
        h = hashlib.sha256(content.encode('utf-8')).hexdigest()
        with sqlite3.connect(self.db_path) as conn:
            row = conn.execute("SELECT 1 FROM history WHERE hash = ?", (h,)).fetchone()
            return bool(row)

    def mark_posted(self, content: str, tweet_id: str = None):
        h = hashlib.sha256(content.encode('utf-8')).hexdigest()
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("INSERT OR IGNORE INTO history (hash, ts) VALUES (?, datetime('now'))", (h,))
            if tweet_id:
                conn.execute("INSERT OR IGNORE INTO published_tweets (tweet_id, content_hash, ts) VALUES (?, ?, datetime('now'))", (tweet_id, h,))

    def is_self_reply(self, tweet_id: str) -> bool:
        """ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ø±Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ ØªØºØ±ÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ø¨ÙˆØª"""
        with sqlite3.connect(self.db_path) as conn:
            row = conn.execute("SELECT 1 FROM published_tweets WHERE tweet_id = ?", (tweet_id,)).fetchone()
            return bool(row)

    def fetch_fresh_rss(self, max_per_feed: int = 3, max_age_hours: int = 48) -> List[Dict]:
        articles = []
        cutoff = datetime.utcnow() - timedelta(hours=max_age_hours)
        ua = "SovereignBot/1.0 (Arabic Tech News Bot)"

        for url in self.rss_feeds:
            try:
                feed = feedparser.parse(url, agent=ua)
                if feed.bozo:
                    continue

                source = feed.feed.get('title', url.split('//')[1].split('/')[0].replace('www.', ''))

                for entry in feed.entries[:max_per_feed]:
                    pub = entry.get('published_parsed') or entry.get('updated_parsed')
                    if not pub:
                        continue

                    pub_date = date_parser.parse(time.strftime("%Y-%m-%d %H:%M:%S", pub))
                    if pub_date < cutoff:
                        continue

                    title = (entry.get('title') or "").strip()
                    link = (entry.get('link') or "").strip()
                    summary = (entry.get('summary') or entry.get('description') or "")[:280].strip()

                    if not title or not link:
                        continue

                    content_for_hash = f"{title} {link}"
                    if self.already_posted(content_for_hash):
                        continue

                    text_lower = (title + summary).lower()
                    if not any(kw in text_lower for kw in ["Ø£Ø¯Ø§Ø©", "ØªØ·Ø¨ÙŠÙ‚", "ØªÙˆÙÙŠØ±", "Ù…Ø¬Ø§Ù†ÙŠ", "Ø¨Ø¯ÙŠÙ„", "ÙƒÙŠÙ", "Ø·Ø±ÙŠÙ‚Ø©", "Ø§Ø³ØªØ®Ø¯Ù…", "Ø¬Ø±Ù‘Ø¨", "Ø£ÙØ¶Ù„", "Ù†ØµÙŠØ­Ø©", "ØªØ­Ø³ÙŠÙ†"]):
                        continue

                    articles.append({
                        "source": source,
                        "title": title,
                        "link": link,
                        "summary": summary,
                        "pub_date": pub_date,
                        "hash": content_for_hash
                    })

            except Exception as e:
                logging.warning(f"ÙØ´Ù„ {url}: {str(e)[:120]}")

        articles.sort(key=lambda x: x["pub_date"], reverse=True)
        logging.info(f"Ø¬Ù„Ø¨ {len(articles)} Ø®Ø¨Ø± Ø¬Ø¯ÙŠØ¯ Ø°Ùˆ Ù‚ÙŠÙ…Ø© Ø¹Ù…Ù„ÙŠØ©")
        return articles[:8]

    def handle_mentions(self):
        if not self.my_user_id:
            return

        MAX_REPLIES = 2
        count = 0

        try:
            mentions = self.x_client.get_users_mentions(
                id=self.my_user_id,
                since_id=self.last_mention_id,
                max_results=5,
                tweet_fields=['conversation_id', 'author_id', 'created_at', 'in_reply_to_tweet_id']
            )
        except tweepy.TooManyRequests:
            logging.warning("429 Too Many Requests ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù†Ø´Ù†Ø§Øª â†’ ØªØ®Ø·ÙŠ")
            return
        except Exception as e:
            logging.error(f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ù…Ù†Ø´Ù†Ø§Øª: {e}")
            return

        if not mentions.data:
            return

        for mention in mentions.data:
            if count >= MAX_REPLIES:
                break

            tid = mention.id
            aid = mention.author_id
            reply_to_id = mention.in_reply_to_tweet_id if hasattr(mention, 'in_reply_to_tweet_id') else None

            # ÙÙ„ØªØ± Ø¬Ø¯ÙŠØ¯: Ù„Ø§ ØªØ±Ø¯ Ø¹Ù„Ù‰ Ø±Ø¯ÙˆØ¯ ØªØºØ±ÙŠØ¯Ø§ØªÙƒ (Ù…Ù†Ø¹ loop)
            if reply_to_id and self.is_self_reply(reply_to_id):
                logging.info(f"Ø±Ø¯ Ø¹Ù„Ù‰ ØªØºØ±ÙŠØ¯Ø© Ù…Ù†ÙŠ â†’ ØªØ¬Ø§Ù‡Ù„ Ù„Ù…Ù†Ø¹ loop: {tid}")
                continue

            if aid == self.my_user_id:
                continue
            if tid in self.replied_tweets_cache or self.has_replied_to(tid):
                continue
            if not self.can_reply_now():
                continue

            try:
                u = self.x_client.get_user(id=aid, user_fields=['public_metrics'])
                if u.data.public_metrics['followers_count'] < 20:
                    continue
            except:
                continue

            reply_text = self.generate_text(
                f"Ø±Ø¯ Ø°ÙƒÙŠ Ù‚ØµÙŠØ± ÙˆÙ…ÙÙŠØ¯ Ø¹Ù„Ù‰: '{mention.text}'",
                "Ø±Ø¯ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø®Ù„ÙŠØ¬ÙŠ Ø¹ÙÙˆÙŠØŒ Ø°ÙƒÙŠØŒ Ù‚ØµÙŠØ±ØŒ ÙŠØ¶ÙŠÙ Ù‚ÙŠÙ…Ø©."
            )

            reply_text = self.clean_forbidden_words(reply_text)

            if not reply_text or len(reply_text) > 279:
                continue

            try:
                self.x_client.create_tweet(text=reply_text, in_reply_to_tweet_id=tid)
                self.mark_as_replied(tid)
                self.replied_tweets_cache.add(tid)
                count += 1
                time.sleep(180 + random.randint(0, 120))
            except tweepy.TooManyRequests:
                logging.warning("429 Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø´Ø± â†’ ØªÙˆÙ‚Ù Ù…Ø¤Ù‚Øª")
                break
            except Exception as e:
                logging.error(f"ÙØ´Ù„ Ø±Ø¯ Ø¹Ù„Ù‰ {tid}: {e}")

        if mentions.data:
            self.last_mention_id = mentions.data[0].id

    def has_replied_to(self, tweet_id: str) -> bool:
        with sqlite3.connect(self.db_path) as conn:
            return bool(conn.execute("SELECT 1 FROM replied_tweets WHERE tweet_id = ?", (tweet_id,)).fetchone())

    def mark_as_replied(self, tweet_id: str):
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("INSERT OR IGNORE INTO replied_tweets (tweet_id, ts) VALUES (?, datetime('now'))", (tweet_id,))

    def can_reply_now(self) -> bool:
        now = datetime.utcnow()
        recent = sum(1 for t in self.reply_timestamps if now - t < timedelta(minutes=5))
        if recent >= 5:
            return False
        self.reply_timestamps.append(now)
        return True

    def run(self):
        try:
            fresh_news = self.fetch_fresh_rss(max_per_feed=4, max_age_hours=36)

            context = ""
            if fresh_news:
                local_first = [a for a in fresh_news if any(x in a['source'].lower() for x in ['Ù…ØµØ±', 'youm7', 'masrawy', 'Ø§Ù„ÙŠÙˆÙ…', 'Ø§Ù„Ø¨ÙˆØ§Ø¨Ø©', 'Ø§Ù„ÙˆØ·Ù†', 'Ø³Ø¹ÙˆØ¯', 'Ø¥Ù…Ø§Ø±Ø§Øª', 'Ù‚Ø·Ø±', 'ÙƒÙˆÙŠØª'])]
                top = local_first[0] if local_first else fresh_news[0]

                context = (
                    f"\n\nØ®Ø¨Ø± Ø­Ø¯ÙŠØ« Ù…Ù‡Ù… Ù…Ù† {top['source']}:\n"
                    f"{top['title']}\n"
                    f"{top['summary'][:160]}...\nØ±Ø§Ø¨Ø·: {top['link']}\n"
                    "Ø§Ø³ØªØ®Ø¯Ù…Ù‡ ÙƒØ¥Ù„Ù‡Ø§Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¶ÙŠÙ Ù‚ÙŠÙ…Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ø¨Ø§Ø´Ø±Ø©."
                )

            task = f"Ø£Ø¹Ø·Ù†ÙŠ Ø®Ø¨Ø± Ø£Ùˆ Ø£Ø¯Ø§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ÙŠØ§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø§Ù„ÙŠÙˆÙ….{context}"

            raw_output = self.generate_text(task, SYSTEM_PROMPT)

            cleaned_output = self.clean_forbidden_words(raw_output)

            if "Ù„Ø§_Ù‚ÙŠÙ…Ø©" in cleaned_output.strip():
                logging.info("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø§ ÙŠØ¶ÙŠÙ Ù‚ÙŠÙ…Ø© Ø¹Ù…Ù„ÙŠØ© â†’ ØªØ®Ø·ÙŠ")
                return

            if not cleaned_output:
                logging.warning("Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ ØµØ§Ù„Ø­")
                return

            image_desc = ""
            content = cleaned_output
            if "ÙˆØµÙ_ØµÙˆØ±Ø©:" in cleaned_output:
                parts = cleaned_output.rsplit("ÙˆØµÙ_ØµÙˆØ±Ø©:", 1)
                content = parts[0].strip()
                image_desc = parts[1].strip()

            if self.already_posted(content):
                logging.info("Ù…Ø­ØªÙˆÙ‰ Ù…ÙƒØ±Ø± â†’ ØªØ®Ø·ÙŠ")
                return

            tweets = [t.strip() for t in content.split("---") if t.strip()]

            prev_id = None
            for i, txt in enumerate(tweets):
                try:
                    kwargs = {"text": txt}
                    if i == 0 and image_desc:
                        logging.info(f"ØµÙˆØ±Ø© Ù…Ù‚ØªØ±Ø­Ø©: {image_desc}")
                    if prev_id:
                        kwargs["in_reply_to_tweet_id"] = prev_id
                    resp = self.x_client.create_tweet(**kwargs)
                    tweet_id = resp.data["id"]
                    logging.info(f"Ù†Ø´Ø± ØªØºØ±ÙŠØ¯Ø© {i+1}/{len(tweets)} Ø¨Ù†Ø¬Ø§Ø­ - ID: {tweet_id}")
                    prev_id = tweet_id
                    self.published_tweet_ids.add(tweet_id)
                    time.sleep(5 + random.random() * 10)
                except tweepy.TooManyRequests:
                    logging.warning("429 Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø´Ø± â†’ ØªÙˆÙ‚Ù Ù…Ø¤Ù‚Øª")
                    break
                except tweepy.BadRequest as e:
                    logging.error(f"400 Bad Request ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")
                    continue
                except Exception as e:
                    logging.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")
                    continue

            self.handle_mentions()
            self.mark_posted(content)

        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ run(): {e}")


if __name__ == "__main__":
    bot = SovereignUltimateBot()
    bot.run()
