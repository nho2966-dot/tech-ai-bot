import os, sqlite3, logging, hashlib, time, random, textwrap
from datetime import datetime
import tweepy, feedparser
from dotenv import load_dotenv
from openai import OpenAI

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ© ---
load_dotenv()
DB_FILE = "tech_om_enterprise_2026.db"
logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

TARGET_TOPICS = ["Ø£Ø¯ÙˆØ§Øª AI", "Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø±Ù‚Ù…ÙŠØ©", "Ø£Ù…Ù† Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "Ø£ØªÙ…ØªØ©", "Ù‡Ù†Ø¯Ø³Ø© Ø£ÙˆØ§Ù…Ø±", "Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©"]
NEWS_SOURCES = ["https://www.theverge.com/rss/index.xml", "https://www.wired.com/feed/rss"]
CTA_MAP = {"ai_tool": "ğŸ“Œ Ø§Ø­ÙØ¸ Ø§Ù„Ø£Ø¯Ø§Ø©.", "info": "ğŸ” Ø£Ø¹Ø¯ Ø§Ù„ØªØºØ±ÙŠØ¯.", "scoop": "ğŸš€ ØªØ§Ø¨Ø¹ Ù„Ù„Ø­ØµØ±ÙŠØ§Øª.", "quiz": "ğŸ’¬ Ø´Ø§Ø±ÙƒÙ†Ø§ Ø±Ø£ÙŠÙƒ."}
STYLE_MODES = ["3 Ù†Ù‚Ø§Ø· Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹.", "Ù†Ù‚Ø·ØªØ§Ù† Ù…Ø¹ Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ.", "Ù†Ù‚Ø·Ø© Ù…Ø±ÙƒØ²Ø© + ØªØ­Ø°ÙŠØ± ØªÙ‚Ù†ÙŠ."]
TRUSTED_KEYWORDS = ["official", "announced", "released", "launch", "update", "new"]

class TechSovereignEngine:
    def __init__(self):
        self._init_db()
        self._init_clients()
        self.ai_calls = 0
        self.MAX_AI_CALLS = 25
        self.last_ai_reset = datetime.now().date()

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("""CREATE TABLE IF NOT EXISTS content_memory 
                         (h TEXT PRIMARY KEY, h_link TEXT, type TEXT, topic TEXT, monetizable INTEGER DEFAULT 0, dt TEXT)""")
            conn.execute("CREATE TABLE IF NOT EXISTS tweet_history (tweet_id TEXT PRIMARY KEY, text_hash TEXT, dt TEXT)")
            conn.execute("""CREATE TABLE IF NOT EXISTS performance 
                         (tweet_id TEXT PRIMARY KEY, type TEXT, likes INTEGER, retweets INTEGER, replies INTEGER, dt TEXT)""")
            conn.commit()

    def _init_clients(self):
        self.x = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _safe_ai_call(self, sys_p, user_p):
        if datetime.now().date() != self.last_ai_reset:
            self.ai_calls = 0
            self.last_ai_reset = datetime.now().date()
        if self.ai_calls >= self.MAX_AI_CALLS: return None

        style = random.choice(STYLE_MODES)
        STRICT_SYSTEM = (sys_p + f"\n[ØµÙØ± Ù‡Ù„ÙˆØ³Ø©]. {style} Ø§Ø¨Ø¯Ø£ Ø¨Ø¬Ù…Ù„Ø© Claim Ù‚ÙˆÙŠØ©. Ø§Ø°ÙƒØ± Ø§Ù„Ù…ØµØ¯Ø± Ø¨Ø§Ù„Ø§Ø³Ù….")
        try:
            self.ai_calls += 1
            r = self.ai.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role": "system", "content": STRICT_SYSTEM}, {"role": "user", "content": user_p}],
                temperature=0.15
            )
            return r.choices[0].message.content.strip()
        except: return None

    def task_expert_reply(self):
        query = "(\"AI\" OR \"ØªÙ‚Ù†ÙŠØ©\" OR #Ø¹Ù…Ø§Ù†_ØªØªÙ‚Ø¯Ù…) -is:retweet"
        try:
            tweets = self.x.search_recent_tweets(query=query, max_results=5, user_auth=True)
            if not tweets or not tweets.data: return False
            for t in tweets.data:
                text_hash = hashlib.sha256(t.text.encode()).hexdigest()
                with sqlite3.connect(DB_FILE) as conn:
                    if conn.execute("SELECT 1 FROM tweet_history WHERE tweet_id=? OR text_hash=?", (str(t.id), text_hash)).fetchone(): continue
                
                reply = self._safe_ai_call("Ø®Ø¨ÙŠØ± Ø­Ù„ÙˆÙ„.", f"Ø±Ø¯ Ø¨Ø®Ø·ÙˆØ© Ø¹Ù…Ù„ÙŠØ© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰: {t.text}")
                if reply:
                    final_reply = reply.strip() + "\n\nâ€” Tech Insight"
                    self.x.create_tweet(text=final_reply[:280], in_reply_to_tweet_id=t.id)
                    with sqlite3.connect(DB_FILE) as conn:
                        conn.execute("INSERT INTO tweet_history VALUES (?, ?, ?)", (str(t.id), text_hash, datetime.now().isoformat()))
                    return True
        except: return False
        return False

    def task_scoop_and_content(self):
        weights_dict = {"scoop": 2, "ai_tool": 3, "info": 4, "quiz": 1}
        task_type = random.choices(list(weights_dict.keys()), weights=list(weights_dict.values()))[0]
        topic = random.choice(TARGET_TOPICS)

        content = self._safe_ai_call(f"Ø®Ø¨ÙŠØ± {topic}.", f"Ù‚Ø¯Ù… Ù…Ø­ØªÙˆÙ‰ {task_type} Ù…Ù…ÙŠØ².")
        if content:
            h = hashlib.sha256(content.encode()).hexdigest()
            with sqlite3.connect(DB_FILE) as conn:
                conn.execute("INSERT INTO content_memory (h, type, topic, dt) VALUES (?, ?, ?, ?)", 
                             (h, task_type, topic, datetime.now().isoformat()))
            
            # Ø§Ù„Ù†Ø´Ø± ÙƒÙ€ Thread Ø¨Ø³ÙŠØ·
            chunks = textwrap.wrap(content, width=250)
            prev_id = None
            for i, chunk in enumerate(chunks):
                if i == len(chunks)-1: chunk += f"\n\n{CTA_MAP.get(task_type, '')}"
                tweet = self.x.create_tweet(text=chunk, in_reply_to_tweet_id=prev_id)
                prev_id = tweet.data['id']
                time.sleep(60)
            return True
        return False

    def run(self):
        if not self.task_expert_reply():
            self.task_scoop_and_content()

if __name__ == "__main__":
    TechSovereignEngine().run()
