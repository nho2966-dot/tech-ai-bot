import os, sqlite3, logging, hashlib, time, re, random, json
from datetime import datetime, timedelta
import tweepy, feedparser
from dotenv import load_dotenv
from openai import OpenAI
from urllib.parse import urlparse

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ© ---
load_dotenv()
DB_FILE = "news_enterprise_full_2026.db"
STRATEGY_FILE = "strategy_adaptive.json"
ROI_WEIGHTS = {"like": 1.0, "repost": 2.5, "reply": 3.0, "poll_vote": 1.5}

APPROVED_HASHTAGS = {
    "AI_Official": ["#Ø§Ù„Ø°ÙƒØ§Ø¡_Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "#AI", "#TechNews"],
    "Microsoft_Official": ["#Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª", "#Ø£Ø³Ø±Ø§Ø±_Ø§Ù„ØªÙ‚Ù†ÙŠØ©", "#MS365"],
    "CyberSecurity": ["#Ø§Ù„Ø£Ù…Ù†_Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "#CyberSecurity", "#InfoSec"]
}

SOURCES = {
    "AI_Official": ["https://blog.google/technology/ai/rss/", "https://openai.com/news/rss/"],
    "Microsoft_Official": ["https://www.microsoft.com/en-us/microsoft-365/blog/feed/"],
    "CyberSecurity": ["https://thehackernews.com/feeds/posts/default"]
}

logging.basicConfig(level=logging.INFO, format="ðŸ›¡ï¸ %(asctime)s - %(message)s")

# Ø§Ù„Ù€ Prompts Ø§Ù„ØªØ®ØµØµÙŠØ©
PUBLISH_PROMPT = "Ø£Ù†Øª Ù…Ø­Ø±Ø± ØªÙ‚Ù†ÙŠ Ù…Ø¤Ø³Ø³ÙŠ. ØµÙØº Ø«Ø±ÙŠØ¯Ø§Ù‹ ØªÙ‚Ù†ÙŠØ§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ù…Ø¹ Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†. [TWEET_1] Ù‡ÙˆÙƒØŒ [TWEET_2] ØªÙØ§ØµÙŠÙ„ØŒ [POLL_QUESTION] Ø³Ø¤Ø§Ù„ØŒ [POLL_OPTIONS] Ø®ÙŠØ§Ø±Ø§Øª (-). Ù„Ø§ Ù‡Ø§Ø´ØªØ§ØºØ§Øª."
REPLY_PROMPT = "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø³ÙŠØ§Ø¯ÙŠ. Ø§ÙƒØªØ¨ Ø±Ø¯Ø§Ù‹ Ø°ÙƒÙŠØ§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ (Smart Reply) ÙŠØ¶ÙŠÙ Ù‚ÙŠÙ…Ø© Ø¹Ù„Ù…ÙŠØ©ØŒ Ù…Ø¹ Ø°ÙƒØ± Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†. Ù„Ø§ Ø±Ø¯ÙˆØ¯ Ø¹Ø§Ù…Ø©."

class TechEliteEnterpriseSystem:
    def __init__(self):
        self._init_db()
        self._init_clients()
        self._load_strategy()
        self.daily_limit = 4

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS editorial_memory (content_hash TEXT PRIMARY KEY, summary TEXT, created_at TEXT)")
            conn.execute("CREATE TABLE IF NOT EXISTS roi_metrics (tweet_id TEXT PRIMARY KEY, category TEXT, score REAL, created_at TEXT)")
            conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, keywords TEXT)")

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _load_strategy(self):
        if os.path.exists(STRATEGY_FILE):
            with open(STRATEGY_FILE, 'r') as f: self.strategy = json.load(f)
        else:
            self.strategy = {"daily_limit": 4, "focus_cats": list(SOURCES.keys())}

    # --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ù…Ù‚Ø§ÙˆÙ… Ù„Ù„Ø²Ø­Ø§Ù… (Fast-Jump AI Engine) ---
    def _is_in_memory(self, h):
        with sqlite3.connect(DB_FILE) as conn:
            return conn.execute("SELECT 1 FROM editorial_memory WHERE content_hash=?", (h,)).fetchone() is not None

    def _generate_ai(self, system_p, user_p, h):
        if self._is_in_memory(h): return None
        
        # Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙ†ÙˆØ¹Ø© Ù„ØªØ¬Ù†Ø¨ ØªØ¹Ù„ÙŠÙ‚ Ø§Ù„Ù€ Action Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø²Ø­Ø§Ù… (429)
        models = [
            "qwen/qwen-2.5-72b-instruct", 
            "google/gemini-flash-1.5", 
            "anthropic/claude-3-haiku",
            "openai/gpt-4o-mini"
        ]
        
        for model_name in models:
            try:
                logging.info(f"ðŸ¤– Trying: {model_name}")
                r = self.ai_client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "system", "content": system_p}, {"role": "user", "content": user_p}],
                    temperature=0.3,
                    timeout=45 
                )
                content = r.choices[0].message.content
                with sqlite3.connect(DB_FILE) as conn:
                    conn.execute("INSERT INTO editorial_memory VALUES (?, ?, ?)", (h, content[:50], datetime.now().isoformat()))
                return content
            except Exception as e:
                if "429" in str(e):
                    logging.warning(f"âš ï¸ {model_name} busy. Jumping to next...")
                    continue 
                logging.error(f"ðŸš¨ Model {model_name} failed: {e}")
                continue
        return None

    def _safe_x_post(self, func, **kwargs):
        for i in range(2): # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù„Ø³Ø±Ø¹Ø© Ø§Ù„ØªÙ†ÙÙŠØ°
            try: return func(**kwargs)
            except: time.sleep(30)
        return None

    # --- [Ø§Ù„Ø±ÙƒÙ† Ø§Ù„Ø£ÙˆÙ„]: Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§ÙÙŠ ---
    def post_thread(self, raw_text, url, title, cat):
        ai_text = re.sub(r'[*_>`â€¢]', '', raw_text).strip()
        parts = re.findall(r'\[.*?\](.*?)(?=\[|$)', ai_text, re.S)
        if len(parts) < 3: return False

        tags = " ".join(random.sample(APPROVED_HASHTAGS.get(cat, ["#Tech"]), 2))
        last_id = None

        for i, content in enumerate(parts[:3]):
            msg = f"{i+1}/ {content.strip()}"
            if i == 1: msg += f"\n\nðŸ”— Source: {url}"
            if i == 2: msg += f"\n\n{tags}"
            
            res = self._safe_x_post(self.x_client.create_tweet, text=msg[:280], in_reply_to_tweet_id=last_id)
            if res: last_id = res.data['id']
            time.sleep(10)

        return True if last_id else False

    # --- [Ø§Ù„Ø±ÙƒÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ]: Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ© ---
    def process_smart_replies(self):
        logging.info("ðŸ” Engagement Mode Active...")
        queries = ["Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "Microsoft 365"]
        for q in queries:
            try:
                tweets = self.x_client.search_recent_tweets(query=f"{q} -is:retweet", max_results=5)
                if not tweets.data: continue
                for tweet in tweets.data:
                    h = hashlib.sha256(f"rep_{tweet.id}".encode()).hexdigest()
                    reply = self._generate_ai(REPLY_PROMPT, tweet.text, h)
                    if reply:
                        self._safe_x_post(self.x_client.create_tweet, text=reply[:280], in_reply_to_tweet_id=tweet.id)
                        logging.info(f"âœ… Replied to: {tweet.id}")
                        time.sleep(30)
            except: continue

    def run_cycle(self):
        logging.info("ðŸš€ Sovereign Cycle Execution")
        self.process_smart_replies() 
        
        posts_count = 0
        for cat, urls in SOURCES.items():
            if posts_count >= self.daily_limit: break
            for url in urls:
                feed = feedparser.parse(url)
                for entry in feed.entries[:2]:
                    h = hashlib.sha256(entry.title.encode()).hexdigest()
                    content = self._generate_ai(PUBLISH_PROMPT, entry.title, h)
                    if content and self.post_thread(content, entry.link, entry.title, cat):
                        posts_count += 1
                        time.sleep(60)

if __name__ == "__main__":
    # ØªØ´ØºÙŠÙ„ Ø¯ÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ÙŠØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ GitHub Actions
    TechEliteEnterpriseSystem().run_cycle()
