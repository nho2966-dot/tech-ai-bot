import os
import asyncio
import httpx
import tweepy
import sqlite3
import hashlib
import random
import re
import difflib
from datetime import datetime
from loguru import logger

# =========================================================
# ğŸ” Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙØ§ØªÙŠØ­
# =========================================================
GEMINI_KEY = os.getenv("GEMINI_KEY")
X_CONFIG = {
    "key": os.getenv("X_API_KEY"),
    "secret": os.getenv("X_API_SECRET"),
    "token": os.getenv("X_ACCESS_TOKEN"),
    "access_s": os.getenv("X_ACCESS_SECRET"),
    "bearer": os.getenv("X_BEARER_TOKEN")
}

client_v2 = tweepy.Client(
    bearer_token=X_CONFIG["bearer"],
    consumer_key=X_CONFIG["key"], consumer_secret=X_CONFIG["secret"],
    access_token=X_CONFIG["token"], access_token_secret=X_CONFIG["access_s"],
    wait_on_rate_limit=True
)

# =========================================================
# ğŸ—„ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·ÙˆØ±Ø© (Ø­ÙØ¸ Ø§Ù„Ø£ÙÙƒØ§Ø±)
# =========================================================
conn = sqlite3.connect("nasser_sovereign_v2.db")
cursor = conn.cursor()
# Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ 'topic_idea' Ù„Ø­ÙØ¸ Ø¬ÙˆÙ‡Ø± Ø§Ù„ÙÙƒØ±Ø© ÙˆÙ…Ù†Ø¹ ØªÙƒØ±Ø§Ø±Ù‡Ø§ Ù…Ø¹Ù†ÙˆÙŠØ§Ù‹
cursor.execute("""
    CREATE TABLE IF NOT EXISTS published (
        hash TEXT PRIMARY KEY, 
        topic_idea TEXT, 
        content_text TEXT, 
        date TEXT
    )
""")
conn.commit()

# =========================================================
# ğŸ›¡ï¸ ÙÙ„ØªØ± Ù†Ø§ØµØ± ÙˆÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ
# =========================================================
def nasser_filter(text):
    if not text: return ""
    # Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø£ÙØ±Ø§Ø¯ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    text = text.replace("Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©", "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡")
    # Ø­Ø°Ù Ø£ÙŠ Ø°ÙƒØ± Ù„Ø§Ø³Ù… Ù†Ø§ØµØ± Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø®Ø¨ÙŠØ± Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø³Ø±ÙŠØ© ÙˆØ§Ù„Ù…Ù‡Ù†ÙŠØ©
    text = re.sub(r'\b(Ù†Ø§ØµØ±|Ø®Ø¨ÙŠØ±|Ø¨ÙˆØª|Ø¢Ù„ÙŠ)\b', '', text)
    return text.strip()

def is_intellectually_duplicated(new_idea, threshold=0.45):
    """
    Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨ÙƒÙ„ Ù…Ø§ Ù†ÙØ´Ø± Ø³Ø§Ø¨Ù‚Ø§Ù‹.
    Ø¥Ø°Ø§ Ø²Ø§Ø¯Øª Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ Ø¹Ù† 45% ÙŠØ¹ØªØ¨Ø± Ù…ÙƒØ±Ø±Ø§Ù‹.
    """
    cursor.execute("SELECT topic_idea FROM published")
    past_ideas = [row[0] for row in cursor.fetchall()]
    
    for old_idea in past_ideas:
        similarity = difflib.SequenceMatcher(None, new_idea, old_idea).ratio()
        if similarity > threshold:
            return True, similarity
    return False, 0

# =========================================================
# ğŸ§  Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ (Gemini)
# =========================================================
async def generate_scoop(prompt, system_msg):
    url = f"https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
    headers = {"Authorization": f"Bearer {GEMINI_KEY}"}
    try:
        async with httpx.AsyncClient(timeout=60) as client:
            payload = {
                "model": "gemini-2.5-flash",
                "messages": [
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": prompt}
                ]
            }
            r = await client.post(url, headers=headers, json=payload)
            return nasser_filter(r.json()['choices'][0]['message']['content'])
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: {e}")
        return None

# =========================================================
# ğŸ¦ ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# =========================================================
async def post_unique_thread():
    # 1. Ø§Ø®ØªÙŠØ§Ø± Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† "Ø§Ù„Ø®Ø¨Ø§ÙŠØ§"
    scoop_topics = [
        "Ø®Ø¨Ø§ÙŠØ§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª AI Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ù„Ù„Ø£ÙØ±Ø§Ø¯.",
        "ØªØ³Ø±ÙŠØ¨ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.",
        "Ø·Ø±ÙŠÙ‚Ø© Ù…Ø®ÙÙŠØ© Ù„Ø¯Ù…Ø¬ ChatGPT Ù…Ø¹ Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø¯ÙˆÙ† Ø±ÙØ¹Ù‡Ø§ Ù„Ù„Ø³Ø­Ø§Ø¨.",
        "Ø£Ø¯ÙˆØ§Øª AI ØªØªÙŠØ­ Ù„Ù„Ø£ÙØ±Ø§Ø¯ Ø¨Ù†Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙÙŠ Ø¯Ù‚Ø§Ø¦Ù‚."
    ]
    selected_topic = random.choice(scoop_topics)

    # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    system = "Ø£Ù†Øª Ù…ØµØ¯Ø± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø®Ø¨Ø§ÙŠØ§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ø£ÙØ±Ø§Ø¯. Ø£Ø³Ù„ÙˆØ¨Ùƒ Ø®Ù„ÙŠØ¬ÙŠØŒ Ø¯Ù‚ÙŠÙ‚ØŒ ÙˆÙ„Ø§ ÙŠØ°ÙƒØ± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø´Ø®ØµÙŠØ©."
    prompt = f"Ø§ÙƒØªØ¨ Ø«Ø±ÙŠØ¯ Ù…Ù† 3 ØªØºØ±ÙŠØ¯Ø§Øª Ø¹Ù†: {selected_topic}. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ©."
    
    raw_content = await generate_scoop(prompt, system)
    if not raw_content: return

    # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ "Ø¨ØµÙ…Ø© Ø§Ù„ÙÙƒØ±Ø©" Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ
    idea_prompt = f"Ù„Ø®Øµ Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙÙŠ 4 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø·: {raw_content}"
    core_idea = await generate_scoop(idea_prompt, "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø­ØªÙˆÙ‰.")

    # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± (Ø­ØªÙ‰ Ù„Ùˆ ØªØºÙŠØ±Øª Ø§Ù„ØµÙŠØ§ØºØ©)
    is_dup, score = is_intellectually_duplicated(core_idea)
    if is_dup:
        logger.warning(f"ğŸš« ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù†Ø´Ø±! Ø§Ù„ÙÙƒØ±Ø© Ù…ÙƒØ±Ø±Ø© Ø¨Ù†Ø³Ø¨Ø© {score:.2f}. (Ø§Ù„ÙÙƒØ±Ø©: {core_idea})")
        return

    # 5. Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ X
    tweets = [t.strip() for t in raw_content.split('\n\n') if len(t) > 10]
    try:
        last_id = None
        for i, tweet_text in enumerate(tweets[:3]):
            if i == 0:
                response = client_v2.create_tweet(text=tweet_text)
            else:
                response = client_v2.create_tweet(text=tweet_text, in_reply_to_tweet_id=last_id)
            last_id = response.data['id']
            await asyncio.sleep(random.randint(20, 40)) # Ø£Ù†Ø³Ù†Ø© Ø§Ù„ØªÙˆÙ‚ÙŠØª

        # 6. Ø­ÙØ¸ "Ø¨ØµÙ…Ø© Ø§Ù„ÙÙƒØ±Ø©" ÙÙŠ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ù„Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø±Ù‡Ø§ Ù…Ø³ØªÙ‚Ø¨Ù„Ø§Ù‹
        content_hash = hashlib.md5(raw_content.encode()).hexdigest()
        cursor.execute("INSERT INTO published VALUES (?,?,?,?)", 
                       (content_hash, core_idea, raw_content, datetime.now().isoformat()))
        conn.commit()
        logger.success(f"âœ… ØªÙ… Ù†Ø´Ø± Ø®Ø¨ÙŠØ¦Ø© ØªÙ‚Ù†ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©: {core_idea}")

    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {e}")

# =========================================================
# ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
# =========================================================
if __name__ == "__main__":
    logger.info("ğŸš€ Ø§Ù†Ø·Ù„Ø§Ù‚ Ø¨ÙˆØª Ù†Ø§ØµØ± Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠ...")
    asyncio.run(post_unique_thread())
