import os
import asyncio
import random
from datetime import datetime, timezone, timedelta
from loguru import logger
import tweepy
import httpx
from bs4 import BeautifulSoup
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# âš™ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
# ==========================================
KEYS = {"GROQ": os.getenv("GROQ_API_KEY")}
X_CRED = {
    "bearer_token": os.getenv("X_BEARER_TOKEN"),            # v2 Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø·
    "consumer_key": os.getenv("X_API_KEY"),                 # v1 Ù„Ù„Ù†Ø´Ø±
    "consumer_secret": os.getenv("X_API_SECRET"),
    "access_token": os.getenv("X_ACCESS_TOKEN"),
    "access_token_secret": os.getenv("X_ACCESS_SECRET")
}

OFFICIAL_REFS = ["GoogleAI", "OpenAI", "DeepMind", "MetaAI", "Microsoft", "AnthropicAI", "NVIDIAAIDev"]
BLACKLIST = ["Ø³ÙŠØ§Ø³Ø©", "Ù…Ø®Ø¯Ø±Ø§Øª", "Ø¹Ù†ØµØ±ÙŠØ©", "Ø´ØªÙ…", "ØªØ­Ø±ÙŠØ¶"]

# ==========================================
# ğŸ”‘ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
# ==========================================
try:
    # v2 Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
    client_v2 = tweepy.Client(
        bearer_token=X_CRED["bearer_token"],
        wait_on_rate_limit=True
    )

    # v1 Ù„Ù„Ù†Ø´Ø±
    auth_v1 = tweepy.OAuth1UserHandler(
        X_CRED["consumer_key"],
        X_CRED["consumer_secret"],
        X_CRED["access_token"],
        X_CRED["access_token_secret"]
    )
    api_v1 = tweepy.API(auth_v1)

    BOT_ID = client_v2.get_me().data.id
    logger.success("âœ… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù†Ø·Ù„Ù‚ØŒ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© Ù†Ø§Ø¬Ø­Ø© Ù„ÙƒÙ„ Ù…Ù† v1 Ùˆ v2!")
except Exception as e:
    logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©: {e}")
    exit()

# ==========================================
# ğŸ›¡ï¸ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
# ==========================================
async def ai_guard(prompt, mode="news"):
    if any(word in prompt.lower() for word in BLACKLIST):
        return "SKIP"

    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"])
    
    sys_prompt = f"""Ø£Ù†Øª 'Ø£ÙŠØ¨ÙƒØ³'. Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡.
    - Ø§Ù„Ù„Ù‡Ø¬Ø©: Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ (Ø¨Ø¯ÙˆÙŠØ© Ø­Ø¶Ø±ÙŠØ© Ø±Ø§Ù‚ÙŠØ©).
    - Ø§Ù„Ù‚ÙŠÙˆØ¯: ÙŠÙ…Ù†Ø¹ Ø°ÙƒØ± 'Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ©' Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ØŒ Ø§Ø³ØªØ¨Ø¯Ù„Ù‡Ø§ Ø¨Ù€ 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡'.
    - Ø§Ù„Ù„ØºØ©: Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙÙŠ Ø§Ù„Ù†ØµØŒ ÙÙ‚Ø· Ø¨ÙŠÙ† Ø£Ù‚ÙˆØ§Ø³ (Name).
    - Ø§Ù„Ù†Ù…Ø·: { 'Ø§Ù‚ØªØ¨Ø³ ÙˆØ¹Ù„Ù‚ Ø¨Ø°ÙƒØ§Ø¡' if mode == 'snipe' else 'ØµØº Ø®Ø¨Ø± Ù…ÙÙŠØ¯ Ù„Ù„Ø£ÙØ±Ø§Ø¯' }."""

    try:
        response = await asyncio.to_thread(
            client.chat.completions.create,
            model="llama-3.3-70b-versatile",
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": prompt}],
            temperature=0.1
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ AI: {e}")
        return "SKIP"

# ==========================================
# ğŸ¯ Ø§Ù„Ù‚Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø©
# ==========================================
async def snipe_official_refs():
    target = random.choice(OFFICIAL_REFS)
    logger.info(f"ğŸ¯ ÙØ­Øµ Ù…Ø±Ø¬Ø¹ Ù…ÙˆØ«ÙˆÙ‚: {target}")
    try:
        user = client_v2.get_user(username=target)
        tweets = client_v2.get_users_tweets(
            id=user.data.id,
            max_results=5,
            tweet_fields=['text', 'id']
        )

        if tweets.data:
            tweet = tweets.data[0]
            comment = await ai_guard(tweet.text, mode="snipe")
            if "SKIP" not in comment:
                await asyncio.sleep(random.randint(60, 180))
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… v1 Ù„Ù„Ù†Ø´Ø± Ù„ØªØ¬Ù†Ø¨ 401
                api_v1.update_status(status=comment, in_reply_to_status_id=tweet.id, auto_populate_reply_metadata=True)
                logger.success(f"ğŸš€ ØªÙ… Ù‚Ù†Øµ ØªØºØ±ÙŠØ¯Ø© Ù…Ù† {target}!")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù‚Ù†Øµ: {e}")

# ==========================================
# ğŸ“° Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø¯ÙˆØ±ÙŠ
# ==========================================
async def post_unique_news():
    logger.info("ğŸ“° Ø¬Ù„Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡...")
    try:
        async with httpx.AsyncClient() as c:
            r = await c.get("https://aitnews.com/feed/", timeout=10)
            soup = BeautifulSoup(r.content, 'xml')
            item = soup.find('item')
            if item:
                link = item.link.text
                my_tweets = client_v2.get_users_tweets(id=BOT_ID, max_results=10)
                if my_tweets.data and any(link in t.text for t in my_tweets.data):
                    logger.warning("âš ï¸ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± ØªÙ… Ù†Ø´Ø±Ù‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹ØŒ ØªØ®Ø·ÙŠ...")
                    return

                tweet_text = await ai_guard(item.title.text, mode="news")
                if "SKIP" not in tweet_text:
                    api_v1.update_status(status=f"{tweet_text}\n\nğŸ”— {link}")
                    logger.success("âœ… ØªÙ… Ù†Ø´Ø± Ø§Ù„Ø®Ø¨Ø± Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø§Ù„Ù†Ø´Ø±: {e}")

# ==========================================
# ğŸš€ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
async def run_apex_engine():
    await snipe_official_refs()
    await post_unique_news()

if __name__ == "__main__":
    asyncio.run(run_apex_engine())
