import os, sqlite3, logging, hashlib, re, time
from datetime import datetime
from urllib.parse import urlparse
import tweepy
from dotenv import load_dotenv
from openai import OpenAI

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„Ø­ÙˆÙƒÙ…Ø© (Governance)
load_dotenv()
DB_FILE = "tech_om_sovereign_2026.db"
logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

# Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„ØªØ­Ø±ÙŠØ±ÙŠØ© Ø§Ù„Ù†Ø®Ø¨ÙˆÙŠØ©
EDITORIAL_POLICY = {
    "BREAKING": {"min_score": 4, "max_len": 500, "prefix": "ğŸš¨ Ø¹Ø§Ø¬Ù„ ØªÙ‚Ù†ÙŠ"},
    "ANALYSIS": {"min_score": 4, "max_len": 25000, "prefix": "ğŸ§  ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù…Ù‚"},
    "OPINION":  {"min_score": 5, "max_len": 25000, "prefix": "ğŸ—£ï¸ Ø±Ø£ÙŠ ØªÙ‚Ù†ÙŠ"},
    "CONTEST":  {"min_score": 5, "max_len": 280, "prefix": "ğŸ† Ù…Ø³Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"},
    "HARVEST":  {"min_score": 5, "max_len": 25000, "prefix": "ğŸ—ï¸ Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"}
}

TRUSTED_SOURCES = ["theverge.com", "techcrunch.com", "wired.com", "openai.com", "mit.edu", "reuters.com", "bloomberg.com"]

# 2. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø«Ø±ÙŠØ¯Ø§Øª Ø§Ù„Ù†Ø®Ø¨ÙˆÙŠ (Elite Thread Engine)
class TechThreadUltimate:
    def __init__(self, client_x, ai_client):
        self.x = client_x
        self.ai = ai_client
        self.max_len = 250

    def _dedupe_terms(self, text):
        seen = set()
        words = text.split()
        out = []
        for w in words:
            clean_w = re.sub(r"[()]", "", w).lower()
            if clean_w.isascii() and len(clean_w) > 2:
                if clean_w in seen: continue
                seen.add(clean_w)
            out.append(w)
        return " ".join(out)

    def _sanitize_tweets(self, tweets):
        clean = []
        for t in tweets:
            t = self._dedupe_terms(t.strip())
            if len(t) < 45: continue
            if len(t) > self.max_len:
                t = t[:self.max_len - 3] + "..."
            clean.append(t)
        return clean

    def post_thread(self, raw_content, source_url):
        prompt = (
            "Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø«Ø±ÙŠØ¯ Ø®Ù„ÙŠØ¬ÙŠ Ù†Ø®Ø¨ÙˆÙŠ (Hook -> Analysis -> Takeaway).\n"
            "Ø§ÙØµÙ„ Ø¨ÙŠÙ† ÙƒÙ„ ØªØºØ±ÙŠØ¯Ø© ÙˆØ¹Ù„Ø§Ù…Ø© '---'. Ø§Ø³ØªØ®Ø¯Ù… Ù„Ù‡Ø¬Ø© Ø¨ÙŠØ¶Ø§Ø¡ ÙˆÙ…ØµØ·Ù„Ø­Ø§Øª ØªÙ‚Ù†ÙŠØ©."
        )
        try:
            r = self.ai.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role": "user", "content": raw_content}], temperature=0.5
            )
            raw_res = r.choices[0].message.content.strip().split("---")
            tweets = self._sanitize_tweets(raw_res)

            if len(tweets) < 3: return None

            # Semantic Hook Guard
            if not re.search(r"(Ù„ÙŠØ´|ÙƒÙŠÙ|ÙˆØ´|Ù‡Ù„|Ø§Ù„Ø³Ø¨Ø¨|Ø§Ù„ÙØ±Ù‚)", tweets[0]):
                tweets[0] = "Ù„ÙŠØ´ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‡Ù… Ø§Ù„Ø­ÙŠÙ†ØŸ Ø®Ù„Ù‘Ùƒ Ù…Ø¹ÙŠ ÙÙŠ Ù‡Ø§Ù„ØªØ­Ù„ÙŠÙ„.. ğŸ‘‡\n\n" + tweets[0]
            if not re.search(r"[!?ğŸ”¥ğŸš¨ğŸ§ ]", tweets[0]): tweets[0] = "ğŸ§  " + tweets[0]

            previous_tweet_id = None
            for i, tweet_text in enumerate(tweets):
                if i == len(tweets)-1:
                    if "ØŸ" not in tweet_text: tweet_text += "\n\nÙˆØ´ Ø±Ø£ÙŠÙƒØŸ ØªØªÙÙ‚ Ø£Ùˆ Ù„Ø§ØŸ ğŸ‘‡"
                    footer = f"\n\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: {source_url}"
                else: footer = ""

                header = "ğŸ§µ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„\n" if i == 0 else f"â†³ {i+1}/{len(tweets)}\n"
                final_text = f"{header}{tweet_text}{footer}"

                time.sleep(1.2 if i == 0 else 0.7)
                response = self.x.create_tweet(text=final_text, in_reply_to_tweet_id=previous_tweet_id)
                previous_tweet_id = response.data["id"]
                logging.info(f"âœ… ØªÙ… Ù†Ø´Ø± Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø±ÙŠØ¯ {i+1}")
            return previous_tweet_id
        except Exception as e:
            logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø«Ø±ÙŠØ¯: {e}")
            return None

# 3. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Sovereign Engine)
class TechSovereignEngine:
    def __init__(self):
        self._init_db()
        self._init_clients()
        self.year = 2026
        self.threader = TechThreadUltimate(self.x, self.ai)

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS vault (h TEXT PRIMARY KEY, type TEXT, dt TEXT)")
            conn.commit()

    def _init_clients(self):
        self.x = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _is_duplicate(self, text):
        h = hashlib.sha256(text.strip().encode()).hexdigest()
        with sqlite3.connect(DB_FILE) as conn:
            return conn.execute("SELECT 1 FROM vault WHERE h=?", (h,)).fetchone() is not None, h

    def _is_trusted(self, url):
        parsed = urlparse("https://" + url if not url.startswith("http") else url)
        domain = parsed.netloc.lower()
        return any(domain == d or domain.endswith("." + d) for d in TRUSTED_SOURCES)

    def publish(self, raw_input, source_url, mode="ANALYSIS"):
        if not self._is_trusted(source_url):
            logging.warning(f"ğŸ›‘ Ù…ØµØ¯Ø± ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚: {source_url}")
            return

        prompt = (f"Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± Ø®Ù„ÙŠØ¬ÙŠ ÙÙŠ 2026. Ø§Ù„Ù†Ù…Ø·: {mode}.\n"
                  "Ø§Ø³ØªØ®Ø¯Ù… Ù„Ù‡Ø¬Ø© Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ØŒ Ø¶Ø¹ Ù…ØµØ·Ù„Ø­ÙŠÙ† Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠÙŠÙ† Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†.\n"
                  "Ø£Ù†Ù‡Ù Ø¨Ù€: [SCORE: X/5]")
        
        r = self.ai.chat.completions.create(
            model="qwen/qwen-2.5-72b-instruct",
            messages=[{"role": "user", "content": raw_input}], temperature=0.4
        )
        enhanced = r.choices[0].message.content.strip()

        score_match = re.search(r"\[SCORE:\s*(\d)/5\]", enhanced)
        score = int(score_match.group(1)) if score_match else 0
        clean_text = re.sub(r"\[.*?\]", "", enhanced).strip()
        
        policy = EDITORIAL_POLICY.get(mode)
        if score < policy["min_score"]: return

        is_dup, h = self._is_duplicate(clean_text)
        if is_dup: return

        # Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ø´Ø±: Ø«Ø±ÙŠØ¯ Ù„Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø­ØµØ§Ø¯ØŒ Ø£Ùˆ ØªØºØ±ÙŠØ¯Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù„Ø¨Ù‚ÙŠØ©
        if mode in ["ANALYSIS", "HARVEST"] and score == 5:
            self.threader.post_thread(clean_text, source_url)
        else:
            full_post = f"{policy['prefix']} {self.year}\n\n{clean_text[:policy['max_len']]}\n\nğŸ”— Ø§Ù„Ù…Ø±Ø¬Ø¹: {source_url}"
            self.x.create_tweet(text=full_post)
        
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("INSERT INTO vault VALUES (?, ?, ?)", (h, mode, datetime.now().isoformat()))
        logging.info(f"ğŸš€ ØªÙ… ØªÙ†ÙÙŠØ° {mode} Ø¨Ù†Ø¬Ø§Ø­!")

    def auto_run(self):
        day = datetime.now().strftime("%A")
        if day == "Friday":
            self.publish("Ø­ØµØ§Ø¯ ØªÙ‚Ù†ÙŠ Ø¯Ø³Ù… Ù„Ø£Ù‡Ù… 3 Ø§Ø¨ØªÙƒØ§Ø±Ø§Øª ÙÙŠ AI Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹.", "techcrunch.com", "HARVEST")
        elif day == "Monday":
            self.publish("Ø³Ø¤Ø§Ù„ Ù…Ø³Ø§Ø¨Ù‚Ø© ØªÙ‚Ù†ÙŠØ© Ø¹Ù† Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©.", "mit.edu", "CONTEST")
        else:
            self.publish("Ù†ØµÙŠØ­Ø© ØªÙ‚Ù†ÙŠØ© ÙŠÙˆÙ…ÙŠØ© Ø¹Ù† Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø°ÙƒÙŠØ©.", "openai.com", "BREAKING")

if __name__ == "__main__":
    engine = TechSovereignEngine()
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹)
    test_content = "Ø£Ù‡Ù… Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹: Sora 2.0 ÙŠØ°Ù‡Ù„ Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„ÙƒÙ… Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† NVIDIA ØªØµÙ„ Ù„Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ†."
    engine.publish(test_content, "techcrunch.com", mode="HARVEST")
