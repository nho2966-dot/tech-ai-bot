import os, sqlite3, logging, hashlib, time, re, random
from datetime import datetime, timedelta
import tweepy, feedparser
from dotenv import load_dotenv
from openai import OpenAI
from urllib.parse import urlparse

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
DB_FILE = "news_master_2026.db"
LOG_FILE = "system_master.log"

logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s", 
                    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler()])

# 1. Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø±Ø³Ù…ÙŠØ© (ØªÙ… Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø±ÙˆØ§Ø¨Ø·Ù‡Ø§)
SOURCES = {
    "AI_Official": ["https://blog.google/technology/ai/rss/", "https://openai.com/news/rss/"],
    "CyberSecurity": ["https://thehackernews.com/feeds/posts/default", "https://krebsonsecurity.com/feed/"],
    "FinTech_Crypto": ["https://www.coindesk.com/arc/outboundfeeds/rss/", "https://www.theblock.co/rss.xml"],
    "Microsoft_Official": ["https://www.microsoft.com/en-us/microsoft-365/blog/feed/"],
    "Tech_Authority": ["https://arstechnica.com/feed/", "https://www.wired.com/feed/rss"]
}

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¨ÙŠØ¶Ø§Ø¡ Ù„Ù„Ù‡Ø§Ø´ØªØ§ØºØ§Øª (Ù…Ù†Ø¹Ø§Ù‹ Ù„Ù„Ø­Ø³Ø§Ø¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø©)
APPROVED_HASHTAGS = {
    "AI_Official": ["#Ø§Ù„Ø°ÙƒØ§Ø¡_Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "#AI", "#GoogleGemini", "#TechNews"],
    "CyberSecurity": ["#Ø§Ù„Ø£Ù…Ù†_Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ", "#CyberSecurity", "#Ø§Ù…Ù†_Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"],
    "FinTech_Crypto": ["#Ø§Ù„ØªÙ‚Ù†ÙŠØ©_Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "#FinTech", "#Ø¨Ù„ÙˆÙƒØ´ÙŠÙ†"],
    "Microsoft_Official": ["#Ù…Ø§ÙŠÙƒØ±ÙˆØ³ÙˆÙØª", "#Ø£Ø³Ø±Ø§Ø±_Ø§Ù„ØªÙ‚Ù†ÙŠØ©", "#Windows11"],
    "Education": ["#Ø³Ù„Ø³Ù„Ø©_Ø¬ÙˆØ¬Ù„", "#Ù†ØµØ§Ø¦Ø­_ØªÙ‚Ù†ÙŠØ©", "#ØªØ¹Ù„Ù…_Ø§Ù„Ø°ÙƒØ§Ø¡_Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"]
}

STRICT_SYSTEM_PROMPT = """
Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± ØªÙ‚Ù†ÙŠ Ù…Ø­ØªØ±Ù. ØµÙØº Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø±Ø³Ù…ÙŠØ©.
Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯:
1. Ù…Ø«Ù„Ø« Ø§Ù„Ù‚ÙŠÙ…Ø©: [TWEET_1] Ø®ÙØ·Ù‘Ø§ÙØŒ [TWEET_2] Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø³Ø±ØŒ [POLL_QUESTION] ØªÙØ§Ø¹Ù„.
2. Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø±ØµÙŠÙ†Ø©ØŒ Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†.
3. Ù…Ù…Ù†ÙˆØ¹ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ ÙƒØªØ§Ø¨Ø© Ø£ÙŠ Ù‡Ø§Ø´ØªØ§ØºØ§Øª (#) Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†ØµØ› Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ø¨Ø±Ù…Ø¬ÙŠØ§Ù‹.
"""

class TechEliteFinal2026:
    def __init__(self):
        self.max_daily = 4
        self._init_db()
        self._init_clients()

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS news (
                    hash TEXT PRIMARY KEY, title TEXT, category TEXT, 
                    keywords TEXT, hashtags TEXT, published_at TEXT
                )
            """)

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _clean_url(self, url):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„Ù‡ Ø¹Ù„Ù‰ Ù…ØªØµÙØ­Ø§Øª Ø§Ù„Ø¬ÙˆØ§Ù„ ÙˆØªÙˆÙŠØªØ±"""
        parsed = urlparse(url)
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}"

    def post_thread(self, ai_text, url, title, cat, keywords):
        # 1. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø·
        clean_url = self._clean_url(url)
        # 2. Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ù‡Ø§Ø´ØªØ§ØºØ§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù‚Ø¯ ÙŠÙˆÙ„Ø¯Ù‡Ø§ Ø§Ù„Ù€ AI
        clean_ai_text = re.sub(r'#\w+', '', ai_text).strip()
        parts = re.findall(r'\[.*?\](.*?)(?=\[|$)', clean_ai_text, re.S)
        if len(parts) < 3: return False
        
        # 3. Ø§Ø®ØªÙŠØ§Ø± Ù‡Ø§Ø´ØªØ§ØºØ§Øª Ù…ÙˆØ«ÙˆÙ‚Ø©
        tags = " ".join(random.sample(APPROVED_HASHTAGS.get(cat, ["#ØªÙ‚Ù†ÙŠØ©"]), 2))
        last_id = None
        
        for i, content in enumerate(parts[:3]):
            text = f"{i+1}/ {content.strip()}"
            if i == 1: text += f"\n\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø±Ø³Ù…ÙŠ:\n{clean_url}" # Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙØ¹ÙŠÙ„
            if i == 2: text += f"\n\n{tags}"
            
            try:
                if i == 2 and len(parts) >= 4:
                    opts = [o.strip() for o in parts[3].split('-') if o.strip()][:4]
                    res = self.x_client.create_tweet(text=text[:280], poll_options=opts, poll_duration_minutes=1440, in_reply_to_tweet_id=last_id)
                else:
                    res = self.x_client.create_tweet(text=text[:280], in_reply_to_tweet_id=last_id)
                last_id = res.data["id"]
                time.sleep(80) # Ø²ÙŠØ§Ø¯Ø© ÙˆÙ‚Øª Ø§Ù„Ø£Ù…Ø§Ù†
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£ Ù†Ø´Ø±: {e}")
                break
        
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("INSERT OR REPLACE INTO news VALUES (?, ?, ?, ?, ?, ?)", 
                         (hashlib.sha256(title.encode()).hexdigest(), title, cat, keywords, tags, datetime.now().isoformat()))
        return True

    def run_cycle(self):
        # (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… _clean_url)
        pass

if __name__ == "__main__":
    bot = TechEliteFinal2026()
    # Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙŠØ¯ÙˆÙŠ ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    bot.run_cycle()
