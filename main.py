import os, sqlite3, logging, hashlib, time, re, random
from datetime import datetime
import tweepy, feedparser
from dotenv import load_dotenv
from openai import OpenAI
from tweepy.errors import TweepyException, TooManyRequests

load_dotenv()
DB_FILE = "news.db"
LOG_FILE = "error.log"
MAX_DAILY = 3 
MAX_LEN = 280

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª (Logs)
logging.basicConfig(
    level=logging.INFO,
    format="ğŸ›¡ï¸ %(asctime)s - %(message)s",
    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler()]
)

# 1. Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ ÙˆØ§Ù„Ù‚ÙˆØ§Ø¦Ù… (Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)
KNOWLEDGE_BASE = {
    "microsoft": "Ø®Ø¨Ø§ÙŠØ§ Microsoft 365ØŒ Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©ØŒ Ù…ÙŠØ²Ø§Øª Windows 11.",
    "x_profit": "Ø£Ø±Ø¨Ø§Ø­ Ø§Ù„Ø±Ø¯ÙˆØ¯ (0.2 Ø³Ù†Øª)ØŒ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ«Ù‚ÙŠÙ†ØŒ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¢Ø®Ø± 20 Ù…Ù†Ø´ÙˆØ±.",
    "google_ai": "Ø³Ù„Ø³Ù„Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠØ© Ø¯ÙˆØ±ÙŠØ© ØªØ´Ø±Ø­ Ø£Ø¯ÙˆØ§Øª Ø¬ÙˆØ¬Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ©."
}

GOOGLE_AI_TOOLS = [
    {"name": "Google Gemini", "focus": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø© ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ØªÙ‚Ø¯Ù…."},
    {"name": "Google Vertex AI", "focus": "ØªØ·ÙˆÙŠØ± Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ù…Ø¤Ø³Ø³Ø§Øª."},
    {"name": "Google NotebookLM", "focus": "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø´Ø®ØµÙŠØ©."},
    {"name": "Google Imagen 3", "focus": "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø¯Ù‚Ø©."},
    {"name": "Google Workspace AI", "focus": "Ø±ÙØ¹ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø°ÙƒÙŠØ©."}
]

SOURCES = [
    "https://venturebeat.com/category/ai/feed/", 
    "https://www.technologyreview.com/topic/artificial-intelligence/feed/",
    "https://windowscentral.com/rss.xml", 
    "https://techcrunch.com/feed/",
    "https://www.theverge.com/rss/index.xml"
]

# 2. Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø´Ø§Ù…Ù„ (ÙŠØ¬Ù…Ø¹ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø¨ØªÙƒØ± + Ø§Ù„Ù‡Ø§Ø´ØªØ§ØºØ§Øª + ØªÙ†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰)
STRICT_SYSTEM_PROMPT = f"""
Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± (TechElite). ØµÙØº Ù…Ø­ØªÙˆÙ‰ ØªÙ‚Ù†ÙŠØ§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ø¬Ø¯Ø§Ù‹.
Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©: {KNOWLEDGE_BASE}
Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù‚Ø·Ø¹ÙŠØ©:
1. Ù†ÙˆØ¹ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø±Ø¶ Ø¨ÙŠÙ† (Ø«Ø±ÙŠØ¯ Ø¥Ø®Ø¨Ø§Ø±ÙŠØŒ Ù‚Ø§Ø¦Ù…Ø© Top 5ØŒ Ù†ØµÙŠØ­Ø© ØªÙ‚Ù†ÙŠØ©).
2. Ø§Ø³ØªØ®Ø¯Ù… 'Ù…Ø«Ù„Ø« Ø§Ù„Ù‚ÙŠÙ…Ø©': [TWEET_1] Ø®ÙØ·Ù‘Ø§Ù Ø¬Ø°Ø§Ø¨ØŒ [TWEET_2] Ø¬ÙˆÙ‡Ø± Ø§Ù„Ø³Ø±ØŒ [POLL_QUESTION] ØªÙØ§Ø¹Ù„.
3. Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¯ÙˆØ¯Ø© ÙˆØ±ØµÙŠÙ†Ø©ØŒ Ù…Ø¹ Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ† (Term).
4. ØªÙˆÙ„ÙŠØ¯ 3 Ù‡Ø§Ø´ØªØ§ØºØ§Øª Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ø°ÙƒÙŠØ© ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø«Ø±ÙŠØ¯.
5. Ù…Ù†Ø¹ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØµÙŠÙ†ÙŠØ© Ø£Ùˆ HTML ØªÙ…Ø§Ù…Ø§Ù‹.
"""

class TechEliteFinalMaster:
    def __init__(self):
        self._init_db()
        self._init_clients()

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")

    def _init_clients(self):
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    def _is_clean(self, text):
        return not re.search(r'[\u4e00-\u9fff]|<.*?>', text)

    def post_thread(self, ai_text, url):
        parts = re.findall(r'\[.*?\](.*?)(?=\[|$)', ai_text, re.S)
        if len(parts) < 3: return False

        last_id = None
        for i, content in enumerate(parts[:3]):
            text = f"{i+1}/ {content.strip()}"
            if i == 1: text += f"\n\nğŸ”— {url}"
            
            try:
                if i == 2 and len(parts) >= 4:
                    opts = [o.strip() for o in parts[3].split('-') if o.strip()][:4]
                    res = self.x_client.create_tweet(text=text[:MAX_LEN], poll_options=opts, poll_duration_minutes=1440, in_reply_to_tweet_id=last_id)
                else:
                    res = self.x_client.create_tweet(text=text[:MAX_LEN], in_reply_to_tweet_id=last_id)
                
                last_id = res.data["id"]
                time.sleep(70) 
            except TooManyRequests as e:
                wait = int(e.response.headers.get('Retry-After', 300))
                logging.warning(f"âš ï¸ Ø²Ø­Ø§Ù… APIØŒ Ø§Ù†ØªØ¸Ø§Ø± {wait} Ø«Ø§Ù†ÙŠØ©")
                time.sleep(wait)
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£ Ù†Ø´Ø±: {e}")
        return True

    def run_cycle(self):
        current_day = datetime.now().strftime('%A')
        published_count = 0
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()

        # Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡: ØªÙØ¹ÙŠÙ„ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø³Ù„Ø³Ù„Ø© Ø¬ÙˆØ¬Ù„ AI
        if current_day == "Wednesday":
            week_idx = datetime.now().isocalendar()[1] % len(GOOGLE_AI_TOOLS)
            tool = GOOGLE_AI_TOOLS[week_idx]
            ai_text = self._generate_ai(f"Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹: Ø£Ø¯Ø§Ø© {tool['name']}. Ø§Ù„ØªØ±ÙƒÙŠØ²: {tool['focus']}. Ø§Ø´Ø±Ø­ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª ÙˆÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ.")
            if ai_text and self.post_thread(ai_text, "https://ai.google/"):
                published_count = 1

        # Ø§Ù„Ù†Ø´Ø± Ø§Ù„ÙŠÙˆÙ…ÙŠ (Ø£Ø®Ø¨Ø§Ø± + Ù‚ÙˆØ§Ø¦Ù… + Ù†ØµØ§Ø¦Ø­)
        random.shuffle(SOURCES)
        for url in SOURCES:
            if published_count >= MAX_DAILY: break
            feed = feedparser.parse(url)
            for e in feed.entries[:5]:
                if published_count >= MAX_DAILY: break
                h = hashlib.sha256(e.title.encode()).hexdigest()
                cursor.execute("SELECT 1 FROM news WHERE hash=?", (h,))
                if not cursor.fetchone():
                    ai_text = self._generate_ai(f"Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {e.title}\nØ§Ù„ØªÙØ§ØµÙŠÙ„: {getattr(e, 'summary', '')}")
                    if ai_text and self.post_thread(ai_text, e.link):
                        cursor.execute("INSERT INTO news VALUES (?, ?, ?)", (h, e.title, datetime.now().isoformat()))
                        conn.commit()
                        published_count += 1
        conn.close()

    def _generate_ai(self, context):
        try:
            r = self.ai_client.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role":"system","content":STRICT_SYSTEM_PROMPT},{"role":"user","content":context}],
                temperature=0.1
            )
            content = r.choices[0].message.content.strip()
            return content if self._is_clean(content) else None
        except Exception as e:
            logging.error(f"ğŸ¤– Ø®Ø·Ø£ AI: {e}"); return None

if __name__ == "__main__":
    TechEliteFinalMaster().run_cycle()
