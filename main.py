import os
import time
import json
import hashlib
import logging
import requests
import random
from datetime import datetime
from typing import Optional
from urllib.parse import urlparse

import tweepy
import feedparser
from google import genai

# =========================
# GLOBAL SOURCES GRID (Ù…ØµØ§Ø¯Ø± Ø¹Ø§Ù„Ù…ÙŠØ© Ù…ÙˆØ«ÙˆÙ‚Ø©)
# =========================

SOURCES = [
    "https://ai.googleblog.com/atom.xml",
    "https://www.microsoft.com/en-us/research/feed/",
    "https://engineering.fb.com/feed/",
    "https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml",
    "https://www.theguardian.com/technology/rss",
    "https://www.reutersagency.com/feed/?best-topics=technology&post_type=best",
    "https://www.technologyreview.com/feed/",
    "https://spectrum.ieee.org/rss/fulltext",
    "https://arstechnica.com/feed/",
    "https://www.wired.com/feed/rss"
]

STATE_FILE = "state.json"
MAX_POSTS = 2
POST_DELAY = 120

# ÙÙ„Ø§ØªØ± Ø§Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„ØµØ§Ø±Ù…Ø©
BLACKLIST_TOPICS = ["war", "politics", "election", "crime", "court", "lawsuit", "military", "celebrity"]

class TechEliteFinalBot:

    def __init__(self):
        self._init_logging()
        self._load_env()
        self._init_clients()
        self.state = self._load_state()

    def _init_logging(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s | %(message)s", datefmt="%Y-%m-%d %H:%M")

    def _load_env(self):
        # ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙÙŠ GitHub Secrets
        self.GEMINI_KEY = os.getenv("GEMINI_KEY")
        self.X_API_KEY = os.getenv("X_API_KEY")
        self.X_API_SECRET = os.getenv("X_API_SECRET")
        self.X_ACCESS_TOKEN = os.getenv("X_ACCESS_TOKEN")
        self.X_ACCESS_SECRET = os.getenv("X_ACCESS_SECRET")
        self.X_BEARER = os.getenv("X_BEARER_TOKEN")

    def _init_clients(self):
        self.ai = genai.Client(api_key=self.GEMINI_KEY)
        auth = tweepy.OAuth1UserHandler(self.X_API_KEY, self.X_API_SECRET, self.X_ACCESS_TOKEN, self.X_ACCESS_SECRET)
        self.x_api_v1 = tweepy.API(auth)
        self.x_client_v2 = tweepy.Client(
            bearer_token=self.X_BEARER,
            consumer_key=self.X_API_KEY,
            consumer_secret=self.X_API_SECRET,
            access_token=self.X_ACCESS_TOKEN,
            access_token_secret=self.X_ACCESS_SECRET
        )

    def _load_state(self):
        default = {"hashes": [], "replied_ids": [], "blacklist": [], "weekly_titles": [], "last_summary_date": ""}
        if not os.path.exists(STATE_FILE): return default
        try:
            with open(STATE_FILE, "r", encoding="utf-8") as f:
                return {**default, **json.load(f)}
        except: return default

    def _save_state(self):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def _upload_media(self, url: str) -> Optional[str]:
        if not url: return None
        try:
            filename = "media_content.jpg"
            res = requests.get(url, stream=True, timeout=10)
            if res.status_code == 200:
                with open(filename, 'wb') as f:
                    for chunk in res: f.write(chunk)
                media = self.x_api_v1.media_upload(filename)
                os.remove(filename)
                return media.media_id
        except: return None

    def safe_gemini(self, prompt: str) -> Optional[str]:
        try:
            res = self.ai.models.generate_content(model="gemini-2.0-flash", contents=prompt)
            return res.text.strip()
        except: return None

    def generate_content_with_verification(self, title: str, summary: str, source: str) -> Optional[str]:
        """Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØµÙŠØ§ØºØ© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ ØªÙ‚ÙŠÙŠØ¯ ØµØ§Ø±Ù… Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
        draft_prompt = (
            f"Ø£Ù†Øª Ù…Ø­Ø±Ø± ØªÙ‚Ù†ÙŠ Ù…Ø¯Ù‚Ù‚. Ø­ÙˆÙ„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ ØªØºØ±ÙŠØ¯Ø© Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´Ø±ÙŠØ© Ù…Ø­ÙØ²Ø©.\n"
            f"Ø§Ù„Ø®Ø¨Ø±: {title}\nØ§Ù„Ù…Ù„Ø®Øµ: {summary}\n\n"
            f"âš ï¸ Ø´Ø±ÙˆØ· Ø¹Ø¯Ù… Ø§Ù„Ù‡Ù„ÙˆØ³Ø©:\n"
            f"- Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø£Ùˆ Ø±Ù‚Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ Ø£Ø¹Ù„Ø§Ù‡.\n"
            f"- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†.\n"
            f"Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø©:\n"
            f"1. Ø¨Ø¯Ø§ÙŠØ© Ø®Ø§Ø·ÙØ© (Hook).\n"
            f"2. Ø´Ø±Ø­ Ø§Ù„ÙØ§Ø¦Ø¯Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø®Ø¨Ø±.\n"
            f"3. Ù†ØµÙŠØ­Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© (Pro Tip) Ù…Ø³ØªÙˆØ­Ø§Ø© Ù…Ù† Ø§Ù„Ù†Øµ.\n"
            f"4. Ø³Ø¤Ø§Ù„ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…ØªØ§Ø¨Ø¹ÙŠÙ† + Ø§Ù„Ù…ØµØ¯Ø±: {source}"
        )
        draft = self.safe_gemini(draft_prompt)
        if not draft: return None

        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬ (Double Check)
        verify_prompt = (
            f"Ø¨ØµÙØªÙƒ Ù…Ø±Ø§Ù‚Ø¨ Ø¬ÙˆØ¯Ø©ØŒ Ù‚Ø§Ø±Ù† Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ.\n"
            f"Ø§Ù„ØªØºØ±ÙŠØ¯Ø©: {draft}\n"
            f"Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {summary}\n\n"
            f"Ù‡Ù„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙˆØ§Ø­Ø¯Ø© (Ø­ØªÙ‰ Ù„Ùˆ ØµØºÙŠØ±Ø©) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†ØµØŸ\n"
            f"Ø£Ø¬Ø¨ Ø¨ÙƒÙ„Ù…Ø© 'Ø³Ù„ÙŠÙ…' Ù„Ù„Ù†Ø´Ø±ØŒ Ø£Ùˆ 'ØªØ¹Ø¯ÙŠÙ„' Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ø®ØªÙ„Ù‚Ø©."
        )
        check = self.safe_gemini(verify_prompt)
        
        return draft if check and "Ø³Ù„ÙŠÙ…" in check else None

    def run(self):
        logging.info("Cycle Started - Anti-Hallucination Mode")
        posted = 0
        random_sources = random.sample(SOURCES, len(SOURCES))
        
        for src in random_sources:
            feed = feedparser.parse(src)
            for entry in feed.entries[:15]:
                if posted >= MAX_POSTS: break
                
                title, summary, link = entry.title.strip(), getattr(entry, "summary", ""), entry.link
                h = hashlib.md5(title.encode()).hexdigest()

                if h in self.state["hashes"]: continue

                # ÙÙ„ØªØ±Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ØºÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ÙˆØ§Ù„Ø³ÙŠØ§Ø³ÙŠ
                check_prompt = f"Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± ØªÙ‚Ù†ÙŠ/Ø¹Ù„Ù…ÙŠ Ø¨Ø­Øª ÙˆØ¨Ø¹ÙŠØ¯ Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ø³Ø©ØŸ Ø£Ø¬Ø¨ Ø¨Ù€ Ù†Ø¹Ù…/Ù„Ø§: {title}"
                if "Ù†Ø¹Ù…" not in (self.safe_gemini(check_prompt) or ""): continue

                # ØµÙŠØ§ØºØ© ÙˆØªØ­Ù‚Ù‚
                text = self.generate_content_with_verification(title, summary, urlparse(link).netloc)
                if not text:
                    logging.warning(f"âš ï¸ ØªÙ… Ø¥Ù„ØºØ§Ø¡ ØªØºØ±ÙŠØ¯Ø© Ù„Ù„Ø§Ø´ØªØ¨Ø§Ù‡ ÙÙŠ Ø¯Ù‚ØªÙ‡Ø§: {title[:30]}")
                    continue

                try:
                    media_url = None
                    if 'media_content' in entry: media_url = entry.media_content[0]['url']
                    elif 'links' in entry:
                        for l in entry.links:
                            if 'image' in l.get('type', ''): media_url = l.get('href')
                    
                    media_id = self._upload_media(media_url)
                    self.x_client_v2.create_tweet(text=text[:280], media_ids=[media_id] if media_id else None)
                    
                    self.state["hashes"].append(h)
                    self.state["weekly_titles"].append(title)
                    self._save_state()
                    posted += 1
                    time.sleep(POST_DELAY)
                    logging.info(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„Ù†Ø´Ø±: {title[:30]}")
                except Exception as e: logging.error(f"X Error: {e}")

if __name__ == "__main__":
    TechEliteFinalBot().run()
