import os
import sqlite3
import logging
import hashlib
import time
import re
import random
from datetime import datetime, timezone

import tweepy
import feedparser
from dotenv import load_dotenv
from openai import OpenAI
from google import genai

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
DB_FILE = "news.db"

class TechEliteBot:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")
        conn.commit()
        conn.close()

    def _init_clients(self):
        g_api = os.getenv("GEMINI_KEY")
        self.gemini_client = genai.Client(api_key=g_api) if g_api else None
        self.ai_qwen = OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1")
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )

    # --- [Ù…Ø­Ø±Ùƒ Ø§Ù„ÙˆØ³ÙˆÙ… Ø§Ù„Ù‡Ø¬ÙŠÙ† ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ] ---

    def extract_hybrid_tags(self, title, description, ai_suggested_content=""):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ³ÙˆÙ… Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + Ø§Ù„Ù…Ø­ØªÙˆÙ‰ + Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ù€ AI Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±"""
        keywords = {
            "apple": "#Ø¢Ø¨Ù„ #Apple", "iphone": "#Ø¢ÙŠÙÙˆÙ† #iPhone", "nvidia": "#Ø§Ù†ÙÙŠØ¯ÙŠØ§ #Nvidia",
            "ai": "#Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #AI", "tesla": "#ØªØ³Ù„Ø§ #Tesla", "leak": "#ØªØ³Ø±ÙŠØ¨Ø§Øª",
            "samsung": "#Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ #Samsung", "openai": "#OpenAI", "vision": "#VisionPro",
            "m4": "#AppleSilicon", "m5": "#AppleSilicon", "google": "#Google",
            "meta": "#Meta", "space": "#Ø§Ù„ÙØ¶Ø§Ø¡", "crypto": "#Ø¹Ù…Ù„Ø§Øª_Ø±Ù‚Ù…ÙŠØ©"
        }
        
        tags = set(["#ØªÙ‚Ù†ÙŠØ©", "#Ø³Ø¨Ù‚_ØªÙ‚Ù†ÙŠ"])
        full_text = (title + " " + description + " " + ai_suggested_content).lower()

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ³ÙˆÙ… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        for key, val in keywords.items():
            if key in full_text:
                for v in val.split(): tags.add(v)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙƒØªØ¨Ù‡Ø§ Ø§Ù„Ù€ AI ÙÙŠ Ø±Ø¯Ù‡
        ai_tags = re.findall(r'#\w+', ai_suggested_content)
        for t in ai_tags: tags.add(t)

        return " ".join(list(tags)[:7]) # Ù†ÙƒØªÙÙŠ Ø¨Ù€ 7 ÙˆØ³ÙˆÙ… ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰

    def calculate_credibility(self, source_name, entry):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©: Ù…ØµØ¯Ø± (40%) + Ù…Ø­ØªÙˆÙ‰ (40%) + Ø­Ø¯Ø§Ø«Ø© (20%)"""
        score = 55
        authority = {"The Verge": 30, "9to5Mac": 25, "MacRumors": 25, "Bloomberg": 35, "Reuters": 35}
        score += authority.get(source_name, 10)
        content = (entry.title + " " + entry.get('description', '')).lower()
        if any(w in content for w in ["official", "confirmed", "announces", "Ø±Ø³Ù…ÙŠØ§Ù‹"]): score += 20
        if any(w in content for w in ["leak", "rumor", "ØªØ³Ø±ÙŠØ¨", "Ø¥Ø´Ø§Ø¹Ø©"]): score -= 25
        return round(max(1, min(100, score)) / 10, 1)

    # --- [Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù†Ø´Ø±] ---

    def safe_post(self, text, reply_id=None):
        for i in range(3):
            try:
                res = self.x_client.create_tweet(text=text, in_reply_to_tweet_id=reply_id)
                return res.data['id']
            except tweepy.TooManyRequests:
                time.sleep((i + 1) * 60)
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£: {e}")
                break
        return None

    def ai_ask(self, system_prompt, user_content):
        try:
            res = self.gemini_client.models.generate_content(model='gemini-1.5-flash', contents=f"{system_prompt}\n\n{user_content}")
            return res.text.strip()
        except:
            try:
                res = self.ai_qwen.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}])
                return res.choices[0].message.content.strip()
            except: return None

    def post_thread(self, content, title, description):
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø«Ø±ÙŠØ¯ ÙˆØ¯Ù…Ø¬ Ø§Ù„ÙˆØ³ÙˆÙ… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        raw_parts = re.split(r'\n\s*\d+[\/\.\)]\s*|\n\n', content.strip())
        tweets = [t.strip()import os
import sqlite3
import logging
import hashlib
import time
import re
import random
from datetime import datetime, timezone

import tweepy
import feedparser
from dotenv import load_dotenv
from openai import OpenAI
from google import genai

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
DB_FILE = "news.db"

class TechEliteBot:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")
        conn.commit()
        conn.close()

    def _init_clients(self):
        g_api = os.getenv("GEMINI_KEY")
        self.gemini_client = genai.Client(api_key=g_api) if g_api else None
        self.ai_qwen = OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1")
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )

    # --- [Ù…Ø­Ø±Ùƒ Ø§Ù„ÙˆØ³ÙˆÙ… Ø§Ù„Ù‡Ø¬ÙŠÙ† ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ] ---

    def extract_hybrid_tags(self, title, description, ai_suggested_content=""):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ³ÙˆÙ… Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + Ø§Ù„Ù…Ø­ØªÙˆÙ‰ + Ù…Ù‚ØªØ±Ø­Ø§Øª Ø§Ù„Ù€ AI Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ù†ØªØ´Ø§Ø±"""
        keywords = {
            "apple": "#Ø¢Ø¨Ù„ #Apple", "iphone": "#Ø¢ÙŠÙÙˆÙ† #iPhone", "nvidia": "#Ø§Ù†ÙÙŠØ¯ÙŠØ§ #Nvidia",
            "ai": "#Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #AI", "tesla": "#ØªØ³Ù„Ø§ #Tesla", "leak": "#ØªØ³Ø±ÙŠØ¨Ø§Øª",
            "samsung": "#Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ #Samsung", "openai": "#OpenAI", "vision": "#VisionPro",
            "m4": "#AppleSilicon", "m5": "#AppleSilicon", "google": "#Google",
            "meta": "#Meta", "space": "#Ø§Ù„ÙØ¶Ø§Ø¡", "crypto": "#Ø¹Ù…Ù„Ø§Øª_Ø±Ù‚Ù…ÙŠØ©"
        }
        
        tags = set(["#ØªÙ‚Ù†ÙŠØ©", "#Ø³Ø¨Ù‚_ØªÙ‚Ù†ÙŠ"])
        full_text = (title + " " + description + " " + ai_suggested_content).lower()

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØ³ÙˆÙ… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        for key, val in keywords.items():
            if key in full_text:
                for v in val.split(): tags.add(v)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙƒØªØ¨Ù‡Ø§ Ø§Ù„Ù€ AI ÙÙŠ Ø±Ø¯Ù‡
        ai_tags = re.findall(r'#\w+', ai_suggested_content)
        for t in ai_tags: tags.add(t)

        return " ".join(list(tags)[:7]) # Ù†ÙƒØªÙÙŠ Ø¨Ù€ 7 ÙˆØ³ÙˆÙ… ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰

    def calculate_credibility(self, source_name, entry):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØµØ¯Ø§Ù‚ÙŠØ©: Ù…ØµØ¯Ø± (40%) + Ù…Ø­ØªÙˆÙ‰ (40%) + Ø­Ø¯Ø§Ø«Ø© (20%)"""
        score = 55
        authority = {"The Verge": 30, "9to5Mac": 25, "MacRumors": 25, "Bloomberg": 35, "Reuters": 35}
        score += authority.get(source_name, 10)
        content = (entry.title + " " + entry.get('description', '')).lower()
        if any(w in content for w in ["official", "confirmed", "announces", "Ø±Ø³Ù…ÙŠØ§Ù‹"]): score += 20
        if any(w in content for w in ["leak", "rumor", "ØªØ³Ø±ÙŠØ¨", "Ø¥Ø´Ø§Ø¹Ø©"]): score -= 25
        return round(max(1, min(100, score)) / 10, 1)

    # --- [Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù†Ø´Ø±] ---

    def safe_post(self, text, reply_id=None):
        for i in range(3):
            try:
                res = self.x_client.create_tweet(text=text, in_reply_to_tweet_id=reply_id)
                return res.data['id']
            except tweepy.TooManyRequests:
                time.sleep((i + 1) * 60)
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£: {e}")
                break
        return None

    def ai_ask(self, system_prompt, user_content):
        try:
            res = self.gemini_client.models.generate_content(model='gemini-1.5-flash', contents=f"{system_prompt}\n\n{user_content}")
            return res.text.strip()
        except:
            try:
                res = self.ai_qwen.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}])
                return res.choices[0].message.content.strip()
            except: return None

    def post_thread(self, content, title, description):
        """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø«Ø±ÙŠØ¯ ÙˆØ¯Ù…Ø¬ Ø§Ù„ÙˆØ³ÙˆÙ… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        raw_parts = re.split(r'\n\s*\d+[\/\.\)]\s*|\n\n', content.strip())
        tweets = [t.strip()
