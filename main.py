import os
import sqlite3
import logging
import hashlib
import time
import re
import random
from datetime import datetime, timezone

import tweepy
import feedparser
from dotenv import load_dotenv
from openai import OpenAI
from google import genai

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
DB_FILE = "news.db"

class TechEliteBot:
    def __init__(self):
        logging.basicConfig(level=logging.INFO, format="ðŸ›¡ï¸ %(message)s")
        self._init_db()
        self._init_clients()

    def _init_db(self):
        conn = sqlite3.connect(DB_FILE)
        conn.execute("CREATE TABLE IF NOT EXISTS news (hash TEXT PRIMARY KEY, title TEXT, published_at TEXT)")
        conn.commit()
        conn.close()

    def _init_clients(self):
        g_api = os.getenv("GEMINI_KEY")
        self.gemini_client = genai.Client(api_key=g_api) if g_api else None
        self.ai_qwen = OpenAI(api_key=os.getenv("OPENROUTER_API_KEY"), base_url="https://openrouter.ai/api/v1")
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )

    def extract_hybrid_tags(self, title, description, ai_suggested_content=""):
        keywords = {
            "apple": "#Ø¢Ø¨Ù„ #Apple", "iphone": "#Ø¢ÙŠÙÙˆÙ† #iPhone", "nvidia": "#Ø§Ù†ÙÙŠØ¯ÙŠØ§ #Nvidia",
            "ai": "#Ø°ÙƒØ§Ø¡_Ø§ØµØ·Ù†Ø§Ø¹ÙŠ #AI", "tesla": "#ØªØ³Ù„Ø§ #Tesla", "leak": "#ØªØ³Ø±ÙŠØ¨Ø§Øª",
            "samsung": "#Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ #Samsung", "openai": "#OpenAI", "vision": "#VisionPro",
            "m4": "#AppleSilicon", "m5": "#AppleSilicon", "google": "#Google",
            "meta": "#Meta", "space": "#Ø§Ù„ÙØ¶Ø§Ø¡", "crypto": "#Ø¹Ù…Ù„Ø§Øª_Ø±Ù‚Ù…ÙŠØ©"
        }
        tags = set(["#ØªÙ‚Ù†ÙŠØ©", "#Ø³Ø¨Ù‚_ØªÙ‚Ù†ÙŠ"])
        full_text = (title + " " + description + " " + (ai_suggested_content or "")).lower()

        for key, val in keywords.items():
            if key in full_text:
                for v in val.split(): tags.add(v)

        ai_tags = re.findall(r'#\w+', ai_suggested_content or "")
        for t in ai_tags: tags.add(t)
        return " ".join(list(tags)[:7])

    def calculate_credibility(self, source_name, entry):
        score = 55
        authority = {"The Verge": 30, "9to5Mac": 25, "MacRumors": 25, "Bloomberg": 35, "Reuters": 35}
        score += authority.get(source_name, 10)
        content = (entry.title + " " + (entry.get('description', ''))).lower()
        if any(w in content for w in ["official", "confirmed", "announces", "Ø±Ø³Ù…ÙŠØ§Ù‹"]): score += 20
        if any(w in content for w in ["leak", "rumor", "ØªØ³Ø±ÙŠØ¨", "Ø¥Ø´Ø§Ø¹Ø©"]): score -= 25
        return round(max(1, min(100, score)) / 10, 1)

    def safe_post(self, text, reply_id=None):
        for i in range(3):
            try:
                res = self.x_client.create_tweet(text=text, in_reply_to_tweet_id=reply_id)
                return res.data['id']
            except tweepy.TooManyRequests:
                time.sleep((i + 1) * 60)
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£: {e}")
                break
        return None

    def ai_ask(self, system_prompt, user_content):
        try:
            res = self.gemini_client.models.generate_content(model='gemini-1.5-flash', contents=f"{system_prompt}\n\n{user_content}")
            return res.text.strip()
        except:
            try:
                res = self.ai_qwen.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}])
                return res.choices[0].message.content.strip()
            except: return None

    def post_thread(self, content, title, description):
        raw_parts = re.split(r'\n\s*\d+[\/\.\)]\s*|\n\n', content.strip())
        tweets = [t.strip() for t in raw_parts if len(t.strip()) > 10]
        
        last_part = tweets[-1] if tweets and "#" in tweets[-1] else ""
        final_tags = self.extract_hybrid_tags(title, description, last_part)
        if tweets and "#" in tweets[-1]: tweets.pop()

        last_id = None
        for i, tweet in enumerate(tweets[:5]):
            text = f"{i+1}/ {tweet}"
            if i == len(tweets[:5]) - 1
