import os
import time
import random
import hashlib
import yaml
import sqlite3
import logging
from datetime import datetime

# Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
import tweepy
import google.generativeai as genai
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# -------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬ (Logging)
# -------------------------
logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(message)s",
    level=logging.INFO
)
logger = logging.getLogger("SovereignBot")

# -------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ¦Ø©
# -------------------------
def load_config():
    with open("utils/config.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

cfg = load_config()

# -------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª (X & Gemini)
# -------------------------
x_client = tweepy.Client(
    bearer_token=os.getenv("X_BEARER_TOKEN"),
    consumer_key=os.getenv("X_API_KEY"),
    consumer_secret=os.getenv("X_API_SECRET"),
    access_token=os.getenv("X_ACCESS_TOKEN"),
    access_token_secret=os.getenv("X_ACCESS_SECRET"),
    wait_on_rate_limit=True
)

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# -------------------------
# Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# -------------------------
def get_db_conn():
    conn = sqlite3.connect(cfg['bot']['database_path'], timeout=20)
    cursor = conn.cursor()
    cursor.execute("CREATE TABLE IF NOT EXISTS meta (key TEXT PRIMARY KEY, value TEXT)")
    cursor.execute("CREATE TABLE IF NOT EXISTS replies (tweet_id TEXT PRIMARY KEY, hash TEXT)")
    cursor.execute("CREATE TABLE IF NOT EXISTS history (hash TEXT PRIMARY KEY, content TEXT)")
    conn.commit()
    return conn, cursor

def get_meta(key, default=None):
    conn, cursor = get_db_conn()
    cursor.execute("SELECT value FROM meta WHERE key=?", (key,))
    row = cursor.fetchone()
    conn.close()
    return row[0] if row else default

def update_meta(key, value):
    conn, cursor = get_db_conn()
    cursor.execute("INSERT OR REPLACE INTO meta(key, value) VALUES(?,?)", (key, value))
    conn.commit()
    conn.close()

def record_history(content):
    h = hashlib.md5(content.encode()).hexdigest()
    conn, cursor = get_db_conn()
    cursor.execute("INSERT OR IGNORE INTO history (hash, content) VALUES (?,?)", (h, content))
    conn.commit()
    conn.close()
    return h

def is_duplicate(content):
    h = hashlib.md5(content.encode()).hexdigest()
    conn, cursor = get_db_conn()
    cursor.execute("SELECT 1 FROM history WHERE hash=?", (h,))
    result = cursor.fetchone()
    conn.close()
    return result is not None

# -------------------------
# Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
# -------------------------
def call_gemini_model(prompt):
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        full_prompt = f"{cfg['prompts']['system_core']}\n\nØ§Ù„Ø³ÙŠØ§Ù‚: {prompt}"
        response = model.generate_content(full_prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"â™Š Gemini Error: {e}")
        return None

def call_grok_logic(prompt):
    prompt = f"ØªÙ‚Ù…Øµ Ø¯ÙˆØ± GrokØŒ ÙƒÙ† Ø³Ø§Ø®Ø±Ø§Ù‹ ÙˆØ°ÙƒÙŠØ§Ù‹ Ø­ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {prompt}"
    return call_gemini_model(prompt)

def get_ai_response(prompt):
    response = call_gemini_model(prompt)
    if not response:
        response = call_grok_logic(prompt)
    if not response:
        unique_id = hashlib.md5(str(time.time()).encode()).hexdigest()[:4]
        response = f"Ø§Ù„Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙŠ Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ù…ÙØªØ§Ø­ ØªÙ…ÙƒÙŠÙ† Ø§Ù„ÙØ±Ø¯. [{unique_id}]"
    return response[:280]

# -------------------------
# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ±Ù†Ø¯Ø§Øª Ø§Ù„Ù„Ø­Ø¸ÙŠØ©
# -------------------------
def fetch_trending_topics():
    try:
        trends = x_client.get_place_trends(id=1)  # WOEID Ø¹Ø§Ù„Ù…ÙŠ
        topics = [t["name"] for t in trends[0]["trends"]]
        return topics[:10]
    except Exception as e:
        logger.error(f"âš ï¸ Fetch Trending Error: {e}")
        return []

def generate_trend_tweet():
    topics = fetch_trending_topics()
    if not topics:
        return None
    topic = random.choice(topics)
    prompt = f"Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„ØªØ±Ù†Ø¯ Ø§Ù„Ø­Ø¯ÙŠØ« Ø¨Ø¹Ù†Ø§ÙŠØ© ÙˆÙ‚Ø¯Ù… Ù…Ø­ØªÙˆÙ‰ ØªÙ‚Ù†ÙŠ Ø£ØµÙŠÙ„ (AIØŒ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©ØŒ Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§ØªØŒ Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©): {topic}"
    tweet = get_ai_response(prompt)
    if is_duplicate(tweet):
        logger.info("âš ï¸ Duplicate trend content skipped.")
        return None
    return tweet

def dispatch_trend_tweet():
    today = datetime.now().date().isoformat()
    count = int(get_meta(f"count_{today}", "0"))
    if count >= cfg['bot'].get('daily_tweet_limit', 40):
        logger.info("ğŸš« Daily tweet limit reached.")
        return
    tweet = generate_trend_tweet()
    if not tweet:
        return
    try:
        x_client.create_tweet(text=tweet)
        record_history(tweet)
        update_meta(f"count_{today}", str(count + 1))
        logger.info(f"ğŸš€ Trend Tweet Dispatched: {tweet[:50]}...")
    except Exception as e:
        logger.error(f"âŒ Trend Dispatch Failed: {e}")

# -------------------------
# Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ©
# -------------------------
def smart_replies():
    account_id = os.getenv("X_ACCOUNT_ID")
    last_id = get_meta("last_mention_id", "1")
    try:
        mentions = x_client.get_users_mentions(id=account_id, since_id=last_id)
        if not mentions.data:
            return
        conn, cursor = get_db_conn()
        for mention in reversed(mentions.data):
            cursor.execute("SELECT 1 FROM replies WHERE tweet_id=?", (str(mention.id),))
            if cursor.fetchone(): continue
            reply_text = get_ai_response(f"Ø±Ø¯ Ø°ÙƒÙŠ ÙˆÙ…Ø®ØªØµØ± Ø¹Ù„Ù‰: {mention.text}")
            if not is_duplicate(reply_text):
                x_client.create_tweet(text=reply_text, in_reply_to_tweet_id=mention.id)
                cursor.execute("INSERT INTO replies (tweet_id, hash) VALUES (?,?)",
                               (str(mention.id), hashlib.md5(reply_text.encode()).hexdigest()))
                record_history(reply_text)
                logger.info(f"ğŸ’¬ Replied to: {mention.id}")
                time.sleep(random.uniform(5, 15))
        conn.commit()
        conn.close()
        if mentions.data:
            update_meta("last_mention_id", str(mentions.data[0].id))
    except Exception as e:
        logger.error(f"âš ï¸ Smart Replies Error: {e}")

# -------------------------
# Ø§Ù„ØªØºØ±ÙŠØ¯ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
# -------------------------
def dispatch_tweet():
    today = datetime.now().date().isoformat()
    count = int(get_meta(f"count_{today}", "0"))
    if count >= cfg['bot'].get('daily_tweet_limit', 40):
        logger.info("ğŸš« Daily limit reached.")
        return
    prompts = [
        "Ø­Ù„Ù„ ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØªØ¹Ø²ÙŠØ² Ø³ÙŠØ§Ø¯Ø© Ø§Ù„ÙØ±Ø¯ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„ÙŠÙˆÙ…ØŸ",
        "ØªØ­Ø¯Ø« Ø¹Ù† Ø£Ø¯Ø§Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ù† Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© ØªÙÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙ‚Ù„ÙŠÙ†.",
        "Ù…Ø§ Ù‡Ùˆ Ø£Ø«Ø± Ø§Ù„Ø¨Ù„ÙˆÙƒØ´ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø§Ù„Ø´Ø®ØµÙŠØ© ÙÙŠ 2026ØŸ",
        "Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙˆÙ…Ù‚Ø§Ø±Ù†Ø§ØªÙ‡Ø§ ÙˆØ£Ø³Ø±Ø§Ø±Ù‡Ø§ Ø§Ù„ØªÙ‚Ù†ÙŠØ©.",
        "Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© ÙˆØ£Ù‡Ù… Ø·Ø±Ù‚ Ø­Ù…Ø§ÙŠØ© Ø§Ù„ÙØ±Ø¯ ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡ Ø§Ù„Ø±Ù‚Ù…ÙŠ."
    ]
    content = get_ai_response(random.choice(prompts))
    if is_duplicate(content):
        logger.info("âš ï¸ Duplicate regular content skipped.")
        return
    try:
        x_client.create_tweet(text=content)
        record_history(content)
        update_meta(f"count_{today}", str(count + 1))
        logger.info(f"ğŸš€ Strategic Tweet Dispatched: {content[:50]}...")
    except Exception as e:
        logger.error(f"âŒ Dispatch Failed: {e}")

# -------------------------
# Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# -------------------------
def run_cycle():
    logger.info("âš™ï¸ Sovereign Cycle Initiated...")
    hour = datetime.now().hour
    if cfg['bot']['sleep_start'] <= hour < cfg['bot']['sleep_end']:
        logger.info("ğŸ’¤ Bot is in sleep mode.")
        return
    dispatch_trend_tweet()  # Ø§Ù„ØªØºØ±ÙŠØ¯ Ø­Ø³Ø¨ Ø§Ù„ØªØ±Ù†Ø¯
    dispatch_tweet()        # Ø§Ù„ØªØºØ±ÙŠØ¯ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
    smart_replies()         # Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ©
    update_meta("last_run", str(time.time()))
    logger.info("ğŸ Cycle Completed.")

if __name__ == "__main__":
    run_cycle()
