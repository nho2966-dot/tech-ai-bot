import os, sqlite3, logging, hashlib, random, re, time
from datetime import datetime
from urllib.parse import urlparse
import tweepy
from dotenv import load_dotenv
from openai import OpenAI

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„Ø­ÙˆÙƒÙ…Ø©
load_dotenv()
DB_FILE = "tech_om_sovereign_2026.db"
logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

EDITORIAL_POLICY = {
    "BREAKING": {"min_score": 4, "max_len": 500, "prefix": "ğŸš¨ Ø¹Ø§Ø¬Ù„ ØªÙ‚Ù†ÙŠ"},
    "ANALYSIS": {"min_score": 4, "max_len": 25000, "prefix": "ğŸ§  ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù…Ù‚"},
    "OPINION":  {"min_score": 5, "max_len": 25000, "prefix": "ğŸ—£ï¸ Ø±Ø£ÙŠ ØªÙ‚Ù†ÙŠ"},
    "CONTEST":  {"min_score": 5, "max_len": 280, "prefix": "ğŸ† Ù…Ø³Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"},
    "HARVEST":  {"min_score": 5, "max_len": 25000, "prefix": "ğŸ—ï¸ Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"}
}

TRUSTED_SOURCES = ["theverge.com", "techcrunch.com", "wired.com", "openai.com", "mit.edu", "reuters.com"]

class TechSovereignEngine:
    def __init__(self):
        self._init_db()
        self._init_clients()
        self.year = 2026

    def _init_db(self):
        with sqlite3.connect(DB_FILE) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS vault (h TEXT PRIMARY KEY, type TEXT, dt TEXT)")
            conn.execute("CREATE TABLE IF NOT EXISTS replies (rh TEXT PRIMARY KEY, tid TEXT, uid TEXT, dt TEXT)")
            conn.commit()

    def _init_clients(self):
        self.x = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"), consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"), access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=os.getenv("OPENROUTER_API_KEY"))

    # --- Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± ---
    def _is_duplicate(self, text):
        h = hashlib.sha256(text.strip().encode()).hexdigest()
        with sqlite3.connect(DB_FILE) as conn:
            return conn.execute("SELECT 1 FROM vault WHERE h=?", (h,)).fetchone() is not None, h

    def _is_trusted(self, url):
        parsed = urlparse("https://" + url if not url.startswith("http") else url)
        domain = parsed.netloc.lower()
        return any(domain == d or domain.endswith("." + d) for d in TRUSTED_SOURCES)

    # --- Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ø±ÙŠØ± Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠ ---
    def _generate_content(self, raw_input, mode):
        prompt = (f"Ø£Ù†Øª Ø±Ø¦ÙŠØ³ ØªØ­Ø±ÙŠØ± Ø®Ù„ÙŠØ¬ÙŠ ØªÙ‚Ù†ÙŠ ÙÙŠ 2026. Ø§Ù„Ù†Ù…Ø·: {mode}.\n"
                  "1. Ø§Ø³ØªØ®Ø¯Ù… Ù„Ù‡Ø¬Ø© Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ (Ø³Ù„Ø³Ø© ÙˆÙ‚ÙˆÙŠØ©).\n"
                  "2. Ø¶Ø¹ Ù…ØµØ·Ù„Ø­ÙŠÙ† Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ø¨ÙŠÙ† Ù‚ÙˆØ³ÙŠÙ†.\n"
                  "3. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„ØµÙ†Ø§Ø¹ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© ÙˆÙ…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£ÙØ±Ø§Ø¯.\n"
                  "Ø£Ù†Ù‡Ù Ø§Ù„Ù†Øµ Ø¨Ù€: [SCORE: X/5]")
        try:
            r = self.ai.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[{"role": "system", "content": prompt}, {"role": "user", "content": raw_input}],
                temperature=0.4
            )
            return r.choices[0].message.content.strip()
        except: return None

    # --- Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù„Ù†Ø´Ø± ---
    def publish(self, raw_data, source_url, mode="ANALYSIS"):
        if not self._is_trusted(source_url): return
        
        enhanced = self._generate_content(raw_data, mode)
        if not enhanced: return

        # ÙØ­Øµ Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª
        score_match = re.search(r"\[SCORE:\s*(\d)/5\]", enhanced)
        score = int(score_match.group(1)) if score_match else 0
        clean_text = re.sub(r"\[.*?\]", "", enhanced).strip()
        terms = re.findall(r"\([A-Za-z][A-Za-z0-9\- ]{2,}\)", clean_text)

        policy = EDITORIAL_POLICY.get(mode)
        if score < policy["min_score"] or len(terms) < 2:
            logging.info(f"ğŸ›‘ Ø±ÙØ¶ Ø¬ÙˆØ¯Ø©: {mode} | Score: {score}")
            return

        is_dup, h = self._is_duplicate(clean_text)
        if is_dup: return

        full_post = f"{policy['prefix']} {self.year}\n\n{clean_text[:policy['max_len']]}\n\nğŸ”— Ø§Ù„Ù…Ø±Ø¬Ø¹: {source_url}"
        
        try:
            self.x.create_tweet(text=full_post)
            with sqlite3.connect(DB_FILE) as conn:
                conn.execute("INSERT INTO vault VALUES (?, ?, ?)", (h, mode, datetime.now().isoformat()))
            logging.info(f"âœ… ØªÙ… Ù†Ø´Ø± {mode} Ø¨Ù†Ø¬Ø§Ø­!")
        except Exception as e: logging.error(f"âŒ Ø®Ø·Ø£: {e}")

    # --- Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ø°ÙƒÙŠ (Scheduler) ---
    def auto_run(self):
        day = datetime.now().strftime("%A") # Monday, Friday, etc.
        logging.info(f"ğŸ“… ÙØ­Øµ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„ÙŠÙˆÙ…: {day}")

        if day == "Monday":
            self.publish("ØµÙ…Ù… Ù…Ø³Ø§Ø¨Ù‚Ø© ØªÙ‚Ù†ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ© Ø¹Ù† Ø£Ù…Ø§Ù† Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠÙŠÙ†.", "mit.edu", "CONTEST")
        elif day == "Wednesday":
            self.publish("Ø§Ø·Ø±Ø­ Ø§Ø³ØªØ·Ù„Ø§Ø¹ Ø±Ø£ÙŠ (Poll) Ø­ÙˆÙ„ ØªÙ‚Ø¨Ù‘Ù„ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø±ÙˆØªÙŠÙ†ÙŠØ© Ø¨Ù€ AI Agents.", "wired.com", "OPINION")
        elif day == "Friday":
            self.publish("Ø§ÙƒØªØ¨ Ø­ØµØ§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ù„Ø£Ù‡Ù… 3 Ø§Ø¨ØªÙƒØ§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ø­ÙˆØ³Ø¨Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©.", "techcrunch.com", "HARVEST")
        else:
            self.publish("Ù‚Ø¯Ù… Ù†ØµÙŠØ­Ø© ÙŠÙˆÙ…ÙŠØ© Ø³Ø±ÙŠØ¹Ø© Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©.", "openai.com", "BREAKING")

if __name__ == "__main__":
    engine = TechSovereignEngine()
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ø±Ùƒ (ÙŠÙ…ÙƒÙ† ÙˆØ¶Ø¹Ù‡ ÙÙŠ Cron Job Ù„ÙŠØ¹Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
    engine.auto_run()
