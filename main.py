import os
import time
import json
import hashlib
import logging
import requests
import random
from typing import Optional
from urllib.parse import urlparse

import tweepy
import feedparser
from google import genai
from openai import OpenAI

SOURCES = [
    "https://ai.googleblog.com/atom.xml",
    "https://www.microsoft.com/en-us/research/feed/",
    "https://engineering.fb.com/feed/",
    "https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml",
    "https://arstechnica.com/feed/",
    "https://www.wired.com/feed/rss"
]

STATE_FILE = "state.json"
MAX_POSTS = 2 

class TechEliteHybridBot:
    def __init__(self):
        self._init_logging()
        self._load_env()
        self._init_clients()
        self.state = self._load_state()

    def _init_logging(self):
        logging.basicConfig(level=logging.INFO, format="ðŸ›¡ï¸ %(asctime)s | %(message)s")

    def _load_env(self):
        self.GEMINI_KEY = os.getenv("GEMINI_KEY")
        self.QWEN_KEY = os.getenv("QWEN_API_KEY")
        self.X_API_KEY = os.getenv("X_API_KEY")
        self.X_API_SECRET = os.getenv("X_API_SECRET")
        self.X_ACCESS_TOKEN = os.getenv("X_ACCESS_TOKEN")
        self.X_ACCESS_SECRET = os.getenv("X_ACCESS_SECRET")
        self.X_BEARER = os.getenv("X_BEARER_TOKEN")

    def _init_clients(self):
        self.ai_gemini = genai.Client(api_key=self.GEMINI_KEY)
        self.ai_qwen = OpenAI(
            api_key=self.QWEN_KEY,
            base_url="https://openrouter.ai/api/v1"
        )
        auth = tweepy.OAuth1UserHandler(self.X_API_KEY, self.X_API_SECRET, self.X_ACCESS_TOKEN, self.X_ACCESS_SECRET)
        self.x_api_v1 = tweepy.API(auth)
        self.x_client_v2 = tweepy.Client(
            bearer_token=self.X_BEARER,
            consumer_key=self.X_API_KEY,
            consumer_secret=self.X_API_SECRET,
            access_token=self.X_ACCESS_TOKEN,
            access_token_secret=self.X_ACCESS_SECRET
        )

    def _load_state(self):
        if not os.path.exists(STATE_FILE): return {"hashes": []}
        try:
            with open(STATE_FILE, "r") as f: return json.load(f)
        except: return {"hashes": []}

    def _save_state(self):
        with open(STATE_FILE, "w") as f: json.dump(self.state, f)

    def safe_ai_request(self, title: str, summary: str, source: str) -> Optional[str]:
        # ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù…Ù†Ø¹ Ø§Ù„Ù‡Ù„ÙˆØ³Ø© ÙˆØ§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ©
        instruction = (
            "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠ. ØµØº ØªØºØ±ÙŠØ¯Ø© Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø±ÙÙ‚Ø© ÙÙ‚Ø·.\n"
            "âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:\n"
            "1. Ù…Ù…Ù†ÙˆØ¹ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù…ØµØ·Ù„Ø­Ø§Øª Ø£Ùˆ Ø±Ù…ÙˆØ² ØµÙŠÙ†ÙŠØ©.\n"
            "2. Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙÙ‚Ø·.\n"
            "3. Ù…Ù…Ù†ÙˆØ¹ Ø§Ø®ØªØ±Ø§Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© (Ù„Ø§ Ù„Ù„Ù‡Ù„ÙˆØ³Ø©).\n"
            "4. Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: Hook Ø¬Ø°Ø§Ø¨ + Ù…Ø¹Ù„ÙˆÙ…Ø© ØªÙ‚Ù†ÙŠØ© + Ù†ØµÙŠØ­Ø© (Pro Tip)."
        )
        user_content = f"Ø§Ù„Ø®Ø¨Ø±: {title}\nØ§Ù„ØªÙØ§ØµÙŠÙ„: {summary}\nØ§Ù„Ù…ØµØ¯Ø±: {source}"

        # 1. Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„: Ø¬Ù…Ù†Ø§ÙŠ
        try:
            logging.info("ðŸš€ Gemini Primary Attempt...")
            time.sleep(10)
            res = self.ai_gemini.models.generate_content(
                model="gemini-2.0-flash", 
                contents=f"{instruction}\n\n{user_content}"
            )
            if res.text: return res.text.strip()
        except Exception as e:
            logging.warning(f"âš ï¸ Gemini Busy. Switching to Qwen...")

        # 2. Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø«Ø§Ù†ÙŠ: ÙƒÙˆÙŠÙ† (Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù‚ØµÙˆÙ‰)
        try:
            if not self.QWEN_KEY: return None
            logging.info("ðŸ”„ Qwen Fallback (Strict No-Chinese Mode)...")
            completion = self.ai_qwen.chat.completions.create(
                model="qwen/qwen-2.5-72b-instruct",
                messages=[
                    {"role": "system", "content": instruction},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.1, # Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ© ÙˆØ¹Ø¯Ù… Ø§Ù„ØªØ®Ø±ÙŠÙ
                max_tokens=300
            )
            return completion.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"âŒ All Models Failed: {e}")
            return None

    def run(self):
        logging.info("Cycle Started - Secure Hybrid Mode")
        posted = 0
        for src in random.sample(SOURCES, len(SOURCES)):
            if posted >= MAX_POSTS: break
            feed = feedparser.parse(src)
            for entry in feed.entries[:5]:
                h = hashlib.md5(entry.title.encode()).hexdigest()
                if h in self.state["hashes"] or posted >= MAX_POSTS: continue

                tweet = self.safe_ai_request(entry.title, getattr(entry, "summary", ""), urlparse(entry.link).netloc)
                if tweet:
                    try:
                        self.x_client_v2.create_tweet(text=tweet[:280])
                        self.state["hashes"].append(h)
                        self._save_state()
                        posted += 1
                        logging.info(f"âœ… Success: {entry.title[:30]}")
                        time.sleep(60)
                    except Exception as e: logging.error(f"X Error: {e}")

if __name__ == "__main__":
    TechEliteHybridBot().run()
