import os
import sqlite3
import logging
import time
import hashlib
import requests
import tweepy
import feedparser
from bs4 import BeautifulSoup
from io import BytesIO
from datetime import datetime, timedelta, timezone
from google import genai

logging.basicConfig(level=logging.INFO, format="ğŸ›¡ï¸ %(asctime)s - %(message)s")

class SovereignBot:
    def __init__(self):
        self.keys = {
            "gemini": os.getenv("GEMINI_KEY"),
            "x_api": os.getenv("X_API_KEY"),
            "x_secret": os.getenv("X_API_SECRET"),
            "x_token": os.getenv("X_ACCESS_TOKEN"),
            "x_token_secret": os.getenv("X_ACCESS_SECRET")
        }
        self.db_path = "data/sovereign_v23.db"
        self._setup_brains()
        self._setup_x()
        self._init_db()

    def _setup_brains(self):
        self.brain = genai.Client(api_key=self.keys["gemini"]) if self.keys["gemini"] else None

    def _setup_x(self):
        try:
            self.x_client = tweepy.Client(
                bearer_token=os.getenv("X_BEARER_TOKEN"),
                consumer_key=self.keys["x_api"], consumer_secret=self.keys["x_secret"],
                access_token=self.keys["x_token"], access_token_secret=self.keys["x_token_secret"]
            )
            auth = tweepy.OAuth1UserHandler(self.keys["x_api"], self.keys["x_secret"], self.keys["x_token"], self.keys["x_token_secret"])
            self.api_v1 = tweepy.API(auth)
            logging.info("âœ… Ø£Ù†Ø¸Ù…Ø© X Ø¬Ø§Ù‡Ø²Ø© (Ù†Ø´Ø± + ÙˆØ³Ø§Ø¦Ø·)")
        except Exception as e: logging.error(f"âŒ ÙØ´Ù„ Ø±Ø¨Ø· X: {e}")

    def _init_db(self):
        os.makedirs("data", exist_ok=True)
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS history (hash TEXT PRIMARY KEY, ts DATETIME)")
            conn.execute("CREATE TABLE IF NOT EXISTS waiting_room (hash TEXT PRIMARY KEY, content TEXT, url TEXT, ts DATETIME)")

    def _get_image(self, url):
        try:
            res = requests.get(url, timeout=0)
            soup = BeautifulSoup(res.text, 'html.parser')
            img = soup.find("meta", property="og:image")
            return img["content"] if img else None
        except: return None

    def fetch_news(self):
        logging.info("ğŸŒ Ø¬Ø§Ø±ÙŠ Ø³Ø­Ø¨ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...")
        feed = feedparser.parse("https://techcrunch.com/category/artificial-intelligence/feed/")
        for entry in feed.entries[:3]:
            h = hashlib.md5(entry.link.encode()).hexdigest()
            with sqlite3.connect(self.db_path) as conn:
                if not conn.execute("SELECT 1 FROM history WHERE hash=?", (h,)).fetchone():
                    conn.execute("INSERT OR REPLACE INTO waiting_room VALUES (?, ?, ?, ?)",
                                (h, entry.title, entry.link, datetime.now(timezone.utc)))

    def handle_posting(self):
        """Ù†Ø´Ø± Ø®Ø¨Ø± ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ÙØ§ØµÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ"""
        now = datetime.now(timezone.utc)
        with sqlite3.connect(self.db_path) as conn:
            # Ø´Ø±Ø·: Ù†Ø´Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ØªÙŠ Ù…Ø¶Ù‰ Ø¹Ù„ÙŠÙ‡Ø§ 10 Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
            target = conn.execute("SELECT hash, content, url FROM waiting_room WHERE ts <= ? LIMIT 1", 
                                 (now - timedelta(minutes=10),)).fetchone()
            if target:
                h, content, url = target
                self._publish(h, content, url)
            else:
                logging.info("â³ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ø¬Ø§Ù‡Ø² Ù„Ù„Ù†Ø´Ø± (ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø±ÙˆØ± Ø§Ù„ÙØ§ØµÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ).")

    def _publish(self, h, content, url):
        try:
            # ØµÙŠØ§ØºØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø®Ù„ÙŠØ¬ÙŠØ©
            p = f"ØµØº Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ø¨Ù„Ù‡Ø¬Ø© Ø®Ù„ÙŠØ¬ÙŠØ© Ù…Ù‡Ù†ÙŠØ© Ù„Ù„Ø£ÙØ±Ø§Ø¯ØŒ Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙØ§Ø¦Ø¯Ø©ØŒ ÙˆØ§Ø®ØªÙ… Ø¨Ø§Ù„Ù…ØµØ¯Ø±: {content} - {url}"
            txt = self.brain.models.generate_content(model="gemini-2.0-flash", contents=p).text
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
            m_ids = None
            img_url = self._get_image(url)
            if img_url:
                img_data = requests.get(img_url).content
                with BytesIO(img_data) as f:
                    m = self.api_v1.media_upload(filename="ai.jpg", file=f)
                    m_ids = [m.media_id]

            self.x_client.create_tweet(text=txt[:275], media_ids=m_ids)
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("INSERT INTO history VALUES (?, ?)", (h, datetime.now(timezone.utc)))
                conn.execute("DELETE FROM waiting_room WHERE hash=?", (h,))
                conn.commit()
            logging.info("ğŸ¯ ØªÙ… Ù†Ø´Ø± Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        except Exception as e: logging.error(f"âŒ Ø®Ø·Ø£ Ù†Ø´Ø±: {e}")

    def handle_replies(self):
        """Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ© Ø¨ÙØ§ØµÙ„ Ø²Ù…Ù†ÙŠ Ø¹Ù† Ø§Ù„Ù†Ø´Ø±"""
        time.sleep(30) # ÙØ§ØµÙ„ Ø¨Ø³ÙŠØ· Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„ØªØ¯Ø§Ø®Ù„ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù„Ø­Ø¸Ø©
        logging.info("ğŸ’¬ Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù†Ø´Ù†Ø§Øª Ù„Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ...")
        # Ø³ÙŠØªÙ… ØªÙØ¹ÙŠÙ„ Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¯ Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§ÙÙŠ Ù‡Ù†Ø§ ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©

if __name__ == "__main__":
    bot = SovereignBot()
    bot.fetch_news()      # 1. Ø³Ø­Ø¨
    bot.handle_posting()  # 2. Ù†Ø´Ø± (Ø¨Ø´Ø±Ø· Ø§Ù„ÙØ§ØµÙ„)
    bot.handle_replies()  # 3. Ø±Ø¯ (Ø¨Ø¹Ø¯ ÙØ§ØµÙ„)
