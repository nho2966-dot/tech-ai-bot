import os, sqlite3, logging, hashlib, re, time
from datetime import datetime
import tweepy
from openai import OpenAI

class TechThreadUltimate:
    def __init__(self, client_x, ai_client):
        self.x = client_x
        self.ai = ai_client
        self.max_len = 250

    def _dedupe_terms(self, text):
        """Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø±ØµØ§Ù†Ø© Ø§Ù„Ù†Øµ"""
        seen = set()
        words = text.split()
        out = []
        for w in words:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ³ÙŠÙ† Ù„Ù„ÙØ­Øµ
            clean_w = re.sub(r"[()]", "", w).lower()
            if clean_w.isascii() and len(clean_w) > 2:
                if clean_w in seen: continue
                seen.add(clean_w)
            out.append(w)
        return " ".join(out)

    def _sanitize_tweets(self, tweets):
        clean = []
        for t in tweets:
            t = self._dedupe_terms(t.strip())
            if len(t) < 45: continue
            if len(t) > self.max_len:
                t = t[:self.max_len - 3] + "..."
            clean.append(t)
        return clean

    def post_thread(self, raw_content, source_url):
        # 1. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø«Ø±ÙŠØ¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¹Ø¨Ø± AI
        prompt = "Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø«Ø±ÙŠØ¯ Ø®Ù„ÙŠØ¬ÙŠ Ù†Ø®Ø¨ÙˆÙŠ (Hook -> Analysis -> Takeaway) Ù…Ø¹ ÙÙˆØ§ØµÙ„ '---'."
        raw_res = self.ai.chat.completions.create(
            model="qwen/qwen-2.5-72b-instruct",
            messages=[{"role": "user", "content": raw_content}], temperature=0.5
        ).choices[0].message.content.strip().split("---")

        tweets = self._sanitize_tweets(raw_res)
        if len(tweets) < 3: return

        # 2. Semantic Hook Guard (Ø±ÙØ¹ Ø§Ù„Ù€ Average Read Time)
        if not re.search(r"(Ù„ÙŠØ´|ÙƒÙŠÙ|ÙˆØ´|Ù‡Ù„|Ø§Ù„Ø³Ø¨Ø¨|Ø§Ù„ÙØ±Ù‚)", tweets[0]):
            tweets[0] = "Ù„ÙŠØ´ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù‡Ù… Ø§Ù„Ø­ÙŠÙ†ØŸ Ø®Ù„Ù‘Ùƒ Ù…Ø¹ÙŠ ÙÙŠ Ù‡Ø§Ù„ØªØ­Ù„ÙŠÙ„.. ğŸ‘‡\n\n" + tweets[0]
        
        # 3. Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¬Ø§Ø°Ø¨ ÙÙŠ Ø§Ù„Ù€ Hook
        if not re.search(r"[!?ğŸ”¥ğŸš¨ğŸ§ ]", tweets[0]):
            tweets[0] = "ğŸ§  " + tweets[0]

        previous_tweet_id = None
        for i, tweet_text in enumerate(tweets):
            # 4. Takeaway Guard (Ù…Ø¶Ø§Ø¹ÙØ© Ø§Ù„ØªÙØ§Ø¹Ù„ ÙÙŠ Ø¢Ø®Ø± ØªØºØ±ÙŠØ¯Ø©)
            if i == len(tweets)-1:
                if "ØŸ" not in tweet_text:
                    tweet_text += "\n\nÙˆØ´ Ø±Ø£ÙŠÙƒ ÙÙŠ Ù‡Ø§Ù„Ù†Ù‚Ø·Ø©ØŸ ØªØªÙÙ‚ Ù…Ø¹ÙŠ Ø£Ùˆ Ø¹Ù†Ø¯Ùƒ ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø«Ø§Ù†ÙŠØ©ØŸ ğŸ‘‡"
                footer = f"\n\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: {source_url}"
            else:
                footer = ""

            header = "ğŸ§µ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„\n" if i == 0 else f"â†³ {i+1}/{len(tweets)}\n"
            final_text = f"{header}{tweet_text}{footer}"

            try:
                # 5. Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø°ÙƒÙŠ (Smart Indexing Timing)
                time.sleep(1.2 if i == 0 else 0.7)
                
                response = self.x.create_tweet(
                    text=final_text,
                    in_reply_to_tweet_id=previous_tweet_id if i > 0 else None
                )
                previous_tweet_id = response.data["id"]
                logging.info(f"âœ… ØªÙ… Ù†Ø´Ø± Ø§Ù„Ø¬Ø²Ø¡ {i+1}")
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø£: {e}")
                break

        return previous_tweet_id
