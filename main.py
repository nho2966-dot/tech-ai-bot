import os
import asyncio
import random
import httpx
import tweepy
from google import genai
from openai import OpenAI
from loguru import logger

# ==========================================
# ğŸ” Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„ÙˆØµÙˆÙ„ (Ù…Ù† Secrets)
# ==========================================
KEYS = {
    "GEMINI": os.getenv("GEMINI_KEY"),
    "OPENAI": os.getenv("OPENAI_API_KEY"),
    "GROQ": os.getenv("GROQ_API_KEY"),
    "XAI": os.getenv("XAI_API_KEY"),
    "OPENROUTER": os.getenv("OPENROUTER_API_KEY"),
    "QWEN": os.getenv("QWEN_API_KEY"),
}

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø´Ø±
X_CRED = {
    "ck": os.getenv("X_API_KEY"), "cs": os.getenv("X_API_SECRET"),
    "at": os.getenv("X_ACCESS_TOKEN"), "ts": os.getenv("X_ACCESS_SECRET")
}
TG_TOKEN = os.getenv("TG_TOKEN")
TG_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# --- Ù†Øµ Ø§Ù„Ø§Ø³ØªÙ‡Ø¯Ø§Ù (Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡) ---
SYSTEM_PROMPT = """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø®Ù„ÙŠØ¬ÙŠ Ù…ØªÙ…ÙƒÙ†. Ø§ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ 'Ø¨Ø±ÙŠÙ…ÙŠÙˆÙ…' ÙˆÙ…Ø·ÙˆÙ„Ø§Ù‹ Ù„Ù„Ø£ÙØ±Ø§Ø¯.
Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ£Ø­Ø¯Ø« Ø£Ø¯ÙˆØ§ØªÙ‡ Ù„Ø¹Ø§Ù… 2026'.
Ø§Ù„Ø´Ø±ÙˆØ·: 
1. Ø§Ù„Ù„Ù‡Ø¬Ø©: Ø®Ù„ÙŠØ¬ÙŠØ© Ø¨ÙŠØ¶Ø§Ø¡ ÙØ®Ù…Ø© (Ù…ÙˆØ¬Ù‡Ø© Ù„Ù„Ø£ÙØ±Ø§Ø¯).
2. Ø§Ù„Ù…Ø­ØªÙˆÙ‰: Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø£Ø¯ÙˆØ§Øª ØªØ²ÙŠØ¯ Ø§Ù„Ø¯Ø®Ù„ ÙˆØ§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©.
3. Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨ØŒ Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­Ø©ØŒ ÙˆØ®Ø§ØªÙ…Ø© Ù…Ø­ÙØ²Ø©.
4. ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆÙ‡Ù„ÙˆØ³Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.
"""

# ==========================================
# ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø³ØªØ© Ø§Ù„Ù…ØªØªØ§Ø¨Ø¹Ø© (The 6-Brain Failover)
# ==========================================

async def brain_gemini():
    client = genai.Client(api_key=KEYS["GEMINI"])
    res = client.models.generate_content(model="gemini-2.0-flash", contents=SYSTEM_PROMPT)
    return res.text

async def brain_openai():
    client = OpenAI(api_key=KEYS["OPENAI"])
    res = client.chat.completions.create(model="gpt-4o", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_groq():
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=KEYS["GROQ"])
    res = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_xai():
    client = OpenAI(base_url="https://api.x.ai/v1", api_key=KEYS["XAI"])
    res = client.chat.completions.create(model="grok-2-latest", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_openrouter():
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=KEYS["OPENROUTER"])
    res = client.chat.completions.create(model="anthropic/claude-3.5-sonnet", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def brain_qwen():
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=KEYS["QWEN"])
    res = client.chat.completions.create(model="qwen/qwen-2.5-72b-instruct", messages=[{"role": "user", "content": SYSTEM_PROMPT}])
    return res.choices[0].message.content

async def get_premium_content():
    brains = [
        ("Gemini", brain_gemini), ("OpenAI", brain_openai), ("Groq", brain_groq),
        ("xAI Grok", brain_xai), ("OpenRouter", brain_openrouter), ("Qwen", brain_qwen)
    ]
    for name, func in brains:
        try:
            logger.info(f"ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ø¨Ø±: {name}")
            content = await func()
            if content: 
                logger.success(f"â­ ØªÙ… Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ù…Ù† Ø¹Ù‚Ù„: {name}")
                return content
        except Exception as e:
            logger.warning(f"âš ï¸ {name} Ø§Ø¹ØªØ°Ø±: {e}")
    return None

# ==========================================
# ğŸ“¤ Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©
# ==========================================

def post_to_x(content):
    try:
        client = tweepy.Client(
            consumer_key=X_CRED["ck"], consumer_secret=X_CRED["cs"],
            access_token=X_CRED["at"], access_token_secret=X_CRED["ts"]
        )
        # Ø¨Ù…Ø§ Ø£Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¯ÙÙˆØ¹ØŒ Ù†Ù†Ø´Ø± Ø­ØªÙ‰ 25,000 Ø­Ø±Ù
        client.create_tweet(text=content[:24500])
        logger.success("âœ… ØªÙ… Ø§Ø¬ØªÙŠØ§Ø­ Ù…Ù†ØµØ© X Ø¨Ù†Ø¬Ø§Ø­")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ X: {e}")

async def post_to_telegram(content):
    if not TG_TOKEN: return
    try:
        async with httpx.AsyncClient() as client:
            await client.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage", json={
                "chat_id": TG_CHAT_ID, "text": content[:4000], "parse_mode": "Markdown"
            })
        logger.success("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± ÙÙŠ ØªÙ„ÙŠØ¬Ø±Ø§Ù…")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {e}")

# ==========================================
# ğŸ Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================

async def run_apex_system():
    logger.info("ğŸš€ Ø§Ù†Ø·Ù„Ø§Ù‚ Ø¬ÙˆÙ„Ø© Ù†Ø§ØµØ± Ù„Ø¹Ø§Ù… 2026 - Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø³ØªØ©")
    content = await get_premium_content()
    if content:
        post_to_x(content)
        await post_to_telegram(content)
    else:
        logger.critical("ğŸš¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø³ØªØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø¯Ù…Ø©!")

if __name__ == "__main__":
    asyncio.run(run_apex_system())
