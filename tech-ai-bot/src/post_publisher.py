import os
import tweepy
import logging
import re
import random
from google import genai
from google.genai import types
from openai import OpenAI

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
logging.basicConfig(level=logging.INFO)

def clean_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù„Ø¶Ù…Ø§Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ø´Ø± ÙˆØªÙˆØ§ÙÙ‚ Ø§Ù„Ø±Ù…ÙˆØ²."""
    if not text: return ""
    cleaned = re.sub(r'[^\u0600-\u06FF\s0-9\.\?\!\,\:\-\#\(\)a-zA-ZğŸ¦ğŸ¤–ğŸš€ğŸ’¡âœ¨ğŸ§ ğŸŒğŸ“±ğŸ’»âŒšğŸ“ŠğŸ“ˆğŸ”‹ğŸš¨]', '', text)
    return " ".join(cleaned.split())

def get_pro_tips():
    """Ù…Ø®Ø²Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ: ÙŠØ´Ø±Ø­ Ø§Ù„Ù…ÙŠØ²Ø©ØŒ Ø£Ù‡Ù…ÙŠØªÙ‡Ø§ØŒ ÙˆÙƒÙŠÙÙŠØ© ØªÙˆØ¸ÙŠÙÙ‡Ø§ Ø¹Ù…Ù„ÙŠØ§Ù‹."""
    tips = [
        {
            "ar": "ğŸ¯ ØªÙ‚Ù†ÙŠØ© RAG ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\nğŸ’¡ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: ØªÙ…Ù†Ø¹ 'Ù‡Ù„ÙˆØ³Ø©' Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ø¨Ø± Ø±Ø¨Ø·Ù‡Ø§ Ø¨Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©.\nğŸ› ï¸ ØªÙˆØ¸ÙŠÙÙ‡Ø§: Ø§Ø±Ø¨Ø· Ù…Ù„ÙØ§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ LLM Ø¹Ø¨Ø± Ø£Ø¯ÙˆØ§Øª RAG Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† Ø¯Ø§Ø®Ù„ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙÙ‚Ø·.\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: IBM Research",
            "en": "ğŸ¯ RAG in AI\nğŸ’¡ Importance: Prevents AI hallucinations by grounding it in trusted data.\nğŸ› ï¸ Practice: Connect your private docs to LLMs using RAG tools for source-based accurate answers.\nğŸ”— Source: IBM Research"
        },
        {
            "ar": "ğŸ”‹ Ù…ÙŠØ²Ø© LTPO ÙÙŠ Ø§Ù„Ø´Ø§Ø´Ø§Øª\nğŸ’¡ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: Ø§Ù„Ø³Ø± Ø®Ù„Ù ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø¨Ø·Ø§Ø±ÙŠØ© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ø±Ø§Ø¦Ø¯Ø©.\nğŸ› ï¸ ØªÙˆØ¸ÙŠÙÙ‡Ø§: ÙØ¹Ù„ ÙˆØ¶Ø¹ 'Adaptive'Ø› Ø§Ù„Ø´Ø§Ø´Ø© Ø³ØªØ®ÙØ¶ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù€ 1Hz ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø§Ù„Ø³ÙƒÙˆÙ† Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø·Ø§Ù‚Ø©.\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: Samsung Display",
            "en": "ğŸ”‹ LTPO Display Tech\nğŸ’¡ Importance: The key to battery efficiency in flagship phones.\nğŸ› ï¸ Practice: Enable 'Adaptive' mode; the screen will auto-drop to 1Hz when idle to save power.\nğŸ”— Source: Samsung Display"
        },
        {
            "ar": "ğŸ“· Ø§Ù„ØªØµÙˆÙŠØ± Ø¨ØµÙŠØºØ© RAW/ProRAW\nğŸ’¡ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨ÙƒØ§Ù…Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù† Ø¯ÙˆÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¶Ø§Ø±Ø©.\nğŸ› ï¸ ØªÙˆØ¸ÙŠÙÙ‡Ø§: Ø§Ø³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø§Ù„ØµØ¹Ø¨Ø©ØŒ Ø«Ù… Ø¹Ø¯Ù„ 'Shadows' ÙÙŠ Lightroom Ù„Ù†ØªØ§Ø¦Ø¬ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©.\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: Adobe Professional",
            "en": "ğŸ“· RAW/ProRAW Photography\nğŸ’¡ Importance: Preserves all light and color data without destructive processing.\nğŸ› ï¸ Practice: Use it for tricky lighting, then edit Shadows in Lightroom for cinematic results.\nğŸ”— Source: Adobe Professional"
        }
    ]
    selected = random.choice(tips)
    return f"{selected['ar']}\n\n{selected['en']}\n\n#AI #TechTips #Innovation #Ø®ÙØ§ÙŠØ§_Ø§Ù„ØªÙ‚Ù†ÙŠØ©"

def generate_with_gemini():
    """Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø¹Ø¨Ø± Gemini 2.0."""
    try:
        api_key = os.getenv("GEMINI_KEY")
        if not api_key: return None
        client = genai.Client(api_key=api_key)
        google_search_tool = types.Tool(google_search=types.GoogleSearch())
        
        prompt = "Ø§Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠ Ø¬Ø¯ÙŠØ¯ (Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…). Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© Ø¯Ø³Ù…Ø©: Ø§Ù„Ù…ÙŠØ²Ø©ØŒ Ø£Ù‡Ù…ÙŠØªÙ‡Ø§ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙƒÙŠÙÙŠØ© ØªÙˆØ¸ÙŠÙÙ‡Ø§ØŒ ÙˆØ§Ù„Ù…ØµØ¯Ø±. Ø¨Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ø§Ù„Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª."
        
        response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config=types.GenerateContentConfig(tools=[google_search_tool])
        )
        return clean_text(response.text.strip()) if response.text else None
    except Exception as e:
        logging.error(f"âš ï¸ Gemini Error: {e}")
        return None

def generate_with_qwen_groq():
    """Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¹Ø¨Ø± Qwen/Groq."""
    try:
        api_key = os.getenv("QWEN_API_KEY")
        if not api_key: return None
        client = OpenAI(api_key=api_key, base_url="https://api.groq.com/openai/v1")
        
        completion = client.chat.completions.create(
            model="qwen-2.5-32b",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ ØªØ´Ø±Ø­ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ£Ù‡Ù…ÙŠØªÙ‡Ø§ ÙˆØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù…Ø¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±."},
                {"role": "user", "content": "Ù‡Ø§Øª Ø®Ø¨Ø± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠ Ø¬Ø¯ÙŠØ¯ (Ø¢Ø®Ø± 7 Ø£ÙŠØ§Ù…) Ø¨ØµÙŠØºØ© Ø¯Ø³Ù…Ø© ÙˆÙ…ÙÙŠØ¯Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…."}
            ]
        )
        return clean_text(completion.choices[0].message.content)
    except Exception as e:
        logging.error(f"âš ï¸ Groq/Qwen Error: {e}")
        return None

def publish_tech_tweet():
    """Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ø°ÙƒÙŠ."""
    try:
        logging.info("ğŸš€ Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙØ¶Ù„ Ù…Ø­ØªÙˆÙ‰ ØªÙ‚Ù†ÙŠ...")
        
        content = generate_with_gemini()
        if not content:
            logging.info("ğŸ”„ Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø©: Qwen/Groq...")
            content = generate_with_qwen_groq()
        if not content:
            logging.info("ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙƒÙŠ...")
            content = get_pro_tips()

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª X (Twitter)
        client = tweepy.Client(
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        
        if content:
            client.create_tweet(text=content[:280]) # Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ
            logging.info("âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­!")
            
    except Exception as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {e}")

if __name__ == "__main__":
    publish_tech_tweet()
