import os
import tweepy
import logging
import re
import random
from google import genai
from google.genai import types
from openai import OpenAI

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(level=logging.INFO)

def clean_text(text):
    if not text: return ""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØºØ±ÙŠØ¨Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ù„Ù„ØºØªÙŠÙ†
    cleaned = re.sub(r'[^\u0600-\u06FF\s0-9\.\?\!\,\:\-\#\(\)a-zA-ZğŸ¦ğŸ¤–ğŸš€ğŸ’¡âœ¨ğŸ§ ğŸŒğŸ“±ğŸ’»âŒšğŸ“ŠğŸ“ˆğŸ”‹ğŸš¨ğŸ”—ğŸ¯ğŸ› ï¸ğŸ”‹ğŸ“·]', '', text)
    return " ".join(cleaned.split())

def smart_truncate(content, length=280):
    """ÙŠÙ‚Øµ Ø§Ù„Ù†Øµ Ø¨Ø°ÙƒØ§Ø¡ Ø¹Ù†Ø¯ Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…Ù„Ø© Ø£Ùˆ Ù…Ø³Ø§ÙØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø±ÙÙŠØ©."""
    if len(content) <= length:
        return content
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚Øµ Ø¹Ù†Ø¯ Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© Ø£Ùˆ ÙØ§ØµÙ„Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
    truncated = content[:length-3]
    last_punctuation = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('ØŸ'))
    
    if last_punctuation > length * 0.7: # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ù‚Ø·Ø© Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        return content[:last_punctuation + 1]
    
    # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù†Ù‚Ø·Ø©ØŒ Ù‚Øµ Ø¹Ù†Ø¯ Ø¢Ø®Ø± Ù…Ø³Ø§ÙØ©
    last_space = truncated.rfind(' ')
    return content[:last_space] + "..."

def get_pro_tips():
    """Ù…Ø­ØªÙˆÙ‰ Ø¨Ø¯ÙŠÙ„ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø© ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ ÙˆØ§Ù„Ù…ØµØ¯Ø±."""
    tips = [
        {
            "ar": "ğŸ¯ ØªÙ‚Ù†ÙŠØ© RAG ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ\nğŸ’¡ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: ØªÙ…Ù†Ø¹ 'Ø§Ù„ØªØ£Ù„ÙŠÙ' Ø¨Ø±Ø¨Ø· AI Ø¨Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø©.\nğŸ› ï¸ ØªÙˆØ¸ÙŠÙÙ‡Ø§: Ø§Ø±Ø¨Ø· Ù…Ù„ÙØ§ØªÙƒ Ø¨Ù€ LLM Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø¯Ù‚ÙŠÙ‚Ø© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙÙ‚Ø·.\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: IBM",
            "en": "ğŸ¯ RAG in AI\nğŸ’¡ Importance: Prevents AI hallucinations by grounding it in data.\nğŸ› ï¸ Practice: Connect your docs to LLMs for accurate, source-based results.\nğŸ”— Source: IBM"
        },
        {
            "ar": "ğŸ”‹ Ù…ÙŠØ²Ø© LTPO ÙÙŠ Ø§Ù„Ø´Ø§Ø´Ø§Øª\nğŸ’¡ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: Ø³Ø± ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø¨Ø·Ø§Ø±ÙŠØ© ÙÙŠ Ø§Ù„Ù‡ÙˆØ§ØªÙ Ø§Ù„Ø±Ø§Ø¦Ø¯Ø©.\nğŸ› ï¸ ØªÙˆØ¸ÙŠÙÙ‡Ø§: ÙØ¹Ù„ ÙˆØ¶Ø¹ 'Adaptive'Ø› Ø³ØªØ®ÙØ¶ Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù€ 1Hz ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø·Ø§Ù‚Ø©.\nğŸ”— Ø§Ù„Ù…ØµØ¯Ø±: Samsung",
            "en": "ğŸ”‹ LTPO Tech\nğŸ’¡ Importance: Key to battery life in flagships.\nğŸ› ï¸ Practice: Enable 'Adaptive' mode; screen auto-drops to 1Hz to save power.\nğŸ”— Source: Samsung"
        }
    ]
    selected = random.choice(tips)
    return f"{selected['ar']}\n\n{selected['en']}\n\n#TechTips #Innovation"

def generate_with_gemini():
    try:
        api_key = os.getenv("GEMINI_KEY")
        if not api_key: return None
        client = genai.Client(api_key=api_key)
        google_search_tool = types.Tool(google_search=types.GoogleSearch())
        
        prompt = ("Ø§Ø¨Ø­Ø« Ø¹Ù† Ø®Ø¨Ø± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠ Ø¬Ø¯ÙŠØ¯. Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© Ø¯Ø³Ù…Ø© ØªØ´Ù…Ù„: Ø§Ù„Ù…ÙŠØ²Ø©ØŒ Ø£Ù‡Ù…ÙŠØªÙ‡Ø§ØŒ ÙƒÙŠÙÙŠØ© ØªÙˆØ¸ÙŠÙÙ‡Ø§ØŒ ÙˆØ§Ù„Ù…ØµØ¯Ø±. "
                  "Ø¨Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…Ø±ÙƒØ²Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ Ù„ÙŠÙ†Ø§Ø³Ø¨ 280 Ø­Ø±ÙØ§Ù‹.")
        
        response = client.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt,
            config=types.GenerateContentConfig(tools=[google_search_tool])
        )
        return clean_text(response.text.strip()) if response.text else None
    except Exception as e:
        logging.error(f"âš ï¸ Gemini Error: {e}")
        return None

def generate_with_qwen_groq():
    try:
        api_key = os.getenv("QWEN_API_KEY")
        if not api_key: return None
        client = OpenAI(api_key=api_key, base_url="https://api.groq.com/openai/v1")
        completion = client.chat.completions.create(
            model="qwen-2.5-32b",
            messages=[{"role": "user", "content": "Ù‡Ø§Øª Ø®Ø¨Ø± ØªÙ‚Ù†ÙŠ Ø¬Ø¯ÙŠØ¯ (Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ) Ù…Ø±ÙƒØ² Ø¬Ø¯Ø§Ù‹ Ù…Ø¹ Ø§Ù„Ù…ÙŠØ²Ø© ÙˆØ§Ù„ÙØ§Ø¦Ø¯Ø© ÙˆØ§Ù„Ù…ØµØ¯Ø±."}]
        )
        return clean_text(completion.choices[0].message.content)
    except Exception as e:
        logging.error(f"âš ï¸ Groq Error: {e}")
        return None

def publish_tech_tweet():
    try:
        logging.info("ğŸš€ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø°Ùˆ Ù‚ÙŠÙ…Ø© Ø¹Ø§Ù„ÙŠØ©...")
        content = generate_with_gemini() or generate_with_qwen_groq() or get_pro_tips()

        final_tweet = smart_truncate(content)

        client = tweepy.Client(
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        
        client.create_tweet(text=final_tweet)
        logging.info(f"âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø±! Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {len(final_tweet)}")
            
    except Exception as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {e}")

if __name__ == "__main__":
    publish_tech_tweet()
