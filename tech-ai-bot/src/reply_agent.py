import os
import tweepy
from google import genai
from datetime import datetime, timezone, timedelta
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ GitHub Actions
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_reply_bot():
    """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ X Ù…Ø¹ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
    # Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù†Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Bearer Token ÙˆØ­Ø¯Ù‡Ø› ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø©
    return tweepy.Client(
        bearer_token=os.getenv('X_BEARER_TOKEN'),
        consumer_key=os.getenv('X_API_KEY'),
        consumer_secret=os.getenv('X_API_SECRET'),
        access_token=os.getenv('X_ACCESS_TOKEN'),
        access_token_secret=os.getenv('X_ACCESS_TOKEN_SECRET')
    )

def generate_smart_reply(question: str) -> str:
    """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini 2.0 Flash"""
    client_ai = genai.Client(api_key=os.getenv('GEMINI_KEY'))
    
    prompt = (
        "Ø£Ù†Øª Ø¨ÙˆØª ØªÙ‚Ù†ÙŠ Ø°ÙƒÙŠ ÙˆÙ…Ù‡Ø°Ø¨ Ø§Ø³Ù…Ùƒ 'ØªÙŠÙƒ Ø¨ÙˆØª'. "
        "Ø£Ø¬Ø¨ Ø¹Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¥ÙŠØ¬Ø§Ø² Ø´Ø¯ÙŠØ¯ (Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©)ØŒ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ØŒ "
        "Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø­ØªØ±Ù.\n\n"
        f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question}"
    )
    
    try:
        response = client_ai.models.generate_content(
            model="gemini-2.0-flash", 
            contents=prompt
        )
        reply = response.text.strip()
        return reply[:270] # ØªÙˆÙŠØªØ± ÙŠØ³Ù…Ø­ Ø¨Ù€ 280 Ø­Ø±Ù ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
    except Exception as e:
        logging.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯: {e}")
        return "Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„Ùƒ! Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ù‚Ø±ÙŠØ¨Ø§Ù‹. ğŸ¤–"

def process_mentions(bot_username: str):
    client = get_reply_bot()
    
    try:
        me = client.get_me()
        user_id = me.data.id
        logging.info(f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­ ÙƒÙ€ @{me.data.username}")
    except Exception as e:
        logging.error(f"ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return

    # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù†Ø´Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    mentions = client.get_users_mentions(id=user_id, max_results=10, tweet_fields=["created_at"])

    if not mentions or not mentions.data:
        logging.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù†Ø´Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙ‡Ø§.")
        return

    for mention in mentions.data:
        # ÙØ­Øµ Ø§Ù„ÙˆÙ‚Øª (Ø¢Ø®Ø± 24 Ø³Ø§Ø¹Ø© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø³Ø¬Ù„Ø§Øª ÙØ§Ø±ØºØ©)
        if (datetime.now(timezone.utc) - mention.created_at) > timedelta(hours=24):
            continue

        question = mention.text.lower().replace(f"@{bot_username.lower()}", "").strip()
        reply_text = generate_smart_reply(question)

        try:
            client.create_tweet(text=reply_text, in_reply_to_tweet_id=mention.id)
            logging.info(f"âœ… ØªÙ… Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù„ØªØºØ±ÙŠØ¯Ø© ID: {mention.id}")
        except Exception as e:
            logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {e}")

if __name__ == "__main__":
    BOT_NAME = os.getenv("BOT_USERNAME", "TechAI_Bot")
    process_mentions(BOT_NAME)
