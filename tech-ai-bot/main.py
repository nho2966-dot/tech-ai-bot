import os
import time
import random
import json
import logging
import sqlite3
from datetime import datetime, timedelta
import tweepy
from openai import OpenAI
from dotenv import load_dotenv
from collections import deque
from threading import Thread, Lock
from queue import Queue
from typing import Dict, Optional, List
import requests  # Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ØµØ§Ø¯Ø±

# â”€â”€â”€ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | [TechAgent-Pro-Global] | %(levelname)-5s | %(message)s',
    handlers=[logging.FileHandler("agent_logs.log"), logging.StreamHandler()]
)

# â”€â”€â”€ ØªÙƒÙˆÙŠÙ†Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG = {
    "STATE_FILE": "agent_state.json",
    "DB_FILE": "agent_db.sqlite",              # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ø±Ø¯ÙˆØ¯
    "MAX_REPLIES_PER_HOUR": 15,                # Ø­Ø¯ Ø£Ù…Ø§Ù† Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø³Ø¨Ø§Ù…
    "MIN_FOLLOWERS_FOR_REPLY": 100,            # Ø±Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨Ø§Øª Ø°Ø§Øª ØªØ£Ø«ÙŠØ± (Ù„Ù„Ø´Ù‡Ø±Ø©)
    "CONTENT_POST_INTERVAL_HOURS": 3,          # Ù†Ø´Ø± Ù…Ø­ØªÙˆÙ‰ Ø£ØµÙ„ÙŠ ÙƒÙ„ 3 Ø³Ø§Ø¹Ø§Øª
    "TREND_SEARCH_INTERVAL_MIN": 8,            # Ø¨Ø­Ø« Ø¹Ù† ØªØ±ÙŠÙ†Ø¯Ø§Øª ÙƒÙ„ 8 Ø¯Ù‚Ø§Ø¦Ù‚
    "REPLY_COOLDOWN_SEC": 30,                  # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„Ø±Ø¯ÙˆØ¯ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¢Ù„ÙŠ
    "SUPPORTED_LANGUAGES": ["ar", "en", "fr", "es"],  # Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
    "MAX_REPLY_LENGTH": 270,                   # Ø­Ø¯ X
    "USE_WEB_SEARCH_FOR_SOURCES": True,        # ØªÙƒØ§Ù…Ù„ Ø¨Ø­Ø« ÙˆÙŠØ¨ Ù„Ù„Ù…ØµØ§Ø¯Ø±
    "TRUSTED_SOURCES_DOMAINS": [               # ÙÙ„ØªØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± 100% Ù…ÙˆØ«ÙˆÙ‚Ø©
        "techcrunch.com", "theverge.com", "wired.com", "arstechnica.com",
        "cnet.com", "engadget.com", "bloomberg.com", "reuters.com",
        "apple.com", "blog.google", "microsoft.com", "nvidia.com",
        "samsung.com", "playstation.com", "x.ai"
    ]
}

REPLY_QUEUE = Queue()                          # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ø±Ø¯ÙˆØ¯ (Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠÙˆØ·)
STATE_LOCK = Lock()                            # Ù‚ÙÙ„ Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø¢Ù…Ù†
STATS_DB_CONN = sqlite3.connect(CONFIG["DB_FILE"], check_same_thread=False)
STATS_DB_CURSOR = STATS_DB_CONN.cursor()

# Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
STATS_DB_CURSOR.execute('''
    CREATE TABLE IF NOT EXISTS agent_stats (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        timestamp TEXT,
        action_type TEXT,
        details TEXT,
        success BOOLEAN
    )
''')
STATS_DB_CONN.commit()

# â”€â”€â”€ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TECH_TOPICS = {
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": [
        "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "AI", "Ø°ÙƒØ§Ø¡", "Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "gpt", "grok", "llm", "Ù†Ù…Ø§Ø°Ø¬ Ù„ØºÙˆÙŠØ©",
        "machine learning", "ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ", "deep learning", "midjourney", "stable diffusion"
    ],
    "Ù…Ù†ØµØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ": [
        "ØªÙˆÙŠØªØ±", "x", "ØªÙŠÙƒ ØªÙˆÙƒ", "Ø§Ù†Ø³ØªØºØ±Ø§Ù…", "Ø³Ù†Ø§Ø¨", "ÙÙŠØ³Ø¨ÙˆÙƒ", "Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©", "ØªØ±ÙŠÙ†Ø¯",
        "engagement", "ØªÙØ§Ø¹Ù„", "Ø±ÙŠØªÙˆÙŠØª", "Ù…Ù†Ø´Ù†", "Ù‡Ø§Ø´ØªØ§Ø¬", "threads"
    ],
    "Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©": [
        "Ø§Ù„Ø¹Ø§Ø¨", "gaming", "Ø¨Ù„Ø§ÙŠØ³ØªÙŠØ´Ù†", "Ø§ÙƒØ³ Ø¨ÙˆÙƒØ³", "fortnite", "gta", "call of duty",
        "esports", "vr", "ar", "steam", "Ù†ÙŠÙ†ØªÙ†Ø¯Ùˆ", "Ø¨Ø¨Ø¬ÙŠ", "ÙØ§Ù„ÙˆØ±Ø§Ù†Øª"
    ],
    "Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©": [
        "ØªØ³Ø±ÙŠØ¨", "leak", "ØªØ³Ø±ÙŠØ¨Ø§Øª", "rumor", "ming-chi kuo", "mark gurman",
        "iphone 17", "galaxy s25", "pixel 10", "ØªØ³Ø±ÙŠØ¨", "Ø´Ø§Ø¦Ø¹Ø©"
    ],
    "Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø°ÙƒÙŠØ©": [
        "iphone", "Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬", "pixel", "Ù‡Ø§ØªÙ", "Ø³Ù…Ø§Ø¹Ø©", "Ø³Ø§Ø¹Ø© Ø°ÙƒÙŠØ©", "airpods",
        "watch", "fold", "flip", "Ù…Ø¹Ø§Ù„Ø¬", "snapdragon", "a18", "exynos"
    ],
    "Ø§Ù„Ø³Ø¨Ù‚ Ø§Ù„ØµØ­ÙÙŠ Ø§Ù„ØªÙ‚Ù†ÙŠ": [
        "Ø¥Ø·Ù„Ø§Ù‚", "announce", "Ù…Ø¤ØªÙ…Ø±", "ces", "wwdc", "google i/o", "samsung unpacked",
        "Ø­Ø¯Ø«", "Ø¥Ø¹Ù„Ø§Ù†", "Ø®Ø¨Ø± Ø¹Ø§Ø¬Ù„", "breaking"
    ]
}

ALL_KEYWORDS = set(word.lower() for words in TECH_TOPICS.values() for word in words)

class AutonomousTechAgent:
    def __init__(self):
        # X API v2 Client Ù…Ø¹ ØªØ­Ù‚Ù‚ Ù…ØªÙ‚Ø¯Ù…
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET"),
            wait_on_rate_limit=True
        )

        # OpenAI Ù…Ø¹ ØªÙƒÙˆÙŠÙ†Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ©
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ .env")
        self.ai_client = OpenAI(api_key=api_key)
        self.model = "gpt-4o"  # Ù†Ù…ÙˆØ°Ø¬ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø¬ÙˆØ¯Ø© Ù„Ù„Ø¯Ù‚Ø©

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        me = self.x_client.get_me(user_fields=["username", "public_metrics"])
        self.my_id = me.data.id
        self.my_username = me.data.username
        self.followers_count = me.data.public_metrics["followers_count"]
        logging.info(f"ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ @{self.my_username} | Ù…ØªØ§Ø¨Ø¹ÙˆÙ†: {self.followers_count} | ØªØ§Ø±ÙŠØ®: {datetime.now().isoformat()}")

        # Ø­Ø§Ù„Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ (Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©)
        self.state = self._load_state()
        self.recent_replies = deque(maxlen=CONFIG["MAX_REPLIES_PER_HOUR"])  # ØªØªØ¨Ø¹ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ù„Ù„Ø­Ø¯ÙˆØ¯
        self.last_content_post = datetime.fromisoformat(self.state.get("last_content_post", datetime.min.isoformat()))
        self.stats = {"replies_sent": 0, "content_posted": 0, "trends_replied": 0}  # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©

        # Ø®ÙŠÙˆØ· Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ (Ø±Ø¯ÙˆØ¯ØŒ ØªØ±ÙŠÙ†Ø¯Ø§ØªØŒ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª)
        self.reply_thread = Thread(target=self._process_reply_queue, daemon=True)
        self.trend_thread = Thread(target=self._trend_monitor_loop, daemon=True)
        self.stats_thread = Thread(target=self._log_stats_periodically, daemon=True)
        self.reply_thread.start()
        self.trend_thread.start()
        self.stats_thread.start()

    def _load_state(self) -> Dict:
        if os.path.exists(CONFIG["STATE_FILE"]):
            try:
                with open(CONFIG["STATE_FILE"], "r") as f:
                    return json.load(f)
            except Exception as e:
                logging.warning(f"ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­Ø§Ù„Ø©: {e}")
        return {"last_tweet_id": None, "replies_today": 0, "last_content_post": datetime.min.isoformat()}

    def _save_state(self):
        with STATE_LOCK:
            try:
                self.state["last_content_post"] = self.last_content_post.isoformat()
                with open(CONFIG["STATE_FILE"], "w") as f:
                    json.dump(self.state, f, indent=2)
            except Exception as e:
                logging.error(f"ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø©: {e}")

    def _log_action(self, action_type: str, details: str, success: bool = True):
        """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„Ø§Ø­Ù‚"""
        try:
            STATS_DB_CURSOR.execute('''
                INSERT INTO agent_stats (timestamp, action_type, details, success)
                VALUES (?, ?, ?, ?)
            ''', (datetime.now().isoformat(), action_type, details, success))
            STATS_DB_CONN.commit()
        except Exception as e:
            logging.error(f"ÙØ´Ù„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©: {e}")

    def _log_stats_periodically(self):
        """Ø®ÙŠØ· Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø³Ø§Ø¹Ø©"""
        while True:
            time.sleep(3600)  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
            details = json.dumps(self.stats)
            self._log_action("hourly_stats", details)
            logging.info(f"Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø§Ø¹Ø©: {details}")

    def _is_relevant_topic(self, text: str) -> bool:
        text_lower = text.lower()
        return any(kw in text_lower for kw in ALL_KEYWORDS)

    def _validate_source(self, source_url: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ 100%"""
        if not source_url:
            return False
        domain = source_url.split('//')[-1].split('/')[0].lower()
        return any(trusted in domain for trusted in CONFIG["TRUSTED_SOURCES_DOMAINS"])

    def _fetch_source_snippet(self, query: str) -> Optional[str]:
        """Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø³Ø±ÙŠØ¹ Ù„Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ (Ø¥Ø°Ø§ ØªÙ… ØªÙØ¹ÙŠÙ„Ù‡)"""
        if not CONFIG["USE_WEB_SEARCH_FOR_SOURCES"]:
            return None
        try:
            # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… API Ø¨Ø­Ø« ÙˆÙŠØ¨ Ø®Ø§Ø±Ø¬ÙŠØŒ Ù„ÙƒÙ† Ù„Ù„Ø¨Ø³Ø§Ø·Ø© Ù†Ø³ØªØ®Ø¯Ù… requests ÙƒÙ…Ø«Ø§Ù„
            search_url = f"https://www.google.com/search?q={query}+site:{random.choice(CONFIG['TRUSTED_SOURCES_DOMAINS'])}"
            response = requests.get(search_url, timeout=5)
            if response.status_code == 200:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ Ø±Ø§Ø¨Ø· (Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·ØŒ ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡ Ø¨Ù€ BeautifulSoup)
                if "theverge.com" in response.text:
                    return "Ø§Ù„Ù…ØµØ¯Ø±: The Verge (Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø¨Ø­Ø« Ù…ÙˆØ«ÙˆÙ‚)"
            return None
        except Exception as e:
            logging.debug(f"ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØµØ¯Ø±: {e}")
            return None

    def _generate_professional_reply(self, tweet_text: str, author: str, is_trend: bool = False) -> str | None:
        if not self._is_relevant_topic(tweet_text):
            return (
                f"Ù…Ø±Ø­Ø¨Ù‹Ø§ @{author}ØŒ Ø´ÙƒØ±Ù‹Ø§ Ù„Ù„Ø¥Ø´Ø§Ø±Ø©! ğŸŒ\n"
                "Ø£Ù†Ø§ TechAgent ProØŒ Ø®Ø¨ÙŠØ± ÙÙŠ Ø£Ø®Ø¨Ø§Ø± ØªÙ‚Ù†ÙŠØ© Ù…ÙˆØ«ÙˆÙ‚Ø© 100% Ù…Ù† Ù…ØµØ§Ø¯Ø± Ø±Ø³Ù…ÙŠØ© ÙÙ‚Ø·.\n"
                "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ ØªÙˆØ¶ÙŠØ­ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„ØªÙ‚Ù†ÙŠØŸ Ø³Ø£Ø±Ø¯ Ø¨Ø¯Ù‚Ø© ÙˆÙ…ØµØ§Ø¯Ø± ÙˆØ§Ø¶Ø­Ø©! #TechGlobal"
            )

        source_snippet = self._fetch_source_snippet(tweet_text[:50])  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØµØ¯Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠ

        system_prompt = (
            "Ø£Ù†Øª TechAgent Pro â€“ Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø¹Ø§Ù„Ù…ÙŠØŒ Ù…Ù‡Ù†ÙŠØŒ Ù…Ø­Ø§ÙŠØ¯ØŒ ÙŠØ¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª (Ø§ÙƒØªØ´Ù Ø§Ù„Ù„ØºØ© Ù…Ù† Ø§Ù„Ù†Øµ ÙˆØ±Ø¯ Ø¨Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©).\n"
            "ØªØ±ÙƒÙŠØ²Ùƒ: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ù…Ù†ØµØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ØŒ Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ØŒ Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§ØªØŒ Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©ØŒ Ø§Ù„Ø³Ø¨Ù‚ Ø§Ù„ØµØ­ÙÙŠ.\n"
            "Ù„Ù„Ø´Ù‡Ø±Ø©: Ø£Ø¶Ù Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø©ØŒ Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ©ØŒ Ø´Ø¬Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…ØªØ¨Ø§Ø¯Ù„.\n"
            "Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© 100%:\n"
            "1. Ù„Ø§ ØªÙ‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¥Ù„Ø§ Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ Ù…Ù†: " + ", ".join(CONFIG["TRUSTED_SOURCES_DOMAINS"]) + ".\n"
            "2. Ø£Ø¶Ù ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©: [Ø§Ù„Ù…ØµØ¯Ø±: Ø§Ø³Ù… Ø§Ù„Ù…ÙˆÙ‚Ø¹ - ØªØ§Ø±ÙŠØ®] Ø£Ùˆ 'Ù„Ø§ Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ Ø­Ø§Ù„ÙŠÙ‹Ø§'.\n"
            "3. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ â†’ Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©ØŒ Ø§Ù‚ØªØ±Ø­ Ø¨Ø­Ø«Ù‹Ø§.\n"
            "4. Ø±Ø¯ÙˆØ¯ <" + str(CONFIG["MAX_REPLY_LENGTH"]) + " Ø­Ø±ÙÙ‹Ø§ØŒ Ù…Ù‡Ù†ÙŠØ©ØŒ ØªÙØªØ­ Ù†Ù‚Ø§Ø´Ù‹Ø§.\n"
            "5. Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª: Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© (AR/EN/FR/ES).\n"
            "6. Ù„Ù„ØªØ±ÙŠÙ†Ø¯Ø§Øª: Ø±Ø¤ÙŠØ© Ø¹Ø§Ù„Ù…ÙŠØ© + Ø¯Ø¹ÙˆØ© Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ©.\n"
            "ØªØ°ÙƒØ±: (ÙˆÙØ¶ÙÙ€ÙˆØ­) = Ø¶Ù… Ø§Ù„Ø´ÙØªÙŠÙ† Ø¬ÙŠØ¯Ù‹Ø§"
        )

        user_msg = (
            f"@{author} ÙƒØªØ¨: Â«{tweet_text}Â»\n"
            f"{'Ø±Ø¯ Ø¹Ù„Ù‰ ØªØ±ÙŠÙ†Ø¯ Ø¹Ø§Ù„Ù…ÙŠ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¸Ù‡ÙˆØ±.' if is_trend else ''}\n"
            f"Ù…ØµØ¯Ø± Ù…Ù‚ØªØ±Ø­: {source_snippet if source_snippet else 'Ù„Ø§ Ù…ØµØ¯Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØŒ ØªØ­Ù‚Ù‚ ÙŠØ¯ÙˆÙŠÙ‹Ø§'}\n"
            "Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ø¯ ÙÙ‚Ø·."
        )

        try:
            resp = self.ai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_msg}
                ],
                temperature=0.58,
                max_tokens=150,
                top_p=0.93
            )
            reply = resp.choices[0].message.content.strip().replace("```", "").replace("\n\n", " ")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…ØµØ¯Ø±
            if "[Ø§Ù„Ù…ØµØ¯Ø±:" not in reply and "Ù„Ø§ Ù…ØµØ¯Ø±" not in reply:
                reply += "\n[Ù„Ø§ Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ Ø­Ø¯ÙŠØ«Ù‹Ø§ â€“ ÙŠÙÙØ¶Ù„ Ø§Ù„ØªØ­Ù‚Ù‚]"

            return reply if len(reply) <= CONFIG["MAX_REPLY_LENGTH"] else reply[:CONFIG["MAX_REPLY_LENGTH"] - 3] + "â€¦"

        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ AI: {e}")
            return None

    def _process_reply_queue(self):
        while True:
            task = REPLY_QUEUE.get()
            if task is None:
                break
            tweet_id, reply_text = task
            try:
                self.x_client.create_tweet(text=reply_text, in_reply_to_tweet_id=tweet_id)
                logging.info(f"Ø±Ø¯ Ù†Ø§Ø¬Ø­ Ø¹Ù„Ù‰ {tweet_id}: {reply_text[:50]}...")
                self.stats["replies_sent"] += 1
                self._log_action("reply_sent", f"Tweet ID: {tweet_id}", success=True)
                time.sleep(CONFIG["REPLY_COOLDOWN_SEC"])  # ØªØ£Ø®ÙŠØ± Ø§Ø­ØªØ±Ø§ÙÙŠ
            except tweepy.TweepyException as te:
                logging.error(f"ÙØ´Ù„ Ø±Ø¯: {te}")
                self._log_action("reply_failed", str(te), success=False)
            REPLY_QUEUE.task_done()

    def _can_reply(self, author_followers: int = 0) -> bool:
        now = datetime.now()
        recent_count = sum(1 for t in self.recent_replies if now - t < timedelta(hours=1))
        return recent_count < CONFIG["MAX_REPLIES_PER_HOUR"] and author_followers >= CONFIG["MIN_FOLLOWERS_FOR_REPLY"]

    def _post_original_content(self):
        # ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø£ØµÙ„ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ (Ù…Ø¹ Ù…ØµØ¯Ø±)
        system_prompt = (
            "Ø£Ù†Ø´Ø¦ ØªØºØ±ÙŠØ¯Ø© Ø£ØµÙ„ÙŠØ© Ø¹Ø§Ù„Ù…ÙŠØ© Ø­ÙˆÙ„ Ù…ÙˆØ¶ÙˆØ¹ ØªÙ‚Ù†ÙŠ Ø³Ø§Ø®Ù† Ù…Ù† Ù…ÙˆØ§Ø¶ÙŠØ¹Ùƒ.\n"
            "Ø§Ø¬Ø¹Ù„Ù‡Ø§ Ø¬Ø°Ø§Ø¨Ø©ØŒ Ù…Ù‡Ù†ÙŠØ©ØŒ ØªØ´Ø¬Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ (Ø³Ø¤Ø§Ù„ Ø£Ùˆ poll).\n"
            "<270 Ø­Ø±ÙÙ‹Ø§ØŒ Ø£Ø¶Ù Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ©ØŒ ÙˆÙ…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©.\n"
            "Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª Ø¥Ø°Ø§ Ù„Ø²Ù…."
        )

        try:
            resp = self.ai_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "system", "content": system_prompt}],
                temperature=0.72,
                max_tokens=150
            )
            content = resp.choices[0].message.content.strip()
            self.x_client.create_tweet(text=content)
            logging.info(f"Ù†Ø´Ø± Ù…Ø­ØªÙˆÙ‰ Ø£ØµÙ„ÙŠ: {content[:50]}...")
            self.stats["content_posted"] += 1
            self.last_content_post = datetime.now()
            self._save_state()
            self._log_action("content_posted", content[:100], success=True)
        except Exception as e:
            logging.error(f"ÙØ´Ù„ Ù†Ø´Ø± Ù…Ø­ØªÙˆÙ‰: {e}")
            self._log_action("content_post_failed", str(e), success=False)

    def _trend_monitor_loop(self):
        """Ø®ÙŠØ· Ù…Ø³ØªÙ‚Ù„ Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ±ÙŠÙ†Ø¯Ø§Øª ÙˆØ±Ø¯ Ø¹Ù„ÙŠÙ‡Ø§"""
        last_trend_check = datetime.min
        while True:
            if datetime.now() - last_trend_check > timedelta(minutes=CONFIG["TREND_SEARCH_INTERVAL_MIN"]):
                self._reply_to_trends()
                last_trend_check = datetime.now()
            time.sleep(60)  # ÙØ­Øµ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ø®ÙŠØ·

    def _reply_to_trends(self):
        try:
            topic = random.choice(list(TECH_TOPICS.keys()))
            query = f"{' OR '.join(random.sample(TECH_TOPICS[topic], min(3, len(TECH_TOPICS[topic]))))} min_faves:200 lang:en OR lang:ar -from:{self.my_username}"
            trends = self.x_client.search_recent_tweets(
                query=query,
                max_results=8,
                sort_order="relevancy",
                tweet_fields=["public_metrics"],
                expansions=["author_id"],
                user_fields=["public_metrics"]
            )

            if trends.data:
                for tweet in trends.data:
                    author = next(u.username for u in trends.includes["users"] if u.id == tweet.author_id)
                    author_followers = next(u.public_metrics["followers_count"] for u in trends.includes["users"] if u.id == tweet.author_id)
                    if tweet.public_metrics["like_count"] > 300 and self._can_reply(author_followers):
                        reply_text = self._generate_professional_reply(tweet.text, author, is_trend=True)
                        if reply_text:
                            REPLY_QUEUE.put((tweet.id, reply_text))
                            self.stats["trends_replied"] += 1
                            self._log_action("trend_reply", f"Trend from @{author}", success=True)

        except Exception as e:
            logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±ÙŠÙ†Ø¯Ø§Øª: {e}")
            self._log_action("trend_error", str(e), success=False)

    def start_monitoring(self, check_interval_sec: int = 60):
        logging.info("Ø¨Ø¯Ø¡ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ... (Ù…Ø±Ø§Ù‚Ø¨Ø© + ØªØ±ÙŠÙ†Ø¯Ø§Øª + Ù…Ø­ØªÙˆÙ‰ + Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª + Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª)")

        while True:
            try:
                # 1. Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ù†Ø´Ù†Ø§Øª Ù…Ø¹ ÙÙ„ØªØ± Ø§Ø­ØªØ±Ø§ÙÙŠ
                mentions = self.x_client.get_users_mentions(
                    id=self.my_id,
                    max_results=25,
                    since_id=self.state.get("last_tweet_id"),
                    expansions=["author_id"],
                    user_fields=["username", "public_metrics"],
                    tweet_fields=["created_at", "public_metrics"]
                )

                if mentions.data:
                    sorted_mentions = sorted(mentions.data, key=lambda t: t.id, reverse=True)
                    for tweet in sorted_mentions:
                        author_obj = next((u for u in mentions.includes.get("users", []) if u.id == tweet.author_id), None)
                        if not author_obj:
                            continue
                        author = author_obj.username
                        author_followers = author_obj.public_metrics["followers_count"]
                        if author.lower() == self.my_username.lower() or author_followers < CONFIG["MIN_FOLLOWERS_FOR_REPLY"]:
                            continue  # ÙÙ„ØªØ± Ù„Ù„Ø¬ÙˆØ¯Ø©

                        if self._can_reply(author_followers):
                            logging.info(f"Ù…Ù†Ø´Ù† Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ù† @{author} (Ù…ØªØ§Ø¨Ø¹ÙˆÙ†: {author_followers}): {tweet.text[:70]}...")
                            reply_text = self._generate_professional_reply(tweet.text, author)
                            if reply_text:
                                REPLY_QUEUE.put((tweet.id, reply_text))

                        if tweet.id > (self.state.get("last_tweet_id") or 0):
                            self.state["last_tweet_id"] = tweet.id
                            self._save_state()

                # 2. Ù†Ø´Ø± Ù…Ø­ØªÙˆÙ‰ Ø£ØµÙ„ÙŠ Ø¥Ø°Ø§ Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª
                if datetime.now() - self.last_content_post > timedelta(hours=CONFIG["CONTENT_POST_INTERVAL_HOURS"]):
                    self._post_original_content()

                # ØªØ£Ø®ÙŠØ± Ø°ÙƒÙŠ Ù…Ø¹ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
                sleep_time = check_interval_sec + random.uniform(-20, 25)
                time.sleep(max(50, sleep_time))

            except tweepy.TooManyRequests:
                logging.warning("Rate limit â†’ Ø§Ù†ØªØ¸Ø§Ø± Ø·ÙˆÙŠÙ„ (15 Ø¯Ù‚ÙŠÙ‚Ø©)")
                time.sleep(900)
            except Exception as e:
                logging.error(f"Ø®Ø·Ø£ Ø¹Ø§Ù…: {e}", exc_info=True)
                self._log_action("general_error", str(e), success=False)
                time.sleep(300)

    def shutdown(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ù†Ø¸ÙŠÙ Ù„Ù„Ø®ÙŠÙˆØ· ÙˆØ§Ù„Ù‚Ø§Ø¹Ø¯Ø©"""
        REPLY_QUEUE.put(None)
        self.reply_thread.join()
        self.trend_thread.join()
        self.stats_thread.join()
        STATS_DB_CONN.close()
        logging.info("Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­.")

if __name__ == "__main__":
    try:
        agent = AutonomousTechAgent()
        agent.start_monitoring()
    except KeyboardInterrupt:
        logging.info("Ø¥ÙŠÙ‚Ø§Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….")
        agent.shutdown()
    except Exception as e:
        logging.critical(f"Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}", exc_info=True)
        agent.shutdown()
