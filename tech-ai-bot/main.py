import os
import tweepy
import google.genai as genai
import requests
import logging
import hashlib
import random
from datetime import datetime
from dotenv import load_dotenv

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
load_dotenv()
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Ù…Ù„Ù Ø­ÙØ¸ Ø§Ù„Ù‡Ø§Ø´ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
LAST_HASH_FILE = "last_hash.txt"

# 2. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„ØªØ¯Ù‚ÙŠÙ‚
def get_content_hash(text: str) -> str:
    """ØªÙˆÙ„ÙŠØ¯ Ø¨ØµÙ…Ø© Ø±Ù‚Ù…ÙŠØ© Ù„Ù„Ù†Øµ."""
    return hashlib.md5(text.encode('utf-8')).hexdigest()[:8]

def is_duplicate(content: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª."""
    current_hash = get_content_hash(content)
    try:
        if os.path.exists(LAST_HASH_FILE):
            with open(LAST_HASH_FILE, "r", encoding="utf-8") as f:
                if f.read().strip() == current_hash:
                    logging.info("ğŸš« Ù…Ø­ØªÙˆÙ‰ Ù…ÙƒØ±Ø± ØªÙ… Ø±ØµØ¯Ù‡ â€” Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù†Ø´Ø±.")
                    return True
        
        # Ø­ÙØ¸ Ø§Ù„Ù‡Ø§Ø´ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        with open(LAST_HASH_FILE, "w", encoding="utf-8") as f:
            f.write(current_hash)
        return False
    except Exception as e:
        logging.warning(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡ ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù‡Ø§Ø´: {e}")
        return False

# 3. Ù…Ø­Ø±Ùƒ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
def generate_tech_content():
    """ØªÙˆÙ„ÙŠØ¯ ØªØºØ±ÙŠØ¯Ø© ØªÙ‚Ù†ÙŠØ© Ù…Ø¹ØªÙ…Ø¯Ø© Ø¹Ù„Ù‰ Ù…ØµØ§Ø¯Ø± Ø¹Ø§Ù„Ù…ÙŠØ©."""
    
    trusted_sources = [
        "The Verge", "TechCrunch", "GSMArena", "Wired", 
        "Reuters Tech", "Bloomberg Technology", "9to5Mac"
    ]
    source = random.choice(trusted_sources)

    prompt = f"""
    Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© ØªÙ‚Ù†ÙŠØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¬Ø¯Ø§Ù‹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ù…ÙˆØ«ÙˆÙ‚Ø© Ù…Ù† ({source}).
    
    Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
    ğŸ›¡ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ©: (
