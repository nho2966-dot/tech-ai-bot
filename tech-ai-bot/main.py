import os
import tweepy
import requests
import logging
import random
import re
from datetime import datetime
import pytz
from dotenv import load_dotenv

# âœ… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø®Ø¨Ø©
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(asctime)s - [MASTER-AI] - %(message)s')

client = tweepy.Client(
    bearer_token=os.getenv("X_BEARER_TOKEN"),
    consumer_key=os.getenv("X_API_KEY"),
    consumer_secret=os.getenv("X_API_SECRET"),
    access_token=os.getenv("X_ACCESS_TOKEN"),
    access_token_secret=os.getenv("X_ACCESS_SECRET")
)

ARCHIVE_FILE = "published_archive.txt"

def is_duplicate(identifier):
    if not os.path.exists(ARCHIVE_FILE): return False
    with open(ARCHIVE_FILE, "r", encoding="utf-8") as f:
        return identifier.lower()[:60] in f.read().lower()

def save_to_archive(identifier):
    with open(ARCHIVE_FILE, "a", encoding="utf-8") as f:
        f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M')}: {identifier}\n")

def generate_ai_content(prompt_type, context_data="", username=""):
    try:
        system_persona = (
            "Ø£Ù†Øª 'Cyber Hunter'. Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ ÙˆØ¯ÙˆØ¯ ÙˆØ­Ø§Ø³Ù…. "
            "Ù‚Ø§Ø¹Ø¯Ø© ØµØ§Ø±Ù…Ø©: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø±Ø¯Ùƒ ÙƒØ§Ù…Ù„Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 240 Ø­Ø±ÙØ§Ù‹). "
            "Ø§Ù„Ù‡ÙŠÙƒÙ„: ØªØ­ÙŠØ© -> Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¯Ø³Ù…Ø© ÙˆÙ…Ø®ØªØµØ±Ø© -> Ø³Ø¤Ø§Ù„ Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ù…ØªØ§Ø¨Ø¹."
        )
        
        user_msg = f"Ø±Ø¯ Ø¹Ù„Ù‰ @{username}: {context_data}" if prompt_type == "reply" else f"Ø§ÙƒØªØ¨ ØªØºØ±ÙŠØ¯Ø© Ø¹Ù†: {context_data}"

        res = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={"Authorization": f"Bearer {os.getenv('OPENROUTER_API_KEY')}"},
            json={
                "model": "meta-llama/llama-3.1-70b-instruct",
                "messages": [{"role": "system", "content": system_persona}, {"role": "user", "content": user_msg}],
                "max_tokens": 150 # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªÙˆÙƒÙ†Ø² Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø®ØªØµØ§Ø± ÙˆØ¹Ø¯Ù… Ø§Ù„Ø¨ØªØ±
            }, timeout=45
        )
        return res.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        logging.error(f"âŒ AI Error: {e}")
        return None

def auto_reply():
    try:
        me = client.get_me().data
        mentions = client.get_users_mentions(id=me.id, expansions=['author_id'], user_fields=['username'])
        
        if not mentions or not mentions.data:
            logging.info("ğŸ” Ù„Ø§ Ù…Ù†Ø´Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.")
            return

        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
        users = {u['id']: u['username'] for u in mentions.includes['users']}

        for tweet in mentions.data:
            reply_id = f"reply_{tweet.id}"
            if is_duplicate(reply_id): continue
            
            author_username = users.get(tweet.author_id)
            reply_text = generate_ai_content("reply", tweet.text, author_username)
            
            if reply_text:
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù†Ø´Ù† ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù†Øµ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø±Ø¨Ø· Ø¨Ù€ÙˆÙØ¶ÙÙ€ÙˆØ­
                final_text = f"@{author_username} {reply_text}"
                client.create_tweet(
                    text=final_text[:280], 
                    in_reply_to_tweet_id=tweet.id # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ù‡Ùˆ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ø¬Ø¹Ù„Ù‡Ø§ 'Ø±Ø¯' ÙˆÙ„ÙŠØ³ ØªØºØ±ÙŠØ¯Ø© Ù…Ø³ØªÙ‚Ù„Ø©
                )
                save_to_archive(reply_id)
                logging.info(f"âœ… ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­ Ø¹Ù„Ù‰ {author_username}")
    except Exception as e:
        logging.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø±Ø¯: {e}")

if __name__ == "__main__":
    auto_reply()
    # ÙŠÙ…ÙƒÙ†Ùƒ ØªÙØ¹ÙŠÙ„ post_scoop() Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª Ù†Ø´Ø± ØªØºØ±ÙŠØ¯Ø§Øª Ø¯ÙˆØ±ÙŠØ© Ø£ÙŠØ¶Ø§Ù‹
