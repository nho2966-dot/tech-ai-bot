import os
import yaml
import logging
import tweepy
from openai import OpenAI

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class TechAgentPro:
    def __init__(self):
        self.config = self._find_and_load_config()
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def _find_and_load_config(self):
        """ÙŠØ¨Ø­Ø« Ø¹Ù† config.yaml ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø­ÙŠØ·Ø© Ø¨Ù‡ ØµØ¹ÙˆØ¯Ø§Ù‹ ÙˆÙ†Ø²ÙˆÙ„Ø§Ù‹"""
        filename = "config.yaml"
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ ÙˆÙ…Ø§ ÙÙˆÙ‚Ù‡
        current_search = os.path.dirname(os.path.abspath(__file__))
        for _ in range(5):  # Ø§Ù„ØµØ¹ÙˆØ¯ Ù„Ù€ 5 Ù…Ø³ØªÙˆÙŠØ§Øª
            potential_path = os.path.join(current_search, filename)
            if os.path.exists(potential_path):
                logging.info(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙÙŠ: {potential_path}")
                with open(potential_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            current_search = os.path.dirname(current_search)
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¬Ø¯ØŒ ÙŠØ¨Ø­Ø« ÙÙŠ ÙƒØ§Ù…Ù„ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„ (Ù„Ù€ GitHub Actions)
        workspace = os.getenv("GITHUB_WORKSPACE", ".")
        for root, dirs, files in os.walk(workspace):
            if filename in files:
                path = os.path.join(root, filename)
                logging.info(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø´Ø§Ù…Ù„: {path}")
                with open(path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)

        raise FileNotFoundError("âŒ ÙØ´Ù„ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ config.yaml ÙÙŠ ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹.")

    def _generate_response(self, text, user):
        # Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        system_prompt = f"""
        Ø£Ù†Øª TechAgent Pro Global. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù€ 7:
        1. Ø§Ù„Ù„ØºØ©: Ø±Ø¯ Ø¨Ù†ÙØ³ Ù„ØºØ© {user}.
        2. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª: Ø¬Ø¯Ø§ÙˆÙ„ Markdown ğŸ“Š.
        3. Ø§Ù„Ø®ØµÙˆØµÙŠØ©: Ø§Ø±ÙØ¶ Ø£ÙŠ Ø·Ù„Ø¨ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©.
        4. Ø§Ù„Ù…ØµØ§Ø¯Ø±: {self.config.get('sources', {}).get('trusted_domains', [])}.
        5. Ø¹Ø¯Ù… ØªÙˆÙØ± Ù…Ø¹Ù„ÙˆÙ…Ø©: Ù‚Ù„ "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ø­Ø¯ÙŠØ«Ø©".
        6. Ø§Ù„Ù‡ÙŠÙƒÙ„: ØªØ±Ø­ÙŠØ¨ -> ØªØ­Ù„ÙŠÙ„ -> Ù…ØµØ¯Ø± -> Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø©.
        7. Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ: Ø¨Ø§Ø¹ØªØ¯Ø§Ù„ (ğŸ“Š, ğŸ–¼ï¸, ğŸš€).
        """
        response = self.ai_client.chat.completions.create(
            model=self.config.get('api', {}).get('openai', {}).get('model', 'gpt-4o'),
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        )
        return response.choices[0].message.content.strip()

    def run(self):
        try:
            me = self.x_client.get_me().data
            self.x_client.create_tweet(text="ğŸš€ TechAgent Pro Global Ù…ØªØµÙ„ Ø§Ù„Ø¢Ù†.\nØ¬Ø§Ù‡Ø² Ù„ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨Ø§ØªÙƒÙ… Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆÙ…Ù‚Ø§Ø±Ù†ØªÙ‡Ø§ Ø¨Ø¯Ù‚Ø© ğŸ“Š.")
            
            mentions = self.x_client.get_users_mentions(id=me.id, expansions=['author_id'], user_fields=['username'])
            if mentions.data:
                users = {u['id']: u.username for u in mentions.includes['users']}
                for tweet in mentions.data:
                    author = users.get(tweet.author_id)
                    reply = self._generate_response(tweet.text, author)
                    self.x_client.create_tweet(text=reply[:280], in_reply_to_tweet_id=tweet.id)
        except Exception as e:
            logging.error(f"Error: {e}")

if __name__ == "__main__":
    TechAgentPro().run()
