import os
import yaml
import logging
import tweepy
from openai import OpenAI
from datetime import datetime, timedelta
import random
import time
import hashlib

# â”€â”€â”€ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-5s | %(message)s',
    handlers=[logging.StreamHandler()]
)

LAST_TWEET_FILE = "last_tweet_hash.txt"

class TechAgentPro:
    def __init__(self):
        logging.info("=== TechAgent Pro v8.0 [Super Intelligent Mode] ===")
        self.config = self._load_config()

        # â”€â”€â”€ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Qwen 2.5 72B) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        router_key = os.getenv("OPENROUTER_API_KEY")
        self.ai_client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=router_key or os.getenv("OPENAI_API_KEY")
        )
        self.model = "qwen/qwen-2.5-72b-instruct" if router_key else "gpt-4o-mini"

        # â”€â”€â”€ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù†ØµØ© X â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET"),
            wait_on_rate_limit=True
        )

    def _load_config(self):
        return {"min_followers": 30, "max_replies_per_run": 5}

    def _generate_smart_content(self, system_prompt, user_input):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø¦Ù‚ Ø§Ù„Ø°ÙƒØ§Ø¡"""
        try:
            resp = self.ai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.8, # Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ ÙÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯
                max_tokens=300
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            logging.error(f"AI Generation Error: {e}")
            return None

    def _process_mentions(self):
        """Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø¬Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØ§Ø¨Ø¹ÙŠÙ†"""
        try:
            me = self.x_client.get_me().data
            mentions = self.x_client.get_users_mentions(
                id=me.id, 
                max_results=10, 
                expansions=["author_id", "referenced_tweets.id"],
                tweet_fields=["text", "public_metrics"]
            )
            
            if not mentions.data:
                logging.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§Ø¹Ù„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.")
                return

            # Ù†Ø¸Ø§Ù… Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ
            system_instruction = """Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ Ø¹Ø¨Ù‚Ø±ÙŠØŒ Ø±Ø¯ÙˆØ¯Ùƒ Ø°ÙƒÙŠØ©ØŒ Ù…Ø®ØªØµØ±Ø©ØŒ ÙˆÙ…Ø«ÙŠØ±Ø© Ù„Ù„Ø¥Ø¹Ø¬Ø§Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.
            - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØªÙ‚Ù†ÙŠØ§Ù‹: Ø£Ø¬Ø¨ Ø¨Ø¹Ù…Ù‚ ÙˆØ¨ØµÙŠØ±Ø©.
            - Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø²Ø§Ø­Ø§Ù‹: Ø±Ø¯ Ø¨Ø±ÙˆØ­ Ø¯Ø¹Ø§Ø¨Ø© ØªÙ‚Ù†ÙŠØ© Ø±Ø§Ù‚ÙŠØ©.
            - Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†Ù‚Ø¯Ø§Ù‹: ÙƒÙ† Ø¯ÙŠØ¨Ù„ÙˆÙ…Ø§Ø³ÙŠØ§Ù‹ ÙˆØ°ÙƒÙŠØ§Ù‹.
            - Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙƒØ«Ø± Ù…Ù† 240 Ø­Ø±ÙØ§Ù‹."""

            for tweet in mentions.data:
                logging.info(f"ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø´Ù† Ù…Ù† ID: {tweet.author_id}")
                
                reply_text = self._generate_smart_content(system_instruction, tweet.text)
                
                if reply_text:
                    self.x_client.create_tweet(
                        text=reply_text,
                        in_reply_to_tweet_id=tweet.id
                    )
                    logging.info(f"âœ… ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ø°ÙƒØ§Ø¡ Ø¹Ù„Ù‰: {tweet.text[:30]}...")
                    time.sleep(random.randint(20, 40)) # Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ø¸Ø±
        except Exception as e:
            logging.error(f"Mentions Error: {e}")

    def _publish_leak_tweet(self):
        """Ù†Ø´Ø± ØªØ³Ø±ÙŠØ¨Ø§Øª ÙˆØ³Ø¨Ù‚ ØµØ­ÙÙŠ"""
        system_instruction = "Ø£Ù†Øª Ø±Ø§Ø¯Ø§Ø± Ø§Ù„ØªØ³Ø±ÙŠØ¨Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ Ù„Ø¹Ø§Ù… 2026."
        user_prompt = "Ø£Ø¹Ø·Ù†ÙŠ Ø³Ø¨Ù‚Ø§Ù‹ ØµØ­ÙÙŠØ§Ù‹ ØªÙ‚Ù†ÙŠØ§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ Ø¹Ù† Apple Ø£Ùˆ NvidiaØŒ Ù…ÙƒØªÙˆØ¨Ø§Ù‹ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø´ÙˆÙ‚ Ø¬Ø¯Ø§Ù‹ ÙˆØ°ÙƒÙŠ."
        
        content = self._generate_smart_content(system_instruction, user_prompt)
        
        if content:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… Ø§Ù„ØªÙƒØ±Ø§Ø± (Hash System)
            current_hash = hashlib.md5(content.encode()).hexdigest()
            is_duplicate = False
            if os.path.exists(LAST_TWEET_FILE):
                with open(LAST_TWEET_FILE, "r") as f:
                    if current_hash in f.read(): is_duplicate = True

            if not is_duplicate:
                self.x_client.create_tweet(text=content)
                with open(LAST_TWEET_FILE, "a") as f:
                    f.write(f"{current_hash}|{datetime.now().isoformat()}\n")
                logging.info("ğŸš€ ØªÙ… Ù†Ø´Ø± Ø§Ù„Ø³Ø¨Ù‚ Ø§Ù„ØµØ­ÙÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯.")

    def run(self):
        try:
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Ø§Ù„Ù†Ø´Ø±
            self._process_mentions()
            self._publish_leak_tweet()
        except Exception as e:
            logging.critical(f"Critical Failure: {e}")

if __name__ == "__main__":
    TechAgentPro().run()
