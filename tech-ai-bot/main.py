import os
import yaml
import logging
import tweepy
from openai import OpenAI
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class TechAgentPro:
    def __init__(self):
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø·Ù„Ù‚ Ù„Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù (main.py)
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.config = self._load_config()

        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def _load_config(self):
        config_path = os.path.join(self.script_dir, "config.yaml")
        if not os.path.exists(config_path):
            logging.error(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ: {config_path}")
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø¥Ø°Ø§ ÙØ´Ù„
            config_path = os.path.join(os.getcwd(), "config.yaml")
            
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _generate_response(self, text, user):
        system_prompt = f"""
        Ø£Ù†Øª TechAgent Pro Global. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù€ 7:
        1. Ø§ÙƒØªØ´Ù Ù„ØºØ© {user} ÙˆØ±Ø¯ Ø¨Ù‡Ø§ (Ø¹Ø±Ø¨ÙŠØŒ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŒ Ø¥Ù„Ø®).
        2. Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª: Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ø¯Ø§ÙˆÙ„ Markdown ğŸ“Š.
        3. Ø§Ø±ÙØ¶ Ø·Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© (Privacy Rules).
        4. Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©: {self.config['sources']['trusted_domains']}.
        5. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ù…ØµØ¯Ø± Ù…ÙˆØ«ÙˆÙ‚ Ø­Ø¯ÙŠØ«: Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ù…Ù„Ø© Ø§Ù„Ù€ fallback Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.
        6. Ø§Ù„Ù‡ÙŠÙƒÙ„: ØªØ±Ø­ÙŠØ¨ -> ØªØ­Ù„ÙŠÙ„ ÙˆØ¨Ø­Ø« -> Ù…ØµØ¯Ø± -> Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø© Ø°ÙƒÙŠ.
        7. Ø§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù„Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø¨ØµØ±ÙŠ (ğŸ“Š, ğŸ–¼ï¸, ğŸš€).
        """
        response = self.ai_client.chat.completions.create(
            model=self.config['api']['openai'].get('model', 'gpt-4o'),
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        )
        return response.choices[0].message.content.strip()

    def run(self):
        try:
            me = self.x_client.get_me().data
            logging.info(f"Connected as @{me.username}")
            
            # 1. Ø¥Ø«Ø¨Ø§Øª Ø§Ù„ØªÙˆØ§Ø¬Ø¯
            self.x_client.create_tweet(text="ğŸš€ TechAgent Pro Global Ù…ØªØµÙ„.\nÙ†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠ ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù† ğŸ“Š.")
            
            # 2. ÙØ­Øµ ÙˆØ§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø´Ù†Ø§Øª
            mentions = self.x_client.get_users_mentions(id=me.id, expansions=['author_id'], user_fields=['username'])
            if mentions.data:
                users = {u['id']: u.username for u in mentions.includes['users']}
                for tweet in mentions.data:
                    author = users.get(tweet.author_id)
                    logging.info(f"Processing mention from @{author}")
                    reply = self._generate_response(tweet.text, author)
                    self.x_client.create_tweet(text=reply[:280], in_reply_to_tweet_id=tweet.id)
            
        except Exception as e:
            logging.error(f"Runtime Error: {e}")

if __name__ == "__main__":
    TechAgentPro().run()
