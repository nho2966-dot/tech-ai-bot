import os
import yaml
import logging
import tweepy
from openai import OpenAI

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class TechAgentPro:
    def __init__(self):
        self.config = self._ultra_smart_search()
        self.x_client = tweepy.Client(
            bearer_token=os.getenv("X_BEARER_TOKEN"),
            consumer_key=os.getenv("X_API_KEY"),
            consumer_secret=os.getenv("X_API_SECRET"),
            access_token=os.getenv("X_ACCESS_TOKEN"),
            access_token_secret=os.getenv("X_ACCESS_SECRET")
        )
        self.ai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def _ultra_smart_search(self):
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ù…ÙƒØ§Ù† Ù…Ù…ÙƒÙ† Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¹Ù† Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
        target = "config.yaml"
        # 1. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
        for root, dirs, files in os.walk(os.getcwd()):
            if target in files:
                config_path = os.path.join(root, target)
                logging.info(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù ÙÙŠ: {config_path}")
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
        
        # 2. Ø¥Ø°Ø§ ÙØ´Ù„ØŒ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¨ (Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±)
        parent_dir = os.path.dirname(os.getcwd())
        for root, dirs, files in os.walk(parent_dir):
            if target in files:
                config_path = os.path.join(root, target)
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)

        raise FileNotFoundError("âŒ ØªØ¹Ø°Ø± Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ config.yaml ÙÙŠ Ø£ÙŠ Ù…ÙƒØ§Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹!")

    def _generate_response(self, text, user):
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ø¨Ø¹Ø©
        system_prompt = f"""
        Ø£Ù†Øª TechAgent Pro Global.
        1. Ø§Ù„Ù„ØºØ©: Ø±Ø¯ Ø¨Ù„ØºØ© Ø§Ù„Ø³Ø§Ø¦Ù„ {user}.
        2. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª: Ø§Ø³ØªØ®Ø¯Ù… Ø¬Ø¯Ø§ÙˆÙ„ Markdown ğŸ“Š.
        3. Ø§Ù„Ø®ØµÙˆØµÙŠØ©: Ø§Ø±ÙØ¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©.
        4. Ø§Ù„Ù…ØµØ§Ø¯Ø±: {self.config.get('sources', {}).get('trusted_domains', [])}.
        5. Ø§Ù„ØºÙŠØ§Ø¨: Ù‚Ù„ 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© Ø­Ø¯ÙŠØ«Ø©' Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±.
        6. Ø§Ù„Ù‡ÙŠÙƒÙ„: ØªØ±Ø­ÙŠØ¨ -> ØªØ­Ù„ÙŠÙ„ -> Ù…ØµØ¯Ø± -> Ø³Ø¤Ø§Ù„ Ù…ØªØ§Ø¨Ø¹Ø©.
        7. Ø§Ù„Ø¨ØµØ±ÙŠØ§Øª: Ø§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ (ğŸ“Š, ğŸ–¼ï¸, ğŸš€) Ù„ÙˆØµÙ Ø§Ù„ØµÙˆØ±.
        """
        response = self.ai_client.chat.completions.create(
            model=self.config.get('api', {}).get('openai', {}).get('model', 'gpt-4o'),
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": text}]
        )
        return response.choices[0].message.content.strip()

    def run(self):
        try:
            me = self.x_client.get_me().data
            logging.info(f"Connected as @{me.username}")
            # Ù†Ø´Ø± Ø¥Ø«Ø¨Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„
            self.x_client.create_tweet(text="ğŸš€ Ù†Ø¸Ø§Ù… TechAgent Pro Ù…ØªØµÙ„ Ø§Ù„Ø¢Ù† ÙˆØ¨ÙƒØ§Ù…Ù„ Ø·Ø§Ù‚ØªÙ‡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© ğŸ“Š.")
            
            # ÙØ­Øµ Ø§Ù„Ø±Ø¯ÙˆØ¯
            mentions = self.x_client.get_users_mentions(id=me.id, expansions=['author_id'], user_fields=['username'])
            if mentions.data:
                users = {u['id']: u.username for u in mentions.includes['users']}
                for tweet in mentions.data:
                    reply = self._generate_response(tweet.text, users.get(tweet.author_id))
                    self.x_client.create_tweet(text=reply[:280], in_reply_to_tweet_id=tweet.id)
        except Exception as e:
            logging.error(f"Runtime Error: {e}")

if __name__ == "__main__":
    TechAgentPro().run()
